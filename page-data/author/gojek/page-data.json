{"componentChunkName":"component---src-templates-author-js","path":"/author/gojek/","result":{"data":{"ghostAuthor":{"slug":"gojek","name":"Gojek","bio":null,"cover_image":null,"profile_image":null,"location":null,"website":"http://www.gojek.io","twitter":"@gojektech","facebook":null},"allGhostPost":{"edges":[{"node":{"id":"Ghost__Post__5eb1066a5524cd001e7392a4","title":"Why We Swear by the RCA","slug":"why-we-swear-by-the-rca","featured":false,"feature_image":"https://res-3.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_nOcToFzqvdWlHmOQ59v0sw.jpg","excerpt":"An account of how Gojek responds to production issues, and why the RCA is a critical part of the process.","custom_excerpt":"An account of how Gojek responds to production issues, and why the RCA is a critical part of the process.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"12 May, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-05-05T11:53:38.000+05:30","published_at":"2020-05-12T11:53:00.000+05:30","updated_at":"2020-05-12T11:53:20.000+05:30","meta_title":"Why We Swear by the RCA","meta_description":"An account of how Gojek responds to production issues, and why the RCA is a critical part of the process.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Stories","slug":"stories","description":"Deep dives into high-impact initiatives and products that helped Gojek create significant impact.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Stories","slug":"stories","description":"Deep dives into high-impact initiatives and products that helped Gojek create significant impact.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"When Gojek was still finding its feet, Fridays used to be a nightmare.\n\nJakarta, being the capital of the fourth most-populous country in the world, is\nhome to many people who work in the city and travel to their hometowns on\nweekends. Many of them rely on Gojek as their preferred first mile connectivity\noption — resulting in a traffic spike on our systems on Friday evening. In those\nearly days, this often triggered a system outage.\n\nEvery outage erodes the hard earned trust we build with our customers and driver\npartners.\n\nEnter the RCA\nWe knew we couldn’t fix the failures overnight, but we could learn from them.\nAfter all, so many of these mistakes were common and easily overlooked. So we\ndecided to embrace the ‘Root Cause Analysis’ (RCA). If something related to\nGojek’s Engineering division failed, the person(s) who attended the support call\nand had most context of what happened would prepare a document. This document\nwould contain a timeline, detail what went wrong, suggest corrective measures,\nand compile lessons learned.\n\nThis process ensured everyone across the organisation had visibility into what\nhappened. As a result, even unaffected teams cited in the RCA could analyse\ntheir systems to ensure the same problem would not happen to them. More\nimportantly, it provided a degree of accountability — and that’s important when\nyou have 20+ products.\n\nA post-mortem, and a prevention.\n\nThis post details what happens when a system failure happens at Gojek, and how\nit makes it way into an RCA.\n\n1. The What\nWhen something fails, it is important to understand the origin of the problem.\nEvery team in Gojek sets up alerts which monitor the state of their systems. If\na state change in the system causes a deviation from expected behaviour, an\nalerting service called pager duty automatically dials the phones of the people\nresponsible for that part of the system.\n\nHere’s an example:\n\nWhen a booking is created, we find a list of driver partners and send the order\ndetails to them, at which point they get a pop-up with trip details like\nestimated duration and approximate earnings. The idea is to give driver partners\nenough information to make the decision to accept the trip. But there was a\nproblem.\n\n2. The Why\nOne of the fields this prompt contains is a Booking ID, which is stored as an\ninteger (which, in technical speak, has a limit of 32 bits). Unfortunately for\nus, the ID generated exceeded this limit.\n\nWelcome to what we call Integer Overflow.\n\nAs a result of this, the driver app started crashing.\n\nHow bad can that be, you ask?\n\n3. The Fallout\nDrivers being unable to use the app means they can’t accept bookings. This means\ncustomers can’t book rides, send packages, get food, or use any service that\ndepends on our driver partners.\n\nAs a result, Gojek’s order numbers (or what we call ‘concurrence’, if you want\nto get all technical about it) plummeted. Pager duty is hit, and cell phones\nstart ringing off their proverbial hooks.\n\nWith driver partners stuck with malfunctioning apps, multiple Gojek services\nstart reporting errors. As customers try and figure out why the app is behaving\nthis way, engineers scramble to do the same.\n\n4. The Response\nWhen the phones ring, the team whose alerts have been triggered immediately get\nto work figuring out what happened. If they identify the problem quickly and\ndebug it, they notify other teams. The team then gets to work using information\nfrom the alerts and system dashboards to prepare an RCA.\n\nThis is, of course, the best case scenario.\n\nIf the concerned team cannot find a fix however, a war room is called.\n\nThe war room signifies a larger issue, and members of every available team drop\nwhat they’re doing and join the call. Sometimes, these are frantic Slack\ndiscussions and calls in the middle of the night. Other times, office boardrooms\nare blocked and everyone gathers to brainstorm collectively.\n\nDevs, Team Leads, Product Managers, all hands on deck.\n\nIn a war room scenario, whoever has most context on the situation takes charge\nand delegates tasks as required. This central person also plays a key role in\ndocumenting the happenings in the war room — how many people were present, which\nteams were represented, who was handling what, etc. All this information plays a\nkey role in the RCA. While this is going down, Driver and Customer Care centres\nare also notified, bracing for the inevitable flurry of complaints.\n\nThe fix may take the form of a few simple temporary hacks, or an hours long war\nroom — but in the end, there is always a fix.\n\nWords of appreciation from GoPay CEO Aldi Haryopratomo and Gojek CTO Ajey Gore\nAnd a sense of camaraderie ?\n\nOnce the dust settles, the investigation begins. The person who managed the war\nroom generally authors a document analysing what went wrong, using all the info\nfrom the alerts, dashboards, and firsthand accounts of the responders present.\nTypically every stakeholder in the organisation gets an email the next day with\ndetails of what went wrong — the RCA.\n\n5. The Learnings\n“Collaborate With Compassion”\n\nThese three words mean a lot at Gojek, and our RCAs reflect that. When you open\nan RCA mail, there is rarely even a mention of specific people, except to\nacknowledge those who responded to the distress call and played a role in\nfinding a fix. Call out the ones who made the effort, never the ones\nresponsible.\n\nMost RCAs instead dwell on relevant, actionable information. Information that\nwas being collected and monitored right from when the alert tripped:\n\nThe What: What was the problem?\n\nThe Why: Why did it happen?\n\nThe Fallout: Which services were affected, and for how long?\n\nThe Response: How was it fixed?\n\nThe Learnings: What can be done to avoid a repeat of this in future?\n\nThis simple process has helped us scale more safely and efficiently. It also\nallows for early identification of potential vulnerabilities in other systems.\nAs you may have noticed, there is no mention of who was responsible, no finger\npointing, no blame games. Collaborate with compassion.\n\nTo get a better sense of how we write RCAs at Gojek, read a sample RCA\n[https://docs.google.com/document/d/1r_PSsl7mBxbfAcibGTdFpnM5hm6ot82bF-_9VeV2J9w/edit?ts=5db7c330#heading=h.kreykp6cjau6]\n.\n\nIf you’d like to start a culture of RCAs as well, here’s our RCA template\n[https://docs.google.com/document/d/12Ims21IwFCNWi9MXcw2TVxPLB6YyWrIoTNaw3P-M_t4/edit]\n, courtesy GoPay CTO Ranjan Sakalley [https://twitter.com/rnjn], who also\noccasionally drops invaluable insights in the ‘Learnings’ section. ?\n\n\nRCAs have played an integral part in our journey to becoming a SuperApp.\nInvestigating, analysing, and documenting problems in production help us build\nbetter, more scalable systems, and tackle new problems in a mature manner\nwithout fear of retribution.\n\nThe days of weekly production issues are now a thing of the past. While we won’t\nbe so brash as to say we never have problems, embracing RCAs and a culture of\ncompassionate collaboration have helped us get to where we are today. ?\n\n\n--------------------------------------------------------------------------------\n\nWe’ll be writing about more interesting case studies on issues faced in\nproduction. Keep an eye on this blog, or subscribe to our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] for updates on our stories in\na neat little email.","html":"<p>When Gojek was still finding its feet, Fridays used to be a nightmare.</p><p>Jakarta, being the capital of the fourth most-populous country in the world, is home to many people who work in the city and travel to their hometowns on weekends. Many of them rely on Gojek as their preferred first mile connectivity option — resulting in a traffic spike on our systems on Friday evening. In those early days, this often triggered a system outage.</p><p><em><em>Every outage erodes the hard earned trust we build with our customers and driver partners.</em></em></p><h1 id=\"enter-the-rca\">Enter the RCA</h1><p>We knew we couldn’t fix the failures overnight, but we could learn from them. After all, so many of these mistakes were common and easily overlooked. So we decided to embrace the ‘Root Cause Analysis’ (RCA). If something related to Gojek’s Engineering division failed, the person(s) who attended the support call and had most context of what happened would prepare a document. This document would contain a timeline, detail what went wrong, suggest corrective measures, and compile lessons learned.</p><p>This process ensured everyone across the organisation had visibility into what happened. As a result, even unaffected teams cited in the RCA could analyse their systems to ensure the same problem would not happen to them. More importantly, it provided a degree of accountability — and that’s important when you have 20+ products.</p><p>A post-mortem, and a prevention.</p><p>This post details what happens when a system failure happens at Gojek, and how it makes it way into an RCA.</p><h2 id=\"1-the-what\">1. The What</h2><p>When something fails, it is important to understand the origin of the problem. Every team in Gojek sets up alerts which monitor the state of their systems. If a state change in the system causes a deviation from expected behaviour, an alerting service called <code>pager duty</code> automatically dials the phones of the people responsible for that part of the system.</p><p><strong><strong>Here’s an example:</strong></strong></p><p>When a booking is created, we find a list of driver partners and send the order details to them, at which point they get a pop-up with trip details like estimated duration and approximate earnings. The idea is to give driver partners enough information to make the decision to accept the trip. But there was a problem.</p><h2 id=\"2-the-why\">2. The Why</h2><p>One of the fields this prompt contains is a Booking ID, which is stored as an integer (which, in technical speak, has a limit of 32 bits). Unfortunately for us, the ID generated exceeded this limit.</p><p>Welcome to what we call Integer Overflow.</p><p>As a result of this, the driver app started crashing.</p><p><strong><strong><em><em>How bad can that be, you ask?</em></em></strong></strong></p><h2 id=\"3-the-fallout\">3. The Fallout</h2><p>Drivers being unable to use the app means they can’t accept bookings. This means customers can’t book rides, send packages, get food, or use any service that depends on our driver partners.</p><p>As a result, Gojek’s order numbers (or what we call ‘concurrence’, if you want to get all technical about it) plummeted. Pager duty is hit, and cell phones start ringing off their proverbial hooks.</p><p>With driver partners stuck with malfunctioning apps, multiple Gojek services start reporting errors. As customers try and figure out why the app is behaving this way, engineers scramble to do the same.</p><h2 id=\"4-the-response\">4. The Response</h2><p>When the phones ring, the team whose alerts have been triggered immediately get to work figuring out what happened. If they identify the problem quickly and debug it, they notify other teams. The team then gets to work using information from the alerts and system dashboards to prepare an RCA.</p><p><strong><strong>This is, of course, the best case scenario.</strong></strong></p><p>If the concerned team cannot find a fix however, a war room is called.</p><p>The war room signifies a larger issue, and members of every available team drop what they’re doing and join the call. Sometimes, these are frantic Slack discussions and calls in the middle of the night. Other times, office boardrooms are blocked and everyone gathers to brainstorm collectively.</p><p><em><em>Devs, Team Leads, Product Managers, all hands on deck.</em></em></p><p>In a war room scenario, whoever has most context on the situation takes charge and delegates tasks as required. This central person also plays a key role in documenting the happenings in the war room — <strong><strong>how many people were present, which teams were represented, who was handling what, etc.</strong></strong> <strong><strong>All this information plays a key role in the RCA.</strong></strong> While this is going down, Driver and Customer Care centres are also notified, bracing for the inevitable flurry of complaints.</p><p>The fix may take the form of a few simple temporary hacks, or an hours long war room — but in the end, there is always a fix.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1129/1*UFUYfO3Gw9tnKCiE1y40-Q.jpeg\" class=\"kg-image\"><figcaption>Words of appreciation from GoPay CEO Aldi Haryopratomo and Gojek CTO Ajey Gore</figcaption></figure><p><em><em>And a sense of camaraderie ?</em></em></p><p>Once the dust settles, the investigation begins. The person who managed the war room generally authors a document analysing what went wrong, using all the info from the alerts, dashboards, and firsthand accounts of the responders present. Typically every stakeholder in the organisation gets an email the next day with details of what went wrong — the RCA.</p><h2 id=\"5-the-learnings\">5. The Learnings</h2><p>“Collaborate With Compassion”</p><p>These three words mean a lot at Gojek, and our RCAs reflect that. When you open an RCA mail, there is rarely even a mention of specific people, except to acknowledge those who responded to the distress call and played a role in finding a fix. <strong><strong>Call out the ones who made the effort, never the ones responsible.</strong></strong></p><p>Most RCAs instead dwell on relevant, actionable information. Information that was being collected and monitored right from when the alert tripped:</p><p><em><em>The What: What was the problem?</em></em></p><p><em><em>The Why: Why did it happen?</em></em></p><p><em><em>The Fallout: Which services were affected, and for how long?</em></em></p><p><em><em>The Response: How was it fixed?</em></em></p><p><em><em>The Learnings: What can be done to avoid a repeat of this in future?</em></em></p><p>This simple process has helped us scale more safely and efficiently. It also allows for early identification of potential vulnerabilities in other systems. As you may have noticed, there is no mention of who was responsible, no finger pointing, no blame games. <em><em>Collaborate with compassion.</em></em></p><p>To get a better sense of how we write RCAs at Gojek, <a href=\"https://docs.google.com/document/d/1r_PSsl7mBxbfAcibGTdFpnM5hm6ot82bF-_9VeV2J9w/edit?ts=5db7c330#heading=h.kreykp6cjau6\" rel=\"noopener\"><strong><strong>read a sample RCA</strong></strong></a>.</p><p>If you’d like to start a culture of RCAs as well, <a href=\"https://docs.google.com/document/d/12Ims21IwFCNWi9MXcw2TVxPLB6YyWrIoTNaw3P-M_t4/edit\" rel=\"noopener\"><strong><strong>here’s our RCA template</strong></strong></a>, courtesy GoPay CTO <a href=\"https://twitter.com/rnjn\" rel=\"noopener\">Ranjan Sakalley</a>, who also occasionally drops invaluable insights in the ‘Learnings’ section. <strong><strong>?</strong></strong><br></p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/480/1*2sosYEnk68lMaQTVjdZjWQ.jpeg\" class=\"kg-image\"></figure><p>RCAs have played an integral part in our journey to becoming a SuperApp. Investigating, analysing, and documenting problems in production help us build better, more scalable systems, and tackle new problems in a mature manner without fear of retribution.</p><p>The days of weekly production issues are now a thing of the past. While we won’t be so brash as to say we never have problems, embracing RCAs and a culture of compassionate collaboration have helped us get to where we are today. ?</p><hr><p>We’ll be writing about more interesting case studies on issues faced in production. Keep an eye on this blog, or <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">subscribe to our newsletter</a> for updates on our stories in a neat little email.</p>","url":"https://gojek-ghost.zysk.in/why-we-swear-by-the-rca/","canonical_url":null,"uuid":"ef04187f-7199-434a-8647-6dcd386043cd","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb1066a5524cd001e7392a4","reading_time":5}},{"node":{"id":"Ghost__Post__5eafa30734df85001e15f489","title":"How We Pushed a Million Keys to Redis in Seconds","slug":"how-we-pushed-a-million-keys-to-redis-in-seconds","featured":false,"feature_image":"https://res-2.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_gN5KGQcKSipjSlQqEppJMA.jpg","excerpt":"Dealing with a lot of keys? Redis’ Pipe Mode is your friend.\nHello there!\n\nIn this post, I’ll share my ideas on how we populated Redis (running in a\nKubernetes cluster)… in a matter of seconds.\n\nHere’s what can you expect from this post:\n\n1. How to connect to Redis server running in a Kubernetes cluster ?\n\n2. What is Port-forwarding ?\n\n3. How to use Redis mass insertion & push millions of keys in seconds ?\n\n4. How to generate Redis Protocol ?\n\n5. How to read /parse a CSV in Ruby ?\n\nWait, but why","custom_excerpt":null,"visibility":"public","created_at_pretty":"04 May, 2020","published_at_pretty":"04 May, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-05-04T10:37:19.000+05:30","published_at":"2020-05-04T10:45:13.000+05:30","updated_at":"2020-05-12T11:50:45.000+05:30","meta_title":"How We Pushed a Million Keys to Redis in Seconds","meta_description":"Dealing with a lot of keys? Redis’ Pipe Mode is your friend.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Dealing with a lot of keys? Redis’ Pipe Mode is your friend.\nHello there!\n\nIn this post, I’ll share my ideas on how we populated Redis (running in a\nKubernetes cluster)… in a matter of seconds.\n\nHere’s what can you expect from this post:\n\n1. How to connect to Redis server running in a Kubernetes cluster ?\n\n2. What is Port-forwarding ?\n\n3. How to use Redis mass insertion & push millions of keys in seconds ?\n\n4. How to generate Redis Protocol ?\n\n5. How to read /parse a CSV in Ruby ?\n\nWait, but why do I need to do this? ?\n\nAt Gojek, we use Redis in one of the services for caching drivers for faster\nlookups. Since we have deployed this service to new clusters, we needed to\npopulate Redis with ~81K keys.\n\nWhat we didn’t do (and should not be done)\nWell, this. ?\n\n$ redis-cli -h \"hostname\" -p 6379 set \"key\" \"value\"\n\nThis simple and easy way of storing a key through redis-cli\n[https://redis.io/topics/rediscli] is okay, but not for thousands or millions of\nkeys. You don’t want to end up waiting for hours unless you are Regina Phalange\n[https://en.wikipedia.org/wiki/Phoebe_Buffay#%22Regina_Phalange%22]! ?\n\nUsing a normal Redis client to perform mass insertion is not a good idea. The\nnaive approach of sending one command after the other is slow, because you have\nto pay for the round trip time for every command.\n\nLet’s do something different!\nWe will use Redis mass insertion, but before going to that, let’s talk a bit\nabout Redis Protocol [https://redis.io/topics/protocol].\n\nRedis clients communicate with the Redis server using a protocol called RESP \n(REdis Serialization Protocol).\n\nWith that said, let’s go write some code! I like toying around with Ruby\n[https://www.ruby-lang.org/en/], so this was my language of choice.\n\nredis_mass_insert.rbgen_redis_proto function will generate the protocol required for mass insertion.\n\n> 2.6.3 > puts gen_redis_proto(\"SET\",\"mykey\",\"Hello World!\").inspect\nRunning the above command in Ruby console, will give us the following protocol.\n\n\"*3\\r\\n$3\\r\\nSET\\r\\n$5\\r\\nmykey\\r\\n$12\\r\\nHello World!\\r\\n\"\n\nWell, this is how a command is represented and sent to the Redis Server through \nRedis Protocol [https://redis.io/topics/protocol].\n\n*<args><cr><lf>\n$<len><cr><lf>\n<arg0><cr><lf>\n<arg1><cr><lf>\n...\n<argN><cr><lf>\n\nWhere <cr> means \"\\r\" (or ASCII character 13) and <lf> means \"\\n\" (or ASCII\ncharacter 10).\n\nWe can now run this script, but here’s a catch. Our Redis server runs in a\nKubernetes cluster and we didn’t want to install Ruby and its gems inside a\ncluster. So now?\n\nEnter port-forwarding! ?\n$ kubectl -n \"namespace\" port-forward \"pod-name\" 7000:6379\n\nConnections made to local port 7000 are forwarded to port 6379 of the pod that\nis running the Redis server. With this connection in place we can use our local\nworkstation to debug the database that is running in the pod.\n\nFinally, we run our script to populate Redis ?\n\n> $ ruby redis_mass_insert.rb | redis-cli -p 7000 --pipe\n> All data transferred. Waiting for the last reply...\nLast reply received from server.\nerrors: 0, replies: 81003\nWe ran this script and it completed within a fraction of seconds!\n\nBut, how?\nIn 2.6 or later versions of Redis the redis-cli utility supports a new mode\ncalled pipe mode that was designed in order to perform mass insertion.\n\nUnder the hood of pipe mode\nAccording to the official doc:\n\n * redis-cli — pipe tries to send data as fast as possible to the server.\n * At the same time it reads data when available, trying to parse it.\n * Once there is no more data to read from stdin, it sends a special ECHO \n   command with a random 20 bytes string: we are sure this is the latest command\n   sent, and we are sure we can match the reply checking if we receive the same\n   20 bytes as a bulk reply.\n * Once this special final command is sent, the code receiving replies starts to\n   match replies with these 20 bytes. When the matching reply is reached it can\n   exit with success.\n\nNaice, what’s next?\nWell, I tried populating Redis locally with a million keys.\n\nIt worked like a charm, in just ~2 seconds. ?\n\nThat’s it!\nI really hope that this post gave you some new insights.\n\nThanks for reading! ?\n\nReferences\n\n 1. Redis Mass Insertion [https://redis.io/topics/mass-insert]\n 2. Redis Protocol [https://redis.io/topics/protocol]\n 3. Port Forwarding in Kubernetes to access applications\n    [https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/]\n\nWant our stories to land in your inbox? Sign up for our newsletter!\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]","html":"<h3 id=\"dealing-with-a-lot-of-keys-redis-pipe-mode-is-your-friend-\">Dealing with a lot of keys? Redis’ Pipe Mode is your friend.</h3><p>Hello there!</p><p>In this post, I’ll share my ideas on how we populated Redis (running in a Kubernetes cluster)… in a matter of seconds.</p><p>Here’s what can you expect from this post:</p><p><em><em>1. How to connect to Redis server running in a Kubernetes cluster ?</em></em></p><p><em><em>2. What is Port-forwarding ?</em></em></p><p><em><em>3. How to use Redis mass insertion &amp; push millions of keys in seconds ?</em></em></p><p><em><em>4. How to generate Redis Protocol ?</em></em></p><p><em><em>5. How to read /parse a CSV in Ruby ?</em></em></p><p>Wait, but why do I need to do this? ?</p><p>At Gojek, we use Redis in one of the services for caching drivers for faster lookups. Since we have deployed this service to new clusters, we needed to populate Redis with ~81K keys.</p><h2 id=\"what-we-didn-t-do-and-should-not-be-done-\">What we didn’t do (and should not be done)</h2><p>Well, this. ?</p><p><code>$ redis-cli -h \"hostname\" -p 6379 set \"key\" \"value\"</code></p><p>This simple and easy way of storing a key through <code><a href=\"https://redis.io/topics/rediscli\" rel=\"noopener\">redis-cli</a></code> is okay, but not for thousands or millions of keys. You don’t want to end up waiting for hours unless you are <a href=\"https://en.wikipedia.org/wiki/Phoebe_Buffay#%22Regina_Phalange%22\" rel=\"noopener\">Regina Phalange</a>! ?</p><figure class=\"kg-card kg-embed-card\"><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fgiphy.com%2Fembed%2F5xaOcLvROln5TmaaVOM%2Ftwitter%2Fiframe&amp;display_name=Giphy&amp;url=https%3A%2F%2Fgiphy.com%2Fgifs%2Fthecomebackhbo-comeback-the-val-cherish-5xaOcLvROln5TmaaVOM&amp;image=https%3A%2F%2Fmedia.giphy.com%2Fmedia%2F5xaOcLvROln5TmaaVOM%2Fgiphy.gif&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=giphy\" allowfullscreen=\"\" frameborder=\"0\" height=\"301\" width=\"435\" title=\"Lisa Kudrow Thank You GIF by The Comeback HBO - Find &amp; Share on GIPHY\" class=\"s t u iu ai\" scrolling=\"auto\" style=\"box-sizing: inherit; position: absolute; top: 0px; left: 0px; width: 680px; height: 470.516px;\"></iframe></figure><p>Using a normal Redis client to perform mass insertion is not a good idea. The naive approach of sending one command after the other is slow, because you have to pay for the round trip time for every command.</p><h1 id=\"let-s-do-something-different-\">Let’s do something different!</h1><p>We will use Redis mass insertion, but before going to that, let’s talk a bit about <a href=\"https://redis.io/topics/protocol\" rel=\"noopener\">Redis Protocol</a>.</p><p><em><em>Redis clients communicate with the Redis server using a protocol called <strong><strong>RESP</strong></strong> (REdis Serialization Protocol).</em></em></p><p>With that said, let’s go write some code! I like toying around with <a href=\"https://www.ruby-lang.org/en/\" rel=\"noopener\">Ruby</a>, so this was my language of choice.</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><iframe src=\"https://blog.gojekengineering.com/media/59319951b0d29feee60832a68f811a18\" allowfullscreen=\"\" frameborder=\"0\" height=\"364\" width=\"680\" title=\"Ruby Script for Redis Mass Insertion\" class=\"s t u iu ai\" scrolling=\"auto\" style=\"box-sizing: inherit; position: absolute; top: 0px; left: 0px; width: 680px; height: 364px;\"></iframe><figcaption>redis_mass_insert.rb</figcaption></figure><p><code>gen_redis_proto</code> function will generate the protocol required for mass insertion.</p><blockquote>2.6.3 &gt; <strong><strong>puts gen_redis_proto(\"SET\",\"mykey\",\"Hello World!\").inspect</strong></strong></blockquote><p>Running the above command in Ruby console, will give us the following protocol.</p><p><code>\"*3\\r\\n$3\\r\\nSET\\r\\n$5\\r\\nmykey\\r\\n$12\\r\\nHello World!\\r\\n\"</code></p><p>Well, this is how a command is represented and sent to the Redis Server through <a href=\"https://redis.io/topics/protocol\" rel=\"noopener\">Redis Protocol</a>.</p><p><code>*&lt;args&gt;&lt;cr&gt;&lt;lf&gt;<br>$&lt;len&gt;&lt;cr&gt;&lt;lf&gt;<br>&lt;arg0&gt;&lt;cr&gt;&lt;lf&gt;<br>&lt;arg1&gt;&lt;cr&gt;&lt;lf&gt;<br>...<br>&lt;argN&gt;&lt;cr&gt;&lt;lf&gt;</code></p><p><em><em>Where <code>&lt;cr&gt;</code> means \"\\r\" (or ASCII character 13) and <code>&lt;lf&gt;</code> means \"\\n\" (or ASCII character 10).</em></em></p><p>We can now run this script, but here’s a catch. Our Redis server runs in a Kubernetes cluster and we didn’t want to install Ruby and its gems inside a cluster. So now?</p><h1 id=\"enter-port-forwarding-\">Enter port-forwarding! ?</h1><p><strong><strong><code>$ kubectl -n \"namespace\" port-forward \"pod-name\" 7000:6379</code></strong></strong></p><p>Connections made to local port 7000 are forwarded to port 6379 of the pod that is running the Redis server. With this connection in place we can use our local workstation to debug the database that is running in the pod.</p><p><em><em><em>Finally, we run our script to populate Redis ?</em></em></em></p><blockquote><strong><strong>$ ruby redis_mass_insert.rb | redis-cli -p 7000 --pipe</strong></strong></blockquote><blockquote>All data transferred. Waiting for the last reply...<br>Last reply received from server.<br>errors: 0, replies: 81003</blockquote><p>We ran this script and it completed within a fraction of seconds!</p><figure class=\"kg-card kg-embed-card\"><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fgiphy.com%2Fembed%2FjRARA4zqym98KmvkUy%2Ftwitter%2Fiframe&amp;display_name=Giphy&amp;url=https%3A%2F%2Fgiphy.com%2Fgifs%2FjRARA4zqym98KmvkUy&amp;image=https%3A%2F%2Fmedia.giphy.com%2Fmedia%2FjRARA4zqym98KmvkUy%2Fgiphy.gif&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=giphy\" allowfullscreen=\"\" frameborder=\"0\" height=\"246\" width=\"435\" title=\"Bingo GIF - Find &amp; Share on GIPHY\" class=\"s t u iu ai\" scrolling=\"auto\" style=\"box-sizing: inherit; position: absolute; top: 0px; left: 0px; width: 680px; height: 384.547px;\"></iframe></figure><h1 id=\"but-how\">But, how?</h1><p>In 2.6 or later versions of Redis the <code>redis-cli</code> utility supports a new mode called <strong><strong>pipe mode</strong></strong> that was designed in order to perform mass insertion.</p><h2 id=\"under-the-hood-of-pipe-mode\">Under the hood of pipe mode</h2><p>According to the official doc:</p><ul><li><em><em>redis-cli — pipe tries to send data as fast as possible to the server.</em></em></li><li><em><em>At the same time it reads data when available, trying to parse it.</em></em></li><li><em><em>Once there is no more data to read from stdin, it sends a special </em></em><strong><strong><em><em>ECHO</em></em></strong></strong><em><em> command with a random 20 bytes string: we are sure this is the latest command sent, and we are sure we can match the reply checking if we receive the same 20 bytes as a bulk reply.</em></em></li><li><em><em>Once this special final command is sent, the code receiving replies starts to match replies with these 20 bytes. When the matching reply is reached it can exit with success.</em></em></li></ul><h1 id=\"naice-what-s-next\">Naice, what’s next?</h1><p>Well, I tried populating Redis locally with <em><em>a million keys.</em></em></p><p>It worked like a charm, in just ~2 seconds. ?</p><figure class=\"kg-card kg-embed-card\"><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fgiphy.com%2Fembed%2Fj6ZQKMy3W3629lDJSX%2Ftwitter%2Fiframe&amp;display_name=Giphy&amp;url=https%3A%2F%2Fgiphy.com%2Fgifs%2Fhbo-avenue-5-avenue5-j6ZQKMy3W3629lDJSX&amp;image=https%3A%2F%2Fmedia.giphy.com%2Fmedia%2Fj6ZQKMy3W3629lDJSX%2Fgiphy.gif&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=giphy\" allowfullscreen=\"\" frameborder=\"0\" height=\"244\" width=\"435\" title=\"Hugh Laurie Charm GIF by HBO - Find &amp; Share on GIPHY\" class=\"s t u iu ai\" scrolling=\"auto\" style=\"box-sizing: inherit; position: absolute; top: 0px; left: 0px; width: 680px; height: 381.422px;\"></iframe></figure><h1 id=\"that-s-it-\">That’s it!</h1><p>I really hope that this post gave you some new insights.</p><p>Thanks for reading! ?</p><p><strong><strong>References</strong></strong></p><ol><li><a href=\"https://redis.io/topics/mass-insert\" rel=\"noopener\">Redis Mass Insertion</a></li><li><a href=\"https://redis.io/topics/protocol\" rel=\"noopener\">Redis Protocol</a></li><li><a href=\"https://kubernetes.io/docs/tasks/access-application-cluster/port-forward-access-application-cluster/\" rel=\"noopener\">Port Forwarding in Kubernetes to access applications</a></li></ol><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/60/1*Yigf1nGxRKjzV7vIC_YkYg.png?q=20\" class=\"kg-image\"></figure><p>Want our stories to land in your inbox? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter!</a></p>","url":"https://gojek-ghost.zysk.in/how-we-pushed-a-million-keys-to-redis-in-seconds/","canonical_url":null,"uuid":"399d0acb-04ee-4db6-8925-35c9dd3533e5","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eafa30734df85001e15f489","reading_time":3}},{"node":{"id":"Ghost__Post__5eaf9f2234df85001e15f42d","title":"OK Google, Meet Gojek","slug":"ok-google-meet-gojekwe-added-gojeks-ride-hailing-and-food-ordering-functions-to-google-assistant-heres-what-we-learned-in-the-process","featured":true,"feature_image":"https://res-5.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_QaQg1VnVWuhAebytXO-gKg.jpg","excerpt":"We added Gojek’s ride-hailing and food ordering functions to Google Assistant. Here’s what we learned in the process.","custom_excerpt":"We added Gojek’s ride-hailing and food ordering functions to Google Assistant. Here’s what we learned in the process.","visibility":"public","created_at_pretty":"04 May, 2020","published_at_pretty":"04 May, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-05-04T10:20:42.000+05:30","published_at":"2020-05-04T10:33:07.000+05:30","updated_at":"2020-05-12T11:46:27.000+05:30","meta_title":"Ok Google, Meet Gojek","meta_description":"We added Gojek’s ride-hailing and food ordering functions to Google Assistant. Here’s what we learned in the process.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"We added Gojek’s ride-hailing and food ordering functions to Google Assistant.\nHere’s what we learned in the process.\nBy Vikas Bajpayee and Lokesh Kalal\n\nOur aim behind building a Super App was to help our users get rid of the daily\nfrictions in their lives. But the journey doesn’t stop there. Even after\nbuilding all these convenient products, we still try and reduce frictions that\nmay be encountered even within our app — such as booking a ride or ordering\nfood.\n\nSo we thought, why don’t we integrate with Google Assistant, and let our users\ncommunicate with our products in a new way?\n\nIn this post, we explain how we integrated our food and transport products with\nthe Google Assistant.\n\nThe why\nWe’ve already addressed one part of the why — convenience. The other is user\nre-engagement. According to this survey\n[https://andrewchen.co/new-data-shows-why-losing-80-of-your-mobile-users-is-normal-and-that-the-best-apps-do-much-better/?utm_content=buffere4fa2&utm_medium=twitter.com&utm_source=social&utm_campaign=buffer] \nconducted by Silicon Valley researcher Andrew Chen 77% of users stop using an\napp three days after they install it. Within a month, that number goes up to\n90%. ?\n\nThe how\nTo help integrate Android apps with the Google Assistant, Google launched App\nActions:\n\nWhat are app actions?\nApp Actions are a new way to make your android app content available in places\nlike Google Search, Google Assistant etc. From a user’s perspective, App Actions\nbehave like shortcuts to parts of your Android app. When users invoke an App\nAction, the Assistant either launches a screen in the Android app that the user\nhas already installed or shows an embedded visual card (Android Slice) that\nusers can interact with.\n\nApp actions provide a faster way for users to access Android apps. It can be\nachieved in two ways:- either user can be directed to a specific\nactivity(screen) using a deep link or user may see relevant content on the\nAssistant itself called Slices.\n\nMore info on this can be found here: \nhttps://developers.google.com/assistant/app/overview\n\nWhat are Slices?\nSlices are super-powered app actions. They provide a way to interact with apps\nwithout moving away from Assistant by showing a small piece of UI within\nAssistant. Slices are UI templates that can display rich, dynamic, and\ninteractive content from the app in Google Assistant.\n\nSlices can help users perform tasks faster by enabling engagement outside of the\nfullscreen app experience.\n\nYou can build Slices as enhancements to App Actions.\n\nHere’s an example:\n\nWe choose to use slices to show food order status, as the order status will have\nlimited information (eg. Driver is on the way to Restaurant, with his location\non Map ) which can be easily shown in a small piece of UI segment.\n\nIn fact, this functionality was recently demoed on stage at a Google event in\nIndonesia. You can check it out below:\n\nApp Actions Demo at #Google4ID 2019How does it work?\nWhenever a user says or types something in Assistant, assistant parses the\nquery. If the query matches the built-in intent\n[https://developers.google.com/assistant/app/reference/built-in-intents] grammar\nthen Google Assistant extracts the query parameter in schema.org\n[https://schema.org/] and generates a deep link URL using the mapping we provide\nin an actions.xml file.\n\nGoogle then attaches those extracted parameters to the deep link URL and creates\na final deep link which allows a user to launch specific content or screens in\nthe app.\n\nLet’s dig a little deeper:\n\nGoogle applies Machine Learning and Artificial Intelligence (Natural Language\nProcessing) to understand all the sentences we type in Assistant.\n\nWhile users can type anything they want in Assistant and the system gets better\nat interpreting them over time, but there are some sentences for specific intent\nthat are fixed by Google. More info here\n[https://developers.google.com/assistant/app/reference/built-in-intents#create-taxi-reservation]\n.\n\nHow did we integrate our services with Assistant?\nThe core of integrating Gojek with Assistant involved creating actions on Google\nAssistant with actions.xml file.\n\nLet’s explore how to do this:\n\n1. Create actions.xml file in your XML folder. This contains all the actions\nwith built-in intents which define what actions our app can support in the\nAssistant. Each action contains built-in intents\n[https://developers.google.com/assistant/app/reference/built-in-intents#create-taxi-reservation] \nsupported by Google as a <intent-name> tag.\n\n2. Define a fulfilment mode for each app action — which can be deep links or\nslices. You have to pass a fulfilment mode in each action. This is compulsory.\n\n3. Pass the URL template which will allow a user to launch your app — this can\nbe the deep link to your app or URL to Slice provider.\n\n4. Define entity-set — the Gojek app is available in multiple locales, so to\nprovide locale for all the regions, we added the entity-set, which allows\nAssistant to understand more than one version of category. ex:- taxi can be\npronounced as taksi in Bahasa.\n\nSo, If you want locale for your specific parameter in deep-link URL, you can\nsimply attach an entity-set with that parameter, see how you can achieve this in\nbelow example\n\n<parameter name=”taxiReservation.category”><entity-set-reference\nentitySetId=”TransportCategoryEntitySet” /></parameter>\n\n5. Add a reference to actions.xml file using the <meta> tag in your app’s\nmanifest.xml file inside the application tag.\n\nIn order to integrate Slices:\n\n 1. Implement an Android Slice by following the steps described in the Slices\n    Getting Started guide\n    [https://developer.android.com/guide/slices/getting-started].\n 2. In the actions.xml file, in the <fulfillment> element, specify \n    fulfillmentMode=“actions.fulfillment.SLICE” to indicate that a user intent\n    can be fulfilled using a Slice in your app.\n\nA few quick notes on what we learnt\n 1. Testing this feature is pretty hard and things become weird when you have\n    multiple build types of your app. For testing, you need a build type on the\n    Play Store, (which means the package name of the testing build should match\n    the package name of the published app). You can use a plugin (developed by\n    Google) called App Actions Test Tool\n    [https://developers.google.com/assistant/app/test-tool] for testing this\n    feature.\n\n> Please make sure you are following points while testing with App Actions Test\nTool:\na) Log in to Android Studio and Google Assistant with the account which has\naccess to your published app on Play console.\nb) ApplicationId of the app should be the same as your published app.\nc) Your Gradle should be built successfully.\nd) Use App Action Tool to create and update preview and test the app actions and\nslice.\n2. If your app is used in different locales, you can create locales using \nentity-set\n[https://developers.google.com/assistant/app/action-schema#entity-set-reference] \nin the actions.xml file.\n\n3. In order to give early builds to QA or other users (if you have multiple\nbuild types in your app), you can create an internal test track on Play console\nand add relevant people to it. This allows you to share the build to production\nfor only some listed users.\n\n(See this\n[https://support.google.com/googleplay/android-developer/answer/3131213?hl=en] \nfor how you can create an internal test track for your app.)\n\n4. Actions.xml shouldn’t be obfuscated in release apk — it means if you are\nusing any obfuscated tools like proguard then actions.xml shouldn’t be\nobfuscated there.\n\n5. Slices can be requested before the onCreate of your application is completed.\nYou can run into issues if you are using something which is initialised in \nonCreate while creating slices.\n\n6. Don't refresh slices from onBindSlice() method, it will end up in an infinite\nloop where Google Assistant will call onBindSlice() infinitely.\n\nThat’s all from us folks. Hope this post gave you a better understanding of how\nApp Actions and Slices work with Google Assistant. Working on this feature was\nan amazing experience for us. If you use the Gojek app, make sure to give them a\ntry and let us know what you think. ?\n\n\n--------------------------------------------------------------------------------\n\nLiked what you read? Sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] and we’ll send you updates\nfrom the blog straight to your inbox! ?","html":"<h3 id=\"we-added-gojek-s-ride-hailing-and-food-ordering-functions-to-google-assistant-here-s-what-we-learned-in-the-process-\">We added Gojek’s ride-hailing and food ordering functions to Google Assistant. Here’s what we learned in the process.</h3><p><strong><strong><em>By Vikas Bajpayee and Lokesh Kalal</em></strong></strong></p><p>Our aim behind building a Super App was to help our users get rid of the daily frictions in their lives. But the journey doesn’t stop there. Even after building all these convenient products, we still try and reduce frictions that may be encountered even within our app — such as booking a ride or ordering food.</p><p>So we thought, why don’t we integrate with Google Assistant, and let our users communicate with our products in a new way?</p><p>In this post, we explain how we integrated our food and transport products with the Google Assistant.</p><h1 id=\"the-why\">The why</h1><p>We’ve already addressed one part of the <em><em>why — </em></em>convenience. The other is user re-engagement. According to <a href=\"https://andrewchen.co/new-data-shows-why-losing-80-of-your-mobile-users-is-normal-and-that-the-best-apps-do-much-better/?utm_content=buffere4fa2&amp;utm_medium=twitter.com&amp;utm_source=social&amp;utm_campaign=buffer\" rel=\"noopener\">this survey</a> conducted by Silicon Valley researcher Andrew Chen 77% of users stop using an app three days after they install it. Within a month, that number goes up to 90%. ?</p><h1 id=\"the-how\">The how</h1><p>To help integrate Android apps with the Google Assistant, Google launched App Actions:</p><h2 id=\"what-are-app-actions\">What are app actions?</h2><p>App Actions are a new way to make your android app content available in places like Google Search, Google Assistant etc. From a user’s perspective, App Actions behave like shortcuts to parts of your Android app. When users invoke an App Action, the Assistant either launches a screen in the Android app that the user has already installed or shows an embedded visual card (Android Slice) that users can interact with.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/260/1*w4jk-CTME9amkb5dsIQDzw.gif\" class=\"kg-image\"></figure><p>App actions provide a faster way for users to access Android apps. It can be achieved in two ways:- either user can be directed to a specific activity(screen) using a deep link or user may see relevant content on the Assistant itself called Slices.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/260/1*KPBLtVMjiHBOPEJ53E9F8A.gif\" class=\"kg-image\"></figure><p>More info on this can be found here: <a href=\"https://developers.google.com/assistant/app/overview\" rel=\"noopener\">https://developers.google.com/assistant/app/overview</a></p><h2 id=\"what-are-slices\"><strong>What are Slices?</strong></h2><p>Slices are super-powered app actions. They provide a way to interact with apps without moving away from Assistant by showing a small piece of UI within Assistant. Slices are UI templates that can display rich, dynamic, and interactive content from the app in Google Assistant.</p><p><em><em>Slices can help users perform tasks faster by enabling engagement outside of the fullscreen app experience.</em></em></p><p>You can build Slices as enhancements to App Actions.</p><p>Here’s an example:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1080/1*EFF30b3185UtwKYjx0VP1A.jpeg\" class=\"kg-image\"></figure><p>We choose to use slices to show food order status, as the order status will have limited information (eg. Driver is on the way to Restaurant, with his location on Map ) which can be easily shown in a small piece of UI segment.</p><p>In fact, this functionality was recently demoed on stage at a Google event in Indonesia. You can check it out below:</p><figure class=\"kg-card kg-embed-card kg-card-hascaption\"><iframe src=\"https://cdn.embedly.com/widgets/media.html?src=https%3A%2F%2Fwww.youtube.com%2Fembed%2F0u20Iu4m2Co%3Fstart%3D5805%26feature%3Doembed%26start%3D5805&amp;url=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3D0u20Iu4m2Co&amp;image=https%3A%2F%2Fi.ytimg.com%2Fvi%2F0u20Iu4m2Co%2Fhqdefault.jpg&amp;key=a19fcc184b9711e1b4764040d3dc5c07&amp;type=text%2Fhtml&amp;schema=youtube\" allowfullscreen=\"\" frameborder=\"0\" height=\"480\" width=\"854\" title=\"#Google4ID 2019\" class=\"s t u iu ai\" scrolling=\"auto\" style=\"box-sizing: inherit; position: absolute; top: 0px; left: 0px; width: 680px; height: 382.188px;\"></iframe><figcaption>App Actions Demo at #Google4ID 2019</figcaption></figure><h1 id=\"how-does-it-work\"><strong>How does it work?</strong></h1><p>Whenever a user says or types something in Assistant, assistant parses the query. If the query matches the<a href=\"https://developers.google.com/assistant/app/reference/built-in-intents\" rel=\"noopener\"> built-in intent</a> grammar then Google Assistant extracts the query parameter in<a href=\"https://schema.org/\" rel=\"noopener\"> schema.org</a> and generates a deep link URL using the mapping we provide in an actions.xml file.</p><p>Google then attaches those extracted parameters to the deep link URL and creates a final deep link which allows a user to launch specific content or screens in the app.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1490/0*jUlpzwbXbFIgGy7s\" class=\"kg-image\"></figure><p>Let’s dig a little deeper:</p><p>Google applies Machine Learning and Artificial Intelligence (Natural Language Processing) to understand all the sentences we type in Assistant.</p><p>While users can type anything they want in Assistant and the system gets better at interpreting them over time, but there are some sentences for specific intent that are fixed by Google. More info <a href=\"https://developers.google.com/assistant/app/reference/built-in-intents#create-taxi-reservation\" rel=\"noopener\">here</a>.</p><h1 id=\"how-did-we-integrate-our-services-with-assistant\"><strong>How did we integrate our services with Assistant?</strong></h1><p>The core of integrating Gojek with Assistant involved creating actions on Google Assistant with actions.xml file.</p><p>Let’s explore how to do this:</p><p>1. Create <strong><strong>actions.xml</strong></strong> file in your XML folder. This contains all the actions with built-in intents which define what actions our app can support in the Assistant. Each action contains<a href=\"https://developers.google.com/assistant/app/reference/built-in-intents#create-taxi-reservation\" rel=\"noopener\"> built-in intents</a> supported by Google as a &lt;intent-name&gt; tag.</p><p>2. Define a fulfilment mode for each app action — which can be deep links or slices. You have to pass a fulfilment mode in each action. This is compulsory.</p><p>3. Pass the URL template which will allow a user to launch your app — this can be the deep link to your app or URL to Slice provider.</p><p>4. Define entity-set — the Gojek app is available in multiple locales, so to provide locale for all the regions, we added the entity-set, which allows Assistant to understand more than one version of category. ex:- taxi can be pronounced as taksi in Bahasa.</p><p>So, If you want locale for your specific parameter in deep-link URL, you can simply attach an entity-set with that parameter, see how you can achieve this in below example</p><p><em>&lt;parameter name=”taxiReservation.category”&gt;&lt;entity-set-reference entitySetId=”TransportCategoryEntitySet” /&gt;&lt;/parameter&gt;</em></p><p>5. Add a reference to <strong><strong>actions.xml</strong></strong> file using the &lt;meta&gt; tag in your app’s manifest.xml file inside the application tag.</p><p><strong><strong>In order to integrate Slices:</strong></strong></p><ol><li>Implement an Android Slice by following the steps described in the <a href=\"https://developer.android.com/guide/slices/getting-started\" rel=\"noopener\">Slices Getting Started guide</a>.</li><li>In the actions.xml file, in the <code>&lt;fulfillment&gt;</code> element, specify <code>fulfillmentMode=“actions.fulfillment.SLICE”</code> to indicate that a user intent can be fulfilled using a Slice in your app.</li></ol><h1 id=\"a-few-quick-notes-on-what-we-learnt\"><strong>A few quick notes on what we learnt</strong></h1><ol><li>Testing this feature is pretty hard and things become weird when you have multiple build types of your app. For testing, you need a build type on the Play Store, (which means the package name of the testing build should match the package name of the published app). You can use a plugin (developed by Google) called<a href=\"https://developers.google.com/assistant/app/test-tool\" rel=\"noopener\"> <strong><strong>App Actions Test Tool</strong></strong></a> for testing this feature.</li></ol><blockquote><em><em>Please make sure you are following points while testing with App Actions Test Tool:</em></em><br><em><em>a) Log in to Android Studio and Google Assistant with the account which has access to your published app on Play console.</em></em><br><em><em>b) <code>ApplicationId</code> of the app should be the same as your published app.</em></em><br><em><em>c) Your Gradle should be built successfully.</em></em><br><em><em>d) Use App Action Tool to create and update preview and test the app actions and slice.</em></em></blockquote><p>2. If your app is used in different locales, you can create locales using <a href=\"https://developers.google.com/assistant/app/action-schema#entity-set-reference\" rel=\"noopener\">entity-set</a> in the actions.xml file.</p><p>3. In order to give early builds to QA or other users (if you have multiple build types in your app), you can create an internal test track on Play console and add relevant people to it. This allows you to share the build to production for only some listed users.</p><p>(See <a href=\"https://support.google.com/googleplay/android-developer/answer/3131213?hl=en\" rel=\"noopener\">this</a> for how you can create an internal test track for your app.)</p><p>4. Actions.xml shouldn’t be <strong><strong>obfuscated</strong></strong> in release apk — it means if you are using any obfuscated tools like proguard then actions.xml shouldn’t be obfuscated there.</p><p>5. Slices can be requested before the <code>onCreate</code> of your application is completed. You can run into issues if you are using something which is initialised in <code>onCreate</code> while creating slices.</p><p>6. Don't refresh slices from <code>onBindSlice()</code> method, it will end up in an infinite loop where Google Assistant will call <code>onBindSlice()</code> infinitely.</p><p>That’s all from us folks. Hope this post gave you a better understanding of how App Actions and Slices work with Google Assistant. Working on this feature was an amazing experience for us. If you use the Gojek app, make sure to give them a try and let us know what you think. ?</p><hr><p>Liked what you read? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter</a> and we’ll send you updates from the blog straight to your inbox! ?</p>","url":"https://gojek-ghost.zysk.in/ok-google-meet-gojekwe-added-gojeks-ride-hailing-and-food-ordering-functions-to-google-assistant-heres-what-we-learned-in-the-process/","canonical_url":null,"uuid":"a980d332-756f-4f47-a97f-921a11196ed7","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eaf9f2234df85001e15f42d","reading_time":6}},{"node":{"id":"Ghost__Post__5eb0f8af5524cd001e7391f4","title":"How Gojek Uses NLP to Name Pickup Locations at Scale","slug":"how-gojek-uses-nlp-to-name-pickup-locations-at-scale-2","featured":false,"feature_image":"https://res-2.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_dFalBje-vQCkEY8Zrq9P5g.jpg","excerpt":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","custom_excerpt":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"01 May, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-05-05T10:55:03.000+05:30","published_at":"2020-05-01T09:30:00.000+05:30","updated_at":"2020-05-12T11:51:38.000+05:30","meta_title":"How Gojek Uses NLP to Name Pickup Points at Scale","meta_description":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"When our customers want to use our ride hailing products like GoRide and GoCar,\nthey are presented with convenient, clearly named pickup points nearby. Here’s\nan example:\n\nThis saves customers the hassle of calling the driver partner, explaining where\nthey are, what colour clothes they are wearing, and so on. Our pickup points are\ndesigned to make lives easier for both customers and driver partners.\n\nThis is possible because the pickup points shown on the app are popular pickup\nlocations around the area. What’s more, the pickup point names are displayed\nexactly how customers driver partners usually refer to them.\n\nBut how do we manage to name so many pickup points accurately, and at scale?\n\nWe use past booking locations and their associated chat logs to discover named\npickup points. As our previous research has explained, we first perform \nclustering\n[https://blog.gojekengineering.com/fantastic-drivers-and-how-to-find-them-a88239ef3b29] \non historical bookings to form potential pickup points, then we use a language\nmodel\n[https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03] \nto select the best name. Here, we explain how we improved upon the previous\nstatistical language model with a state-of-the-art NLP model, which makes the\nentire naming exercise fully scalable. This is the magic behind all the pickup\npoints seen on the Gojek app.\n\nHow can we learn better?\nAs explained in our previous post, our original statistical language model\nselects the best pickup point name from the most probable n-grams extracted from\nbookings text. However, such a statistical language model doesn’t ‘understand’\nthe meaning of the texts, it simply chooses phrases with high frequencies\nwithout knowing the semantics. Sometimes it throws street names, sometimes even\ncommon phrases with no information about location. We have to manually check\neverything to make sure it reflects the right POI, before it appears on the app.\n\nThis creates a challenge — especially if we want to quickly expand the\nfrictionless pickup experience to customers across in new geographies. Hence, we\ndecided to go a step further with a deep-learning NLP model that ‘understands’\nand ‘learns’ to differentiate what is a valid pickup point name.\n\nAt Gojek, we never stop thinking and always go a step further\n\nMeet CartoBERT ?\nOne of the most recent and impactful breakthroughs NLP was the publication of\nBERT[1] — a contextual language representation with transformer models — by\nGoogle in late 2018. It obtained state-of-the-art results on a wide array of NLP\ntasks. In the 2019, many NLP researches were influenced by BERT, including\nXLNet, RoBERTa, ERNIE etc.\n\nBERT Explained\nBERT, or Bidirectional Encoder Representations from Transformers, is composed of\nan embedding layer, followed by groups of transformer layers.\n\nEvery word (token) in the input sentence will first get encoded into its\nembedding representations in the embedding layer, and then go through\nbidirectional transformer encoder layers. Every encoder layer will perform the\nmulti-head attention computation on the token representation from the previous\nlayer to create a new intermediate representation, which is then output to the\nnext layer. The output from the final layer is the contextual representation of\nthe input token. A pooled sentence level representation combining all token\nrepresentations could be created if needed by specific downstream tasks.\n\nWith the final contextual representations at either token or sentence level, a\npre-trained BERT on large unlabelled text corpus, could be further extended to a\nwide variety of NLP tasks, such as text classification, question answering,\nNamed Entity Recognition (NER) etc.\n\nALBERT[2], published by Google in Sep 2019, improved on BERT with embedding\nparameter factorisation and cross layer parameter sharing to reduce the number\nof parameters (by 9 times for base model). It also uses sequence order\nprediction instead of next sentence prediction for the pre-train task. In the\npaper, ALBERT also outperforms BERT on standard NLP tasks/datasets (SQUAD, RACE\netc), with fewer parameters.\n\nPre-train CartoBERT to learn language representation from Gojek bookings text\nInspired by ALBERT’s lightweight model and performance, we developed CartoBERT,\nGojek’s very own pickup point name recognition model, based on ALBERT’s\narchitecture.\n\nAs illustrated below, the uncased CartoBERT is pre-trained on Gojek’s own masked\nbookings text corpus of about 200 million sentences. Booking text is first\npre-processed for data masking to mask all customer sensitive information,\nlanguage detection, text normalisation (including text cleaning, slang,\nabbreviation transformations, lowercase transformation and emoji removal). The\npre-processed text is used to build subword vocabularies which handles\nOut-Of-Vocabulary (OOV) tokens that could be decomposed to frequent subword\npatterns. CartoBERT tokenizer is then created with the subword vocabularies and\nfurther used to encode and tokenize the same preprocessed bookings text to form\npre-trained input files.\n\nSame as ALBERT, the model is pre-trained to ‘understand’ Gojek’s bookings text\nusing Masked Language Model — which predicts randomly masked tokens in input\nsentences — and Sentence Order Prediction tasks, which predicts the order of\ninput sentences pair.\n\nFine-tuning CartoBERT to extract pickup point names from Gojek bookings text\nWith the huge amount of bookings text we have at Gojek, now CartoBERT can better\n‘understand’ past bookings text. Theoretically, it ‘understands’ every word of a\nbooking text sentence.\n\nFor every token in the input sentence, CartoBERT will output a 768-dimension\nvector (we use the default hidden layer size of the ALBERT base model in\nCartoBERT, however this is configurable) from last transformer encoder layer,\nand we use that to represent CartoBERT’s ‘understanding’ of the token’s meaning\nin the sentence context for fine-tune step.\n\nAs illustrated in the diagram below, while fine-tuning CartoBERT for pickup\npoint name recognition, we replace the Masked Language Model and Sequence Order\nPrediction layers from CartoBERT in pre-train step with token classification\nlayer. The token classification layer learns to predict the probability of a\ntoken belonging to a pickup point name, with the final token representation\noutput from CartoBERT transformer layers, from labelled training data created\nwith bookings text sentences, and corresponding pickup point names. Here, we use\nweighted cross entropy loss to deal with class imbalance, as tokens tagged to\npickup point names are a minority.\n\n\n\nWith this, CartoBERT is fine-tuned to extract pickup point names from bookings\ntext sentences, if any.\n\nHow does the model perform?\nCartoBERT gives a lift of more than 25% in pickup point name accuracy to ~93%\naccuracy, which is measured as the percentage of valid pick up point names out\nof generated names. With this high accuracy, we have achieved full scalability\nof automatic generation for named pickup points to quickly cover multiple\ngeographies without heavy reliance on human inputs.\n\nWhat’s next?\nWe are not stopping here and are exploring using active learning to further\nimprove CartoBERT. With active learning, we only flag out uncertain predictions,\nwhich are measured as sentence level least token probability[3] for human\nlabelling. We then use human-curated data as feedback for model learning. In\nthis way, we can improve model learning efficiency with minimum labelling\neffort.\n\nWhat’s more, with the success of CartoBERT, we are considering pre-training and\nopen sourcing a general Indonesia Bahasa ALBERT model with Indonesia open corpus\nfrom wiki, news, Twitter etc. Currently, the options for open-sourced language\nmodel in Indonesia Bahasa are very limited, only pre-trained static word\nembeddings such as word2vec, fasttext etc are available. It would be beneficial\nto the community if we have a good state-of-the-art attention-based transformer\nmodel for the language. Stay tuned for more updates from the Cartography Data\nScience team. ?\n\nLeave a ? if you liked what you read. Ping me with suggestions and feedback.\n\nThanks to all the amazing people who contributed to this post: Tan Funan, Zane\nLim, Dang Le, Lijuan Chia, Bani Widyatmiko, Maureen Koha, Ringga Saputra, Nur\nIzzahudinr, Sandya Ardi, Yeni Primasari, Ardya Dipta.\n\n\n--------------------------------------------------------------------------------\n\nReferences\n\n[1] J. Devlin [https://arxiv.org/search/cs?searchtype=author&query=Devlin%2C+J], \nM. Chang [https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+M], K.\nLee [https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+K], K. Toutanova\n[https://arxiv.org/search/cs?searchtype=author&query=Toutanova%2C+K]: BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding.\narXiv:1810.04805 [https://arxiv.org/abs/1810.04805] (2018)\n\n[2] Z. Lan [https://arxiv.org/search/cs?searchtype=author&query=Lan%2C+Z], M.\nChen [https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+M], S. Goodman\n[https://arxiv.org/search/cs?searchtype=author&query=Goodman%2C+S], K. Gimpel\n[https://arxiv.org/search/cs?searchtype=author&query=Gimpel%2C+K], P. Sharma\n[https://arxiv.org/search/cs?searchtype=author&query=Sharma%2C+P], R. Soricut\n[https://arxiv.org/search/cs?searchtype=author&query=Soricut%2C+R]: ALBERT: A\nLite BERT for Self-supervised Learning of Language Representations. \narXiv:1909.11942 [https://arxiv.org/abs/1909.11942] (2019)\n\n[3] M.Liu [https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+M], Z. Tu\n[https://arxiv.org/search/cs?searchtype=author&query=Tu%2C+Z], Z. Wang\n[https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Z], X. Xu\n[https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+X]: LTP: A New Active\nLearning Strategy for Bert-CRF Based Named Entity Recognition. arXiv:2001.02524\n[https://arxiv.org/abs/2001.02524] (2020)\n\n\n--------------------------------------------------------------------------------\n\nLiked what you read? Sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] to have our latest stories\ndelivered straight to your inbox!","html":"<p>When our customers want to use our ride hailing products like GoRide and GoCar, they are presented with convenient, clearly named pickup points nearby. Here’s an example:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/180/1*msS7z4IN06LVM0XvClmmPQ.gif\" class=\"kg-image\"></figure><p>This saves customers the hassle of calling the driver partner, explaining where they are, what colour clothes they are wearing, and so on. Our pickup points are designed to make lives easier for both customers and driver partners.</p><p>This is possible because the pickup points shown on the app are popular pickup locations around the area. What’s more, the pickup point names are displayed exactly how customers driver partners usually refer to them.</p><p><strong><strong>But how do we manage to name so many pickup points accurately, and at scale?</strong></strong></p><p>We use past booking locations and their associated chat logs to discover named pickup points. As our previous research has explained, we first perform <a href=\"https://blog.gojekengineering.com/fantastic-drivers-and-how-to-find-them-a88239ef3b29\" rel=\"noopener\">clustering</a> on historical bookings to form potential pickup points, then we use a <a href=\"https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03\" rel=\"noopener\">language model</a> to select the best name. Here, we explain how we improved upon the previous statistical language model with a state-of-the-art NLP model, which makes the entire naming exercise fully scalable. This is the magic behind all the pickup points seen on the Gojek app.</p><h1 id=\"how-can-we-learn-better\">How can we learn better?</h1><p>As explained in our previous post, our original statistical language model selects the best pickup point name from the most probable n-grams extracted from bookings text. However, such a statistical language model doesn’t ‘understand’ the meaning of the texts, it simply chooses phrases with high frequencies without knowing the semantics. Sometimes it throws street names, sometimes even common phrases with no information about location. We have to manually check everything to make sure it reflects the right POI, before it appears on the app.</p><p>This creates a challenge — especially if we want to quickly expand the frictionless pickup experience to customers across in new geographies. Hence, we decided to go a step further with a deep-learning NLP model that ‘understands’ and ‘learns’ to differentiate what is a valid pickup point name.</p><p><em><em>At Gojek, we never stop thinking and always go a step further</em></em></p><h1 id=\"meet-cartobert-\">Meet CartoBERT ?</h1><p>One of the most recent and impactful breakthroughs NLP was the publication of BERT[1] — a contextual language representation with transformer models — by Google in late 2018. It obtained state-of-the-art results on a wide array of NLP tasks. In the 2019, many NLP researches were influenced by BERT, including XLNet, RoBERTa, ERNIE etc.</p><h2 id=\"bert-explained\">BERT Explained</h2><p>BERT, or Bidirectional Encoder Representations from Transformers, is composed of an embedding layer, followed by groups of transformer layers.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1226/1*qHFXdPcW_3UkLEsRJy2FRg.png\" class=\"kg-image\"></figure><p>Every word (token) in the input sentence will first get encoded into its embedding representations in the embedding layer, and then go through bidirectional transformer encoder layers. Every encoder layer will perform the multi-head attention computation on the token representation from the previous layer to create a new intermediate representation, which is then output to the next layer. The output from the final layer is the contextual representation of the input token. A pooled sentence level representation combining all token representations could be created if needed by specific downstream tasks.</p><p>With the final contextual representations at either token or sentence level, a pre-trained BERT on large unlabelled text corpus, could be further extended to a wide variety of NLP tasks, such as text classification, question answering, Named Entity Recognition (NER) etc.</p><p>ALBERT[2], published by Google in Sep 2019, improved on BERT with embedding parameter factorisation and cross layer parameter sharing to reduce the number of parameters (by 9 times for base model). It also uses sequence order prediction instead of next sentence prediction for the pre-train task. In the paper, ALBERT also outperforms BERT on standard NLP tasks/datasets (SQUAD, RACE etc), with fewer parameters.</p><h2 id=\"pre-train-cartobert-to-learn-language-representation-from-gojek-bookings-text\">Pre-train CartoBERT to learn language representation from Gojek bookings text</h2><p>Inspired by ALBERT’s lightweight model and performance, we developed CartoBERT, Gojek’s very own pickup point name recognition model, based on ALBERT’s architecture.</p><p>As illustrated below, the uncased CartoBERT is pre-trained on Gojek’s own masked bookings text corpus of about 200 million sentences. Booking text is first pre-processed for data masking to mask all customer sensitive information, language detection, text normalisation (including text cleaning, slang, abbreviation transformations, lowercase transformation and emoji removal). The pre-processed text is used to build subword vocabularies which handles Out-Of-Vocabulary (OOV) tokens that could be decomposed to frequent subword patterns. CartoBERT tokenizer is then created with the subword vocabularies and further used to encode and tokenize the same preprocessed bookings text to form pre-trained input files.</p><p>Same as ALBERT, the model is pre-trained to ‘understand’ Gojek’s bookings text using Masked Language Model — which predicts randomly masked tokens in input sentences — and Sentence Order Prediction tasks, which predicts the order of input sentences pair.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/1386/1*STaqWssxlYPhFaDulLwJzg.png\" class=\"kg-image\"></figure><h2 id=\"fine-tuning-cartobert-to-extract-pickup-point-names-from-gojek-bookings-text\">Fine-tuning CartoBERT to extract pickup point names from Gojek bookings text</h2><p>With the huge amount of bookings text we have at Gojek, now CartoBERT can better ‘understand’ past bookings text. Theoretically, it ‘understands’ every word of a booking text sentence.</p><p>For every token in the input sentence, CartoBERT will output a 768-dimension vector (we use the default hidden layer size of the ALBERT base model in CartoBERT, however this is configurable) from last transformer encoder layer, and we use that to represent CartoBERT’s ‘understanding’ of the token’s meaning in the sentence context for fine-tune step.</p><p>As illustrated in the diagram below, while fine-tuning CartoBERT for pickup point name recognition, we replace the Masked Language Model and Sequence Order Prediction layers from CartoBERT in pre-train step with token classification layer. The token classification layer learns to predict the probability of a token belonging to a pickup point name, with the final token representation output from CartoBERT transformer layers, from labelled training data created with bookings text sentences, and corresponding pickup point names. Here, we use weighted cross entropy loss to deal with class imbalance, as tokens tagged to pickup point names are a minority.</p><p></p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/1526/1*WO1LRHQPqAqzpLBMMl-NuA.png\" class=\"kg-image\"></figure><p>With this, CartoBERT is fine-tuned to extract pickup point names from bookings text sentences, if any.</p><h2 id=\"how-does-the-model-perform\">How does the model perform?</h2><p>CartoBERT gives a lift of more than 25% in pickup point name accuracy to ~93% accuracy, which is measured as the percentage of valid pick up point names out of generated names. With this high accuracy, we have achieved full scalability of automatic generation for named pickup points to quickly cover multiple geographies without heavy reliance on human inputs.</p><h1 id=\"what-s-next\">What’s next?</h1><p>We are not stopping here and are exploring using active learning to further improve CartoBERT. With active learning, we only flag out uncertain predictions, which are measured as sentence level least token probability[3] for human labelling. We then use human-curated data as feedback for model learning. In this way, we can improve model learning efficiency with minimum labelling effort.</p><p>What’s more, with the success of CartoBERT, we are considering pre-training and open sourcing a general Indonesia Bahasa ALBERT model with Indonesia open corpus from wiki, news, Twitter etc. Currently, the options for open-sourced language model in Indonesia Bahasa are very limited, only pre-trained static word embeddings such as word2vec, fasttext etc are available. It would be beneficial to the community if we have a good state-of-the-art attention-based transformer model for the language. Stay tuned for more updates from the Cartography Data Science team. ?</p><p>Leave a ? if you liked what you read. Ping me with suggestions and feedback.</p><p>Thanks to all the amazing people who contributed to this post: Tan Funan, Zane Lim, Dang Le, Lijuan Chia, Bani Widyatmiko, Maureen Koha, Ringga Saputra, Nur Izzahudinr, Sandya Ardi, Yeni Primasari, Ardya Dipta.</p><hr><p><strong>References</strong></p><p>[1] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Devlin%2C+J\" rel=\"noopener\">J. Devlin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+M\" rel=\"noopener\">M. Chang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K\" rel=\"noopener\">K. Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toutanova%2C+K\" rel=\"noopener\">K. Toutanova</a>: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.<br><a href=\"https://arxiv.org/abs/1810.04805\" rel=\"noopener\">arXiv:1810.04805</a> (2018)</p><p>[2] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+Z\" rel=\"noopener\">Z. Lan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M\" rel=\"noopener\">M. Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Goodman%2C+S\" rel=\"noopener\">S. Goodman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gimpel%2C+K\" rel=\"noopener\">K. Gimpel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+P\" rel=\"noopener\">P. Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Soricut%2C+R\" rel=\"noopener\">R. Soricut</a>: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. <a href=\"https://arxiv.org/abs/1909.11942\" rel=\"noopener\">arXiv:1909.11942</a> (2019)</p><p>[3] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M\" rel=\"noopener\">M.Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Z\" rel=\"noopener\">Z. Tu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z\" rel=\"noopener\">Z. Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X\" rel=\"noopener\">X. Xu</a>: LTP: A New Active Learning Strategy for Bert-CRF Based Named Entity Recognition. <a href=\"https://arxiv.org/abs/2001.02524\" rel=\"noopener\">arXiv:2001.02524</a> (2020)</p><hr><p>Liked what you read? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter</a> to have our latest stories delivered straight to your inbox!</p>","url":"https://gojek-ghost.zysk.in/how-gojek-uses-nlp-to-name-pickup-locations-at-scale-2/","canonical_url":null,"uuid":"51dd4492-b728-4b37-8c7f-41fd41619f7a","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb0f8af5524cd001e7391f4","reading_time":6}},{"node":{"id":"Ghost__Post__5ec2ca217aa22c4066f83b64","title":"How Gojek Uses NLP to Name Pickup Locations at Scale","slug":"how-gojek-uses-nlp-to-name-pickup-locations-at-scale","featured":false,"feature_image":"https://gojek-ghost.zysk.in/content/images/2020/05/1_dFalBje-vQCkEY8Zrq9P5g--1-.jpeg","excerpt":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","custom_excerpt":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","visibility":"public","created_at_pretty":"18 May, 2020","published_at_pretty":"01 May, 2020","updated_at_pretty":"18 May, 2020","created_at":"2020-05-18T23:17:13.000+05:30","published_at":"2020-05-01T09:30:00.000+05:30","updated_at":"2020-05-18T23:22:43.000+05:30","meta_title":null,"meta_description":"Introducing CartoBERT, a Natural Language Processing (NLP) model developed by Gojek’s Cartography Data Science team.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Li Xiaohong\n\nWhen our customers want to use our ride hailing products like GoRide and GoCar,\nthey are presented with convenient, clearly named pickup points nearby. Here’s\nan example:\n\nThis saves customers the hassle of calling the driver partner, explaining where\nthey are, what colour clothes they are wearing, and so on. Our pickup points are\ndesigned to make lives easier for both customers and driver partners.\n\nThis is possible because the pickup points shown on the app are popular pickup\nlocations around the area. What’s more, the pickup point names are displayed\nexactly how customers driver partners usually refer to them.\n\nBut how do we manage to name so many pickup points accurately, and at scale?\n\nWe use past booking locations and their associated chat logs to discover named\npickup points. As our previous research has explained, we first perform \nclustering\n[https://blog.gojekengineering.com/fantastic-drivers-and-how-to-find-them-a88239ef3b29] \non historical bookings to form potential pickup points, then we use a language\nmodel\n[https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03] \nto select the best name. Here, we explain how we improved upon the previous\nstatistical language model with a state-of-the-art NLP model, which makes the\nentire naming exercise fully scalable. This is the magic behind all the pickup\npoints seen on the Gojek app.\n\nHow can we learn better?\nAs explained in our previous post, our original statistical language model\nselects the best pickup point name from the most probable n-grams extracted from\nbookings text. However, such a statistical language model doesn’t ‘understand’\nthe meaning of the texts, it simply chooses phrases with high frequencies\nwithout knowing the semantics. Sometimes it throws street names, sometimes even\ncommon phrases with no information about location. We have to manually check\neverything to make sure it reflects the right POI, before it appears on the app.\n\nThis creates a challenge — especially if we want to quickly expand the\nfrictionless pickup experience to customers across in new geographies. Hence, we\ndecided to go a step further with a deep-learning NLP model that ‘understands’\nand ‘learns’ to differentiate what is a valid pickup point name.\n\n> At Gojek, we never stop thinking and always go a step further\nMeet CartoBERT 💚\nOne of the most recent and impactful breakthroughs NLP was the publication of\nBERT[1] — a contextual language representation with transformer models — by\nGoogle in late 2018. It obtained state-of-the-art results on a wide array of NLP\ntasks. In the 2019, many NLP researches were influenced by BERT, including\nXLNet, RoBERTa, ERNIE etc.\n\nBERT Explained\nBERT, or Bidirectional Encoder Representations from Transformers, is composed of\nan embedding layer, followed by groups of transformer layers.\n\nBERT Architecture, Source [https://arxiv.org/pdf/1810.04805v1.pdf]Every word\n(token) in the input sentence will first get encoded into its embedding\nrepresentations in the embedding layer, and then go through bidirectional\ntransformer encoder layers. Every encoder layer will perform the multi-head\nattention computation on the token representation from the previous layer to\ncreate a new intermediate representation, which is then output to the next\nlayer. The output from the final layer is the contextual representation of the\ninput token. A pooled sentence level representation combining all token\nrepresentations could be created if needed by specific downstream tasks.\n\nWith the final contextual representations at either token or sentence level, a\npre-trained BERT on large unlabelled text corpus, could be further extended to a\nwide variety of NLP tasks, such as text classification, question answering,\nNamed Entity Recognition (NER) etc.\n\nALBERT[2], published by Google in Sep 2019, improved on BERT with embedding\nparameter factorisation and cross layer parameter sharing to reduce the number\nof parameters (by 9 times for base model). It also uses sequence order\nprediction instead of next sentence prediction for the pre-train task. In the\npaper, ALBERT also outperforms BERT on standard NLP tasks/datasets (SQUAD, RACE\netc), with fewer parameters.\n\nPre-train CartoBERT to learn language representation from Gojek bookings text\nInspired by ALBERT’s lightweight model and performance, we developed CartoBERT,\nGojek’s very own pickup point name recognition model, based on ALBERT’s\narchitecture.\n\nAs illustrated below, the uncased CartoBERT is pre-trained on Gojek’s own masked\nbookings text corpus of about 200 million sentences. Booking text is first\npre-processed for data masking to mask all customer sensitive information,\nlanguage detection, text normalisation (including text cleaning, slang,\nabbreviation transformations, lowercase transformation and emoji removal). The\npre-processed text is used to build subword vocabularies which handles\nOut-Of-Vocabulary (OOV) tokens that could be decomposed to frequent subword\npatterns. CartoBERT tokenizer is then created with the subword vocabularies and\nfurther used to encode and tokenize the same preprocessed bookings text to form\npre-trained input files.\n\nSame as ALBERT, the model is pre-trained to ‘understand’ Gojek’s bookings text\nusing Masked Language Model — which predicts randomly masked tokens in input\nsentences — and Sentence Order Prediction tasks, which predicts the order of\ninput sentences pair.\n\n\nCartoBERT Pre-trainFine-tuning CartoBERT to extract pickup point names from\nGojek bookings text\nWith the huge amount of bookings text we have at Gojek, now CartoBERT can better\n‘understand’ past bookings text. Theoretically, it ‘understands’ every word of a\nbooking text sentence.\n\nFor every token in the input sentence, CartoBERT will output a 768-dimension\nvector (we use the default hidden layer size of the ALBERT base model in\nCartoBERT, however this is configurable) from last transformer encoder layer,\nand we use that to represent CartoBERT’s ‘understanding’ of the token’s meaning\nin the sentence context for fine-tune step.\n\nAs illustrated in the diagram below, while fine-tuning CartoBERT for pickup\npoint name recognition, we replace the Masked Language Model and Sequence Order\nPrediction layers from CartoBERT in pre-train step with token classification\nlayer. The token classification layer learns to predict the probability of a\ntoken belonging to a pickup point name, with the final token representation\noutput from CartoBERT transformer layers, from labelled training data created\nwith bookings text sentences, and corresponding pickup point names. Here, we use\nweighted cross entropy loss to deal with class imbalance, as tokens tagged to\npickup point names are a minority.\n\nCartoBERT Fine-tuneWith this, CartoBERT is fine-tuned to extract pickup point\nnames from bookings text sentences, if any.\n\nHow does the model perform?\nCartoBERT gives a lift of more than 25% in pickup point name accuracy to ~93%\naccuracy, which is measured as the percentage of valid pick up point names out\nof generated names. With this high accuracy, we have achieved full scalability\nof automatic generation for named pickup points to quickly cover multiple\ngeographies without heavy reliance on human inputs.\n\nWhat’s next?\nWe are not stopping here and are exploring using active learning to further\nimprove CartoBERT. With active learning, we only flag out uncertain predictions,\nwhich are measured as sentence level least token probability[3] for human\nlabelling. We then use human-curated data as feedback for model learning. In\nthis way, we can improve model learning efficiency with minimum labelling\neffort.\n\nWhat’s more, with the success of CartoBERT, we are considering pre-training and\nopen sourcing a general Indonesia Bahasa ALBERT model with Indonesia open corpus\nfrom wiki, news, Twitter etc. Currently, the options for open-sourced language\nmodel in Indonesia Bahasa are very limited, only pre-trained static word\nembeddings such as word2vec, fasttext etc are available. It would be beneficial\nto the community if we have a good state-of-the-art attention-based transformer\nmodel for the language. Stay tuned for more updates from the Cartography Data\nScience team. 🙌\n\nLeave a 👏 if you liked what you read. Ping me with suggestions and feedback.\n\nThanks to all the amazing people who contributed to this post: Tan Funan, Zane\nLim, Dang Le, Lijuan Chia, Bani Widyatmiko, Maureen Koha, Ringga Saputra, Nur\nIzzahudinr, Sandya Ardi, Yeni Primasari, Ardya Dipta.\n\n\n--------------------------------------------------------------------------------\n\nReferences\n[1] J. Devlin [https://arxiv.org/search/cs?searchtype=author&query=Devlin%2C+J], \nM. Chang [https://arxiv.org/search/cs?searchtype=author&query=Chang%2C+M], K.\nLee [https://arxiv.org/search/cs?searchtype=author&query=Lee%2C+K], K. Toutanova\n[https://arxiv.org/search/cs?searchtype=author&query=Toutanova%2C+K]: BERT:\nPre-training of Deep Bidirectional Transformers for Language Understanding.\narXiv:1810.04805 [https://arxiv.org/abs/1810.04805] (2018)\n\n[2] Z. Lan [https://arxiv.org/search/cs?searchtype=author&query=Lan%2C+Z], M.\nChen [https://arxiv.org/search/cs?searchtype=author&query=Chen%2C+M], S. Goodman\n[https://arxiv.org/search/cs?searchtype=author&query=Goodman%2C+S], K. Gimpel\n[https://arxiv.org/search/cs?searchtype=author&query=Gimpel%2C+K], P. Sharma\n[https://arxiv.org/search/cs?searchtype=author&query=Sharma%2C+P], R. Soricut\n[https://arxiv.org/search/cs?searchtype=author&query=Soricut%2C+R]: ALBERT: A\nLite BERT for Self-supervised Learning of Language Representations. \narXiv:1909.11942 [https://arxiv.org/abs/1909.11942] (2019)\n\n[3] M.Liu [https://arxiv.org/search/cs?searchtype=author&query=Liu%2C+M], Z. Tu\n[https://arxiv.org/search/cs?searchtype=author&query=Tu%2C+Z], Z. Wang\n[https://arxiv.org/search/cs?searchtype=author&query=Wang%2C+Z], X. Xu\n[https://arxiv.org/search/cs?searchtype=author&query=Xu%2C+X]: LTP: A New Active\nLearning Strategy for Bert-CRF Based Named Entity Recognition. arXiv:2001.02524\n[https://arxiv.org/abs/2001.02524] (2020)\n\n\n--------------------------------------------------------------------------------\n\nLiked what you read? Sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] to have our latest stories\ndelivered straight to your inbox!","html":"<p>By Li Xiaohong</p><p>When our customers want to use our ride hailing products like GoRide and GoCar, they are presented with convenient, clearly named pickup points nearby. Here’s an example:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/180/1*msS7z4IN06LVM0XvClmmPQ.gif\" class=\"kg-image\"></figure><p>This saves customers the hassle of calling the driver partner, explaining where they are, what colour clothes they are wearing, and so on. Our pickup points are designed to make lives easier for both customers and driver partners.</p><p>This is possible because the pickup points shown on the app are popular pickup locations around the area. What’s more, the pickup point names are displayed exactly how customers driver partners usually refer to them.</p><p><strong><strong>But how do we manage to name so many pickup points accurately, and at scale?</strong></strong></p><p>We use past booking locations and their associated chat logs to discover named pickup points. As our previous research has explained, we first perform <a href=\"https://blog.gojekengineering.com/fantastic-drivers-and-how-to-find-them-a88239ef3b29\" rel=\"noopener\">clustering</a> on historical bookings to form potential pickup points, then we use a <a href=\"https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03\" rel=\"noopener\">language model</a> to select the best name. Here, we explain how we improved upon the previous statistical language model with a state-of-the-art NLP model, which makes the entire naming exercise fully scalable. This is the magic behind all the pickup points seen on the Gojek app.</p><h1 id=\"how-can-we-learn-better\">How can we learn better?</h1><p>As explained in our previous post, our original statistical language model selects the best pickup point name from the most probable n-grams extracted from bookings text. However, such a statistical language model doesn’t ‘understand’ the meaning of the texts, it simply chooses phrases with high frequencies without knowing the semantics. Sometimes it throws street names, sometimes even common phrases with no information about location. We have to manually check everything to make sure it reflects the right POI, before it appears on the app.</p><p>This creates a challenge — especially if we want to quickly expand the frictionless pickup experience to customers across in new geographies. Hence, we decided to go a step further with a deep-learning NLP model that ‘understands’ and ‘learns’ to differentiate what is a valid pickup point name.</p><blockquote><em><em>At Gojek, we never stop thinking and always go a step further</em></em></blockquote><h1 id=\"meet-cartobert-\">Meet CartoBERT 💚</h1><p>One of the most recent and impactful breakthroughs NLP was the publication of BERT[1] — a contextual language representation with transformer models — by Google in late 2018. It obtained state-of-the-art results on a wide array of NLP tasks. In the 2019, many NLP researches were influenced by BERT, including XLNet, RoBERTa, ERNIE etc.</p><h2 id=\"bert-explained\">BERT Explained</h2><p>BERT, or Bidirectional Encoder Representations from Transformers, is composed of an embedding layer, followed by groups of transformer layers.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1226/1*qHFXdPcW_3UkLEsRJy2FRg.png\" class=\"kg-image\"><figcaption>BERT Architecture, <a href=\"https://arxiv.org/pdf/1810.04805v1.pdf\" rel=\"noopener\">Source</a></figcaption></figure><p>Every word (token) in the input sentence will first get encoded into its embedding representations in the embedding layer, and then go through bidirectional transformer encoder layers. Every encoder layer will perform the multi-head attention computation on the token representation from the previous layer to create a new intermediate representation, which is then output to the next layer. The output from the final layer is the contextual representation of the input token. A pooled sentence level representation combining all token representations could be created if needed by specific downstream tasks.</p><p>With the final contextual representations at either token or sentence level, a pre-trained BERT on large unlabelled text corpus, could be further extended to a wide variety of NLP tasks, such as text classification, question answering, Named Entity Recognition (NER) etc.</p><p>ALBERT[2], published by Google in Sep 2019, improved on BERT with embedding parameter factorisation and cross layer parameter sharing to reduce the number of parameters (by 9 times for base model). It also uses sequence order prediction instead of next sentence prediction for the pre-train task. In the paper, ALBERT also outperforms BERT on standard NLP tasks/datasets (SQUAD, RACE etc), with fewer parameters.</p><h2 id=\"pre-train-cartobert-to-learn-language-representation-from-gojek-bookings-text\">Pre-train CartoBERT to learn language representation from Gojek bookings text</h2><p>Inspired by ALBERT’s lightweight model and performance, we developed CartoBERT, Gojek’s very own pickup point name recognition model, based on ALBERT’s architecture.</p><p>As illustrated below, the uncased CartoBERT is pre-trained on Gojek’s own masked bookings text corpus of about 200 million sentences. Booking text is first pre-processed for data masking to mask all customer sensitive information, language detection, text normalisation (including text cleaning, slang, abbreviation transformations, lowercase transformation and emoji removal). The pre-processed text is used to build subword vocabularies which handles Out-Of-Vocabulary (OOV) tokens that could be decomposed to frequent subword patterns. CartoBERT tokenizer is then created with the subword vocabularies and further used to encode and tokenize the same preprocessed bookings text to form pre-trained input files.</p><p>Same as ALBERT, the model is pre-trained to ‘understand’ Gojek’s bookings text using Masked Language Model — which predicts randomly masked tokens in input sentences — and Sentence Order Prediction tasks, which predicts the order of input sentences pair.<br></p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1386/1*STaqWssxlYPhFaDulLwJzg.png\" class=\"kg-image\"><figcaption>CartoBERT Pre-train</figcaption></figure><h2 id=\"fine-tuning-cartobert-to-extract-pickup-point-names-from-gojek-bookings-text\">Fine-tuning CartoBERT to extract pickup point names from Gojek bookings text</h2><p>With the huge amount of bookings text we have at Gojek, now CartoBERT can better ‘understand’ past bookings text. Theoretically, it ‘understands’ every word of a booking text sentence.</p><p>For every token in the input sentence, CartoBERT will output a 768-dimension vector (we use the default hidden layer size of the ALBERT base model in CartoBERT, however this is configurable) from last transformer encoder layer, and we use that to represent CartoBERT’s ‘understanding’ of the token’s meaning in the sentence context for fine-tune step.</p><p>As illustrated in the diagram below, while fine-tuning CartoBERT for pickup point name recognition, we replace the Masked Language Model and Sequence Order Prediction layers from CartoBERT in pre-train step with token classification layer. The token classification layer learns to predict the probability of a token belonging to a pickup point name, with the final token representation output from CartoBERT transformer layers, from labelled training data created with bookings text sentences, and corresponding pickup point names. Here, we use weighted cross entropy loss to deal with class imbalance, as tokens tagged to pickup point names are a minority.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1526/1*WO1LRHQPqAqzpLBMMl-NuA.png\" class=\"kg-image\"><figcaption>CartoBERT Fine-tune</figcaption></figure><p>With this, CartoBERT is fine-tuned to extract pickup point names from bookings text sentences, if any.</p><h2 id=\"how-does-the-model-perform\">How does the model perform?</h2><p>CartoBERT gives a lift of more than 25% in pickup point name accuracy to ~93% accuracy, which is measured as the percentage of valid pick up point names out of generated names. With this high accuracy, we have achieved full scalability of automatic generation for named pickup points to quickly cover multiple geographies without heavy reliance on human inputs.</p><h1 id=\"what-s-next\">What’s next?</h1><p>We are not stopping here and are exploring using active learning to further improve CartoBERT. With active learning, we only flag out uncertain predictions, which are measured as sentence level least token probability[3] for human labelling. We then use human-curated data as feedback for model learning. In this way, we can improve model learning efficiency with minimum labelling effort.</p><p>What’s more, with the success of CartoBERT, we are considering pre-training and open sourcing a general Indonesia Bahasa ALBERT model with Indonesia open corpus from wiki, news, Twitter etc. Currently, the options for open-sourced language model in Indonesia Bahasa are very limited, only pre-trained static word embeddings such as word2vec, fasttext etc are available. It would be beneficial to the community if we have a good state-of-the-art attention-based transformer model for the language. Stay tuned for more updates from the Cartography Data Science team. 🙌</p><p>Leave a 👏 if you liked what you read. Ping me with suggestions and feedback.</p><p>Thanks to all the amazing people who contributed to this post: Tan Funan, Zane Lim, Dang Le, Lijuan Chia, Bani Widyatmiko, Maureen Koha, Ringga Saputra, Nur Izzahudinr, Sandya Ardi, Yeni Primasari, Ardya Dipta.</p><hr><h1 id=\"references\">References</h1><p>[1] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Devlin%2C+J\" rel=\"noopener\">J. Devlin</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+M\" rel=\"noopener\">M. Chang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lee%2C+K\" rel=\"noopener\">K. Lee</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Toutanova%2C+K\" rel=\"noopener\">K. Toutanova</a>: BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding.<br><a href=\"https://arxiv.org/abs/1810.04805\" rel=\"noopener\">arXiv:1810.04805</a> (2018)</p><p>[2] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Lan%2C+Z\" rel=\"noopener\">Z. Lan</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M\" rel=\"noopener\">M. Chen</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Goodman%2C+S\" rel=\"noopener\">S. Goodman</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Gimpel%2C+K\" rel=\"noopener\">K. Gimpel</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Sharma%2C+P\" rel=\"noopener\">P. Sharma</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Soricut%2C+R\" rel=\"noopener\">R. Soricut</a>: ALBERT: A Lite BERT for Self-supervised Learning of Language Representations. <a href=\"https://arxiv.org/abs/1909.11942\" rel=\"noopener\">arXiv:1909.11942</a> (2019)</p><p>[3] <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+M\" rel=\"noopener\">M.Liu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+Z\" rel=\"noopener\">Z. Tu</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Wang%2C+Z\" rel=\"noopener\">Z. Wang</a>, <a href=\"https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+X\" rel=\"noopener\">X. Xu</a>: LTP: A New Active Learning Strategy for Bert-CRF Based Named Entity Recognition. <a href=\"https://arxiv.org/abs/2001.02524\" rel=\"noopener\">arXiv:2001.02524</a> (2020)</p><hr><p>Liked what you read? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter</a> to have our latest stories delivered straight to your inbox!</p>","url":"https://gojek-ghost.zysk.in/how-gojek-uses-nlp-to-name-pickup-locations-at-scale/","canonical_url":null,"uuid":"b4ebe040-85ec-4818-aff5-0dd14c44c596","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec2ca217aa22c4066f83b64","reading_time":6}},{"node":{"id":"Ghost__Post__5e8efa6b5cbf39001e28e7fa","title":"How We Do Delightful Customer Pickups","slug":"how-we-do-delightful-customer-pickups","featured":false,"feature_image":"https://res-1.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-Do-Delightful-Customer-Pickups-.jpg","excerpt":"The little things that make getting where you need to go that much better.","custom_excerpt":"The little things that make getting where you need to go that much better.","visibility":"public","created_at_pretty":"09 April, 2020","published_at_pretty":"07 April, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-04-09T16:05:23.000+05:30","published_at":"2020-04-07T09:30:00.000+05:30","updated_at":"2020-05-12T11:51:53.000+05:30","meta_title":"How We Do Delightful Customer Pickups","meta_description":"The little things that make getting where you need to go that much better.","og_description":null,"og_image":"https://res-1.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-Do-Delightful-Customer-Pickups-.jpg","og_title":null,"twitter_description":null,"twitter_image":"https://res-1.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-Do-Delightful-Customer-Pickups-.jpg","twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Design","slug":"design","description":"Chronicles of the design journeys behind Gojek products, case studies, and insights on UI/UX design.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Design","slug":"design","description":"Chronicles of the design journeys behind Gojek products, case studies, and insights on UI/UX design.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Did you know Gojek’s Transport team (which oversees the ride hailing products of\nour SuperApp) has a ‘Pickup Experience’ pod?\n\nNo, we’re not helping you get better dates, you’re on your own there. ?\n\nI’m talking about the customer pickup experience on booking a ride with us on\nGoRide (2-wheeler taxis) and GoCar (4-wheeler taxis).\n\nYou know the feeling. The feeling of going to a big mall in an unfamiliar place,\ntrying to book a ride, but not knowing which is the most convenient pickup spot.\n\nDo I try the north entrance? Oh wait, there’s a one-way there, might need to\nwait a long while.\n\nAh, I got a driver but I don’t know how to tell her which side I am on. Wait,\nthere’s a Starbucks here. I’m in front of Starbucks!\n\nOh, you’re near McDonalds? Wait, maybe I can just come to you. But, how do I get\nto McDonalds now? ?‍♂️\n\n> Yeah, we’ve all been there.\nPickup points may seem like trivial things, but when you operate on a scale of\nmillions of orders per day, smoother pickups which require less coordination\n(and time) mean our customers get places faster, and our driver partners earn\nmore.\n\nIn this post, we’ll talk about how Gojek improved the pickup experience for\ncustomers and partners using Points of Interest (POI) — like a mall — and then\nstreamlined pickups around these areas using Pre-Defined Pickup Points (PPOI).\n\nThe Breakdown\nMany of the cities Gojek operates in are highly congested urban settings, where\nlocations are often not properly labelled on maps and pickup points can be hard\nto determine. This initially led to a lot of additional coordination between\npartners and customers over the phone, which is not the best use of anyone’s\ntime.\n\nIn order to streamline this process, we first began identifying POIs in popular\nareas. Once this was done, we located areas around these landmarks where lots of\npickups happened, and began suggesting them as pre-defined pickup points to our\nusers. Making these suggestions within the app was the first step in reducing\nthe cognitive load associated with pickups. (If you’d like to know how we\nidentified these spots. Check out this post\n[https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03]\n).\n\nOur next step in the process was to provide customers some details about the\nquality of these locations. We started showing them more details about the\npickup points near them—are they sheltered from weather, in case the driver\nneeds a couple of minutes to reach them? If it’s night, is it well-lit?\n\nBut wait, there’s more…\nPPOIs have contributed hugely to streamlining pickups and making life easier for\nour stakeholders. But what if the customer is new to an area and cannot easily\nidentify the locations we’re suggesting? Could we do more?\n\nOf course we could.\n\nUp until recently, pickup points showed up as map pins on the customer app based\non their location. We decided to add some additional functionality, starting\nwith images.\n\nIf you’re making a booking from an unfamiliar location, or have unreliable GPS\nconnectivity, how do you know you’re at the correct point suggested by the Gojek\napp? By adding images to the corresponding pins, we gave our customers the\nadvantage of being able to visually confirm they were in the right place.\n\nWith the two-factor confirmation of GPS pin and visual, our customers could\nconfirm their pickup point, and wait in peace. Not bad, eh?\n\nAt this point, our app could cater reliably to most of our users, whether it was\nregulars who already had a lot of context on ideal pickup spots or users who\nwere new to an area. However, we wanted to go even further to make a more\nairtight solution. What if a user was near a pickup point, but did not know how\nto reach it?\n\nThis was a problem with significant impact, as a user walking a short distance\nto a nearby well-served pickup point would be significantly faster than a driver\npartner navigating to an unfamiliar location nearby. Driver partners would\npotentially run into obstacles like one ways, or areas in Jakarta where odd-even\nrules are implemented.\n\nHowever, we didn’t want to put the onus of navigating to the PPOI on the user.\nThe least we could do in return for their cooperation was help them with\ndirections.\n\nSo that’s what we did.\n\nBeing able to leverage technology to help users book rides is an achievement in\nitself, one we’re proud of. But stopping at the solution is not how Super Apps\nare built. We exist to solve problems, and then delighting our users further\nthrough ease of use.\n\nFrom vague pickup points defined by often inaccurate GPS pings, our pickup\nexperience had evolved to the point where a user with zero knowledge of an area\ncould easily identify the best location nearby for smooth pickup, understand\nwhether it was convenient to wait at, navigate there, and confirm their arrival\nby sight. Utter delight. ?\n\nThat said, all our bookings don’t happen in dense urban areas with defined\nPPOIs. We’re working towards having PPOIs in most major areas, but sometimes,\ngood old chat-based coordination is still the default fallback.\n\nWe did learn a thing or two from our experience of putting images on PPOIs, so\nwe worked with Gojek’s Platform team (which handles our chat functionality), and\nbaked in the ability to share images in Driver-to-Customer chat. Even if all\nelse fails, our customers could still click a picture of their current location,\nand share it with our partners to help them identify it.\n\nIt’s safe to say that putting in the effort to help our customers get to their\nrides easily has paid off.\n\n> In the areas where we’ve deployed these features, we’ve seen pickup accuracy\ndouble on average. ✌\nWhat’s next?\nThere’s more?\n\nThere’s always more.\n\nEven as we continue to roll out this functionality across more regions we\noperate in, we’re working towards making it better—by allowing our users to give\nus feedback on how accurate our images/directions were, and even upload PPOI\nimages themselves.\n\nWe’ll keep you updated on how we fare. In the meantime, follow us for more\nstories, and sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]! ?","html":"<p>Did you know Gojek’s Transport team (which oversees the ride hailing products of our SuperApp) has a ‘Pickup Experience’ pod?</p><p><em><em>No, we’re not helping you get better dates, you’re on your own there. </em></em>?</p><p>I’m talking about the customer pickup experience on booking a ride with us on GoRide (2-wheeler taxis) and GoCar (4-wheeler taxis).</p><p>You know the feeling. The feeling of going to a big mall in an unfamiliar place, trying to book a ride, but not knowing which is the most convenient pickup spot.</p><p><em><em>Do I try the north entrance? Oh wait, there’s a one-way there, might need to wait a long while.</em></em></p><p><em><em>Ah, I got a driver but I don’t know how to tell her which side I am on. Wait, there’s a Starbucks here. I’m in front of Starbucks!</em></em></p><p><em><em>Oh, you’re near McDonalds? Wait, maybe I can just come to you. But, how do I get to McDonalds now?</em></em> ?‍♂️</p><blockquote>Yeah, we’ve all been there.</blockquote><p>Pickup points may seem like trivial things, but when you operate on a scale of millions of orders per day, smoother pickups which require less coordination (and time) mean our customers get places faster, and our driver partners earn more.</p><p>In this post, we’ll talk about how Gojek improved the pickup experience for customers and partners using Points of Interest (POI) — like a mall — and then streamlined pickups around these areas using Pre-Defined Pickup Points (PPOI).</p><h2 id=\"the-breakdown\">The Breakdown</h2><p>Many of the cities Gojek operates in are highly congested urban settings, where locations are often not properly labelled on maps and pickup points can be hard to determine. This initially led to a lot of additional coordination between partners and customers over the phone, which is not the best use of anyone’s time.</p><p>In order to streamline this process, we first began identifying POIs in popular areas. Once this was done, we located areas around these landmarks where lots of pickups happened, and began suggesting them as pre-defined pickup points to our users. Making these suggestions within the app was the first step in reducing the cognitive load associated with pickups. (If you’d like to know how we identified these spots. Check out <a href=\"https://blog.gojekengineering.com/how-i-met-my-gojek-driver-without-a-single-call-95041f4fdd03\" rel=\"noopener\">this post</a>).</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-3.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-do.gif\" class=\"kg-image\"></figure><p>Our next step in the process was to provide customers some details about the quality of these locations. We started showing them more details about the pickup points near them—are they sheltered from weather, in case the driver needs a couple of minutes to reach them? If it’s night, is it well-lit?</p><h2 id=\"but-wait-there-s-more-\">But wait, there’s more…</h2><p>PPOIs have contributed hugely to streamlining pickups and making life easier for our stakeholders. But what if the customer is new to an area and cannot easily identify the locations we’re suggesting? Could we do more?</p><p>Of course we could.</p><p>Up until recently, pickup points showed up as map pins on the customer app based on their location. We decided to add some additional functionality, starting with images.</p><p>If you’re making a booking from an unfamiliar location, or have unreliable GPS connectivity, how do you know you’re at the correct point suggested by the Gojek app? By adding images to the corresponding pins, we gave our customers the advantage of being able to visually confirm they were in the right place.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-do-1.gif\" class=\"kg-image\"></figure><p>With the two-factor confirmation of GPS pin and visual, our customers could confirm their pickup point, and wait in peace. Not bad, eh?</p><p>At this point, our app could cater reliably to most of our users, whether it was regulars who already had a lot of context on ideal pickup spots or users who were new to an area. However, we wanted to go even further to make a more airtight solution. What if a user was near a pickup point, but did not know how to reach it?</p><p>This was a problem with significant impact, as a user walking a short distance to a nearby well-served pickup point would be significantly faster than a driver partner navigating to an unfamiliar location nearby. Driver partners would potentially run into obstacles like one ways, or areas in Jakarta where odd-even rules are implemented.</p><p>However, we didn’t want to put the onus of navigating to the PPOI on the user. The least we could do in return for their cooperation was help them with directions.</p><p>So that’s what we did.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://res-1.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/How-We-do-2.gif\" class=\"kg-image\"></figure><p>Being able to leverage technology to help users book rides is an achievement in itself, one we’re proud of. But stopping at the solution is not how Super Apps are built. We exist to solve problems, and then delighting our users further through ease of use.</p><p>From vague pickup points defined by often inaccurate GPS pings, our pickup experience had evolved to the point where a user with zero knowledge of an area could easily identify the best location nearby for smooth pickup, understand whether it was convenient to wait at, navigate there, and confirm their arrival by sight. Utter delight. ?</p><p>That said, all our bookings don’t happen in dense urban areas with defined PPOIs. We’re working towards having PPOIs in most major areas, but sometimes, good old chat-based coordination is still the default fallback.</p><p>We did learn a thing or two from our experience of putting images on PPOIs, so we worked with Gojek’s Platform team (which handles our chat functionality), and baked in the ability to share images in Driver-to-Customer chat. Even if all else fails, our customers could still click a picture of their current location, and share it with our partners to help them identify it.</p><p>It’s safe to say that putting in the effort to help our customers get to their rides easily has paid off.</p><blockquote><em><em>In the areas where we’ve deployed these features, we’ve seen pickup accuracy double on average. <em>✌</em></em></em></blockquote><h2 id=\"what-s-next\">What’s next?</h2><p><em><em>There’s more?</em></em></p><p><em><em>There’s always more.</em></em></p><p>Even as we continue to roll out this functionality across more regions we operate in, we’re working towards making it better—by allowing our users to give us feedback on how accurate our images/directions were, and even upload PPOI images themselves.</p><p>We’ll keep you updated on how we fare. In the meantime, follow us for more stories, and <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">sign up for our newsletter</a>! ?</p>","url":"https://gojek-ghost.zysk.in/how-we-do-delightful-customer-pickups/","canonical_url":null,"uuid":"96625509-a74c-4bd5-a090-f45a04166e62","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5e8efa6b5cbf39001e28e7fa","reading_time":5}},{"node":{"id":"Ghost__Post__5eb128b6f7c7da001effcd8c","title":"Gojek’s Best Practices to Work From Home [Beta]","slug":"gojeks-best-practices-to-work-from-home-beta","featured":true,"feature_image":"https://res-3.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_g1gfRNDqLKJWtAwURoFgaw.jpg","excerpt":"How to come to terms with ‘working from home’, and a few guidelines to help with the transition.","custom_excerpt":"How to come to terms with ‘working from home’, and a few guidelines to help with the transition.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"16 March, 2020","updated_at_pretty":"12 May, 2020","created_at":"2020-05-05T14:19:58.000+05:30","published_at":"2020-03-16T09:30:00.000+05:30","updated_at":"2020-05-12T11:52:22.000+05:30","meta_title":null,"meta_description":"How to come to terms with ‘working from home’, and a few guidelines to help with the transition.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Culture","slug":"culture","description":"Writings on work culture at Gojek—explained through the lens of engineering and product decisions, and the experiences of GoTroops.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Culture","slug":"culture","description":"Writings on work culture at Gojek—explained through the lens of engineering and product decisions, and the experiences of GoTroops.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Kevin Aluwi\n\nIt’s been a trying couple of weeks since the Coronavirus outbreak. As\ngovernments and authorities encourage social distancing, many companies — Gojek\nincluded — have started to put a heightened emphasis on working from home. As an\norganization with a distributed workforce, we have offices in Indonesia,\nSingapore, Vietnam, Thailand, Philippines, and India, a remote strategy has\nalways been embedded in our DNA. This post details some lessons and what we\nthink are ‘best practices’ to follow in a Work from home (WFH) situation.\n\nAt the outset, it’s important to call out a key point: During this time of\nuncertainty, employees may not be at their productive best. There’s a lot of\nanxiety with family and friends, and rightly so. WFH requires high \nAccountability, but also Empathy and Trust. Be mindful, this is a stressful time\nfor everyone. Trust your colleagues to do the best they can given the times.\n\nBefore we begin — context\nGojek has always been mindful of our employees’ health and wellbeing. We have\nunlimited sick leaves, and encourage employees to work where and when they are\nat their productive best. We have proven success — with functional leaders\nworking fully remotely without compromising on effectively launching org-wide\ninitiatives: career ladders, new hiring programs, even setting up an entire new\nfunction. But this is by all means not a comprehensive or a definitive guide.\nThink of this as a ‘beta’ document summarising some lessons in a bid to get\nfeedback from you, our readers. We’re putting this out there so we can learn\ntogether to do better.\n\nIf you think we’ve missed out on something, please leave a comment — will help\nus a long way in fine-tuning our own practices. These are trying times, and we\nwant to do what is right for everyone.\n\n(1)The right environment\nOffice spaces provide designated areas employees start associating with work and\nfocus. This may not be the case in a home environment, so it is important to\nrecreate this space. Some ideal prerequisites include an area with plenty of\nlight, minimal distractions and a comfortable desk and chair.\n\nWorking from home also potentially involves sharing the space with other family\nmembers / housemates. It’s important to set guidelines to indicate when you are\nat work and not to be disturbed — one team member for example set up a plush toy\non a desk as a makeshift ‘Do Not Disturb’ sign!\n\nOnce a setup is established, don’t neglect the importance of taking breaks. The\nabsence of colleagues and social interaction should not lead to long\nuninterrupted sessions. Set a timer to alert you if you’ve been continuously at\nyour desk for over two hours. Take short breaks to stretch your legs. Use the\ntime to also spend time with family, or work on personal projects that require\nthe occasional check-in! There’s a silver lining to every scenario :)\n\nThis whole point might seem obvious and rather trivial, but is critical when you\nwant focus, and don’t have your colleagues to ‘pair’ with you and nudge you.\n\n(2) The right tools\nEnsure the coordination tools used by your organisation / team are installed on\nyour laptop and working properly. At Gojek we use Slack for messaging, Zoom for\nvideo conferencing, and Asana and JIRA for project coordination. Here are a few\nquick tips from our WFH Best Practices\n[https://docs.google.com/document/d/1TPAKV-AowBpODVul5cL73mKN5caN6RQf0wvV_6O5Ees/edit?usp=sharing] \non how best to use them in a remote work scenario:\n\nOver communicate: Set clear expectations and create WFH Rules of Engagement for\nyour team. What cadences need to be synchronous vs. async? Set your Slack status\nto away every time you leave the computer for a break, and update it once you’re\nback. Clearly request responses to critical communications you send, and do the\nsame to confirm you’ve received an update (even Slack’s emoji responses will do,\nas long as there is recorded acknowledgement).\n\nDocument everything: Meetings may become increasingly asynchronous, so it is\nimportant to document all the items discussed and assigned. Record key decisions\nin a centralized decision log. This can be done via written notes hosted in a\ncommon cloud folder, as well as tasks on Asana for accountability. Minimise\ncommunication gaps.\n\nChoose the most high-context communication medium available: A lot gets lost in\ntranslation when you don’t have visual cues. Use video conferencing whenever\npossible. Failing video, (spotty connection) default to a phone call, then chat.\nIn chat, don’t hesitate to use emojis liberally to convey your tone! ?\n\nPro tip: In Zoom preferences, set the option to video muted/off as the default —\nthen manually enable them once you join a meeting. It can help avoid a few\nfacepalms. Not everyone has the perfect Instagram workspace at home, so Zoom’s\nbackground masks\n[https://support.zoom.us/hc/en-us/articles/204674889-Zoom-Rooms-Customized-Background] \nwill help.\n\n(3) The right mindset\nThe shift to remote will be alien for a lot of us. Be respectful and considerate\n— everyone’s doing the best they can. Set up core work hours when the entire\nteam is expected to be available and clearly define these on a calendar. Be\nmindful of each other’s calendars and schedule sensitively so all concerned\nparties can extract the maximum output from their workday.\n\nQuantify what is being done at the end of each day, and by whom. Transparency is\nkey here. You can shape this right at the beginning during daily team meetings.\nWhen social interactions with colleagues are virtual, you as a manager, or an\nemployer, tend to worry about accountability. Maintain a notepad of things you\ndid, what you’re working on, when others can expect work to be delivered, and\nwhen you will respond to messages or requests. This reduces anxiety and helps\nyou plan your day. In the midst of all this, don’t forget to respect your own\ntime as well. Define your working hours, and stop once they are up.\n\nIt’s equally easy to also overwork yourself when working from home. Be mindful\nof your on-screen time.\n\nSnackable hacks\nWe spoke to a bunch of Gojek folks to get some of their actionable WFH hacks:\n\n * If you find your attention span dwindling, take time off, browse your\n   favorite social media app, go for a walk — get that Vitamin D in, talk to a\n   friend/family member etc…\n * Eat on time, eat healthy — set timelines for this on your calendar so you’re\n   not skipping meals.\n * Create a mini-team virtual group just for social interactions that do not\n   discuss work — movies, books, art, interesting articles etc.\n * Hydrate. Stretch every 30 minutes. Hydrate. Have strict timelines on when you\n   eat. Do not sway here. Did we say hydrate? Hydrate.\n * Team calls should start with something fun — a new fact you learnt, an\n   interesting fact you learnt, or something interesting going on in team\n   member’s lives outside of work.\n * Change into a separate set of clothes during core working hours, even if they\n   are just a different set of comfortable PJs. It helps delineate “work time”\n   from “waking up” or “me time” when both are happening in the same place. It’s\n   tempting to work in bed while wearing the clothes you slept in, but avoid\n   this!\n * Your calendar is sacred — set timers for food breaks, leisure walks, time\n   off, family obligations etc.\n * Call out good work! Do this more often than usual and with consistency. Start\n   your meetings with kudos.\n\nWe’re trying to get better\nThis is an important shift in how organisations get work done. While this guide\nis a foundation to help us figure things out, we don’t have all the answers.\n\nIf you have significant experience with remote work\n[https://docs.google.com/document/d/1TPAKV-AowBpODVul5cL73mKN5caN6RQf0wvV_6O5Ees/edit?usp=sharing]\n, we’d like to hear your thoughts. Feel free to drop into our comments.\n\nThat’s all from us for now, stay safe!\n\nP.S. Empathy & Trust — The two key words you want to keep in mind. ✌️","html":"<p>By Kevin Aluwi</p><p>It’s been a trying couple of weeks since the Coronavirus outbreak. As governments and authorities encourage social distancing, many companies — Gojek included — have started to put a heightened emphasis on working from home. As an organization with a distributed workforce, we have offices in Indonesia, Singapore, Vietnam, Thailand, Philippines, and India, a remote strategy has always been embedded in our DNA. This post details some lessons and what we think are ‘best practices’ to follow in a Work from home (WFH) situation.</p><p><em><em>At the outset, it’s important to call out a key point: During this time of uncertainty, employees may not be at their productive best. There’s a lot of anxiety with family and friends, and rightly so. WFH requires high </em></em><strong><strong><em><em>Accountability</em></em></strong></strong><em><em>, but also </em></em><strong><strong><em><em>Empathy</em></em></strong></strong><em><em> and </em></em><strong><strong><em><em>Trust</em></em></strong></strong><em><em>. Be mindful, this is a stressful time for everyone. Trust your colleagues to do the best they can given the times.</em></em></p><h1 id=\"before-we-begin-context\"><strong>Before we begin — context</strong></h1><p>Gojek has always been mindful of our employees’ health and wellbeing. We have unlimited sick leaves, and encourage employees to work where and when they are at their productive best. <strong><strong>We have proven success</strong></strong> — with functional leaders working fully remotely without compromising on effectively launching org-wide initiatives: career ladders, new hiring programs, even setting up an entire new function. But this is by all means <strong><strong>not</strong></strong> a comprehensive or a definitive guide. Think of this as a ‘beta’ document summarising some lessons in a bid to get feedback from you, our readers. We’re putting this out there so we can learn together to do better.</p><p><em><em>If you think we’ve missed out on something, please leave a comment — will help us a long way in fine-tuning our own practices. These are trying times, and we want to do what is right for everyone.</em></em></p><h1 id=\"-1-the-right-environment\"><strong>(1)The right environment</strong></h1><p>Office spaces provide designated areas employees start associating with work and focus. This may not be the case in a home environment, so it is important to recreate this space. Some ideal prerequisites include an area with plenty of light, minimal distractions and a comfortable desk and chair.</p><p>Working from home also potentially involves sharing the space with other family members / housemates. It’s important to set guidelines to indicate when you are at work and not to be disturbed — one team member for example set up a plush toy on a desk as a makeshift ‘Do Not Disturb’ sign!</p><p>Once a setup is established, don’t neglect the importance of taking breaks. The absence of colleagues and social interaction should not lead to long uninterrupted sessions. Set a timer to alert you if you’ve been continuously at your desk for over two hours. Take short breaks to stretch your legs. Use the time to also spend time with family, or work on personal projects that require the occasional check-in! There’s a silver lining to every scenario :)</p><p><strong><strong>This whole point might seem obvious and rather trivial, but is critical when you want focus, and don’t have your colleagues to ‘pair’ with you and nudge you.</strong></strong></p><h1 id=\"-2-the-right-tools\"><strong>(2) The right tools</strong></h1><p>Ensure the coordination tools used by your organisation / team are installed on your laptop and working properly. At Gojek we use Slack for messaging, Zoom for video conferencing, and Asana and JIRA for project coordination. Here are a few quick tips from our <a href=\"https://docs.google.com/document/d/1TPAKV-AowBpODVul5cL73mKN5caN6RQf0wvV_6O5Ees/edit?usp=sharing\" rel=\"noopener\">WFH Best Practices</a> on how best to use them in a remote work scenario:</p><p><strong><strong>Over communicate:</strong></strong> Set clear expectations and create WFH Rules of Engagement for your team. What cadences need to be synchronous vs. async? Set your Slack status to away every time you leave the computer for a break, and update it once you’re back. Clearly request responses to critical communications you send, and do the same to confirm you’ve received an update (even Slack’s emoji responses will do, as long as there is recorded acknowledgement).</p><p><strong><strong>Document everything:</strong></strong> Meetings may become increasingly asynchronous, so it is important to document all the items discussed and assigned. Record key decisions in a centralized decision log. This can be done via written notes hosted in a common cloud folder, as well as tasks on Asana for accountability. Minimise communication gaps.</p><p><strong><strong>Choose the most high-context communication medium available:</strong></strong> A lot gets lost in translation when you don’t have visual cues. Use <strong><strong>video</strong></strong> conferencing whenever possible. Failing video, (spotty connection) default to a phone call, then chat. In chat, don’t hesitate to use emojis liberally to convey your tone! ?</p><p><strong><strong><em><em>Pro tip:</em></em></strong></strong> In Zoom preferences, set the option to<strong><strong> video</strong></strong> <strong><strong>muted/off </strong></strong>as the default — then manually enable them once you join a meeting. It can help avoid a few facepalms. Not everyone has the perfect Instagram workspace at home, so <a href=\"https://support.zoom.us/hc/en-us/articles/204674889-Zoom-Rooms-Customized-Background\" rel=\"noopener\">Zoom’s background masks</a> will help.</p><h1 id=\"-3-the-right-mindset\"><strong>(3) The right mindset</strong></h1><p>The shift to remote will be alien for a lot of us. Be respectful and considerate — everyone’s doing the best they can. Set up core work hours when the entire team is expected to be available and clearly define these on a calendar. Be mindful of each other’s calendars and schedule sensitively so all concerned parties can extract the maximum output from their workday.</p><p>Quantify what is being done at the end of each day, and by whom. Transparency is key here. You can shape this right at the beginning during daily team meetings. When social interactions with colleagues are virtual, you as a manager, or an employer, tend to worry about accountability. Maintain a notepad of things you did, what you’re working on, when others can expect work to be delivered, and when you will respond to messages or requests. This reduces anxiety and helps you plan your day. In the midst of all this, don’t forget to respect your own time as well. Define your working hours, and stop once they are up.</p><p><em>It’s equally easy to also overwork yourself when working from home. Be mindful of your on-screen time.</em></p><h1 id=\"snackable-hacks\"><strong>Snackable hacks</strong></h1><p>We spoke to a bunch of Gojek folks to get some of their actionable WFH hacks:</p><ul><li>If you find your attention span dwindling, take time off, browse your favorite social media app, go for a walk — get that Vitamin D in, talk to a friend/family member etc…</li><li>Eat on time, eat healthy — set timelines for this on your calendar so you’re not skipping meals.</li><li>Create a mini-team virtual group just for social interactions that do not discuss work — movies, books, art, interesting articles etc.</li><li>Hydrate. Stretch every 30 minutes. Hydrate. Have strict timelines on when you eat. Do not sway here. Did we say hydrate? Hydrate.</li><li>Team calls should start with something fun — a new fact you learnt, an interesting fact you learnt, or something interesting going on in team member’s lives outside of work.</li><li>Change into a separate set of clothes during core working hours, even if they are just a different set of comfortable PJs. It helps delineate “work time” from “waking up” or “me time” when both are happening in the same place. It’s tempting to work in bed while wearing the clothes you slept in, but avoid this!</li><li>Your calendar is sacred — set timers for food breaks, leisure walks, time off, family obligations etc.</li><li>Call out good work! Do this more often than usual and with consistency. Start your meetings with kudos.</li></ul><h1 id=\"we-re-trying-to-get-better\"><strong>We’re trying to get better</strong></h1><p>This is an important shift in how organisations get work done. While this guide is a foundation to help us figure things out, we don’t have all the answers.</p><p>If you have significant experience with <a href=\"https://docs.google.com/document/d/1TPAKV-AowBpODVul5cL73mKN5caN6RQf0wvV_6O5Ees/edit?usp=sharing\" rel=\"noopener\">remote work</a>, we’d like to hear your thoughts. Feel free to drop into our comments.</p><p>That’s all from us for now, stay safe!</p><p>P.S. Empathy &amp; Trust — The two key words you want to keep in mind. ✌️</p>","url":"https://gojek-ghost.zysk.in/gojeks-best-practices-to-work-from-home-beta/","canonical_url":null,"uuid":"9c6ef422-8c4d-4d75-a8a4-420f3ab462e3","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb128b6f7c7da001effcd8c","reading_time":5}},{"node":{"id":"Ghost__Post__5ec2ca3d7aa22c4066f83b6c","title":"Screenshot Testing our Design System on Android","slug":"screenshot-testing-our-design-system-on-android","featured":false,"feature_image":"https://gojek-ghost.zysk.in/content/images/2020/05/1_CDWU7CE8XeZNDZ0fa4KNLw.jpeg","excerpt":"An overview of how we do screenshot tests, and the open source libraries that helped us along the way.","custom_excerpt":"An overview of how we do screenshot tests, and the open source libraries that helped us along the way.","visibility":"public","created_at_pretty":"18 May, 2020","published_at_pretty":"14 January, 2020","updated_at_pretty":"18 May, 2020","created_at":"2020-05-18T23:17:41.000+05:30","published_at":"2020-01-14T09:30:00.000+05:30","updated_at":"2020-05-18T23:43:30.000+05:30","meta_title":null,"meta_description":"An overview of how we do screenshot tests, and the open source libraries that helped us along the way.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Design","slug":"design","description":"Chronicles of the design journeys behind Gojek products, case studies, and insights on UI/UX design.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Design","slug":"design","description":"Chronicles of the design journeys behind Gojek products, case studies, and insights on UI/UX design.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Jitin Sharma\n\nIn this post, we’ll take a look at how we test our Design System components on\nAndroid using screenshot tests to make them pixel perfect. 👌\n\nLet’s start with an example.\n\nTake a look at these two images:\n\nAre these images identical?They may look the same, but they aren’t! Here’s\nwhat’s different:\n\nThere are two subtle changes — the colour of the button is a different shade of\ngreen and the elevation is also different.\n\nIn Asphalt\n[https://blog.gojekengineering.com/ux-engineering-at-gojek-9de2abe24928], our\ndesign language system, we want to make sure our UI components are robust and\ndetect breakages early. Here’s how we leveraged screenshot tests to achieve\nthis.\n\nComponents Everywhere\nAsphalt Components in Gojek appWith Asphalt, we create components that can be\nreused across the Gojek app. Every button, text, input, or card which you see in\nmost of the screens of the app is an Asphalt Component. On top of this, we have\na demo app which showcases the usage of these components.\n\nAsphalt Components in Demo appOur components are the backbone of the Gojek app\nUI. For example, our button class has 300+ occurrences across Gojek’s consumer\napp codebase. This heavy reuse helps us enforce design guidelines across the\napp. The importance of these components requires that we test them thoroughly,\nas even a small regression in one component could mean a degraded experience for\nour users.\n\n[U]n[I]t Testing\nUnit tests are supposed to test logic and fail when expectations aren’t met. How\ndo we expect that a certain UI is being rendered properly?\n\nThe idea of screenshot testing is to have a master copy of screenshots that we\nknow are correct and on every test run compare the current screenshots to the\nmaster copy. If the current set does not match the master set, the test fails.\nThis will allow us to check unintentional UI changes. If the changes are\nintentional, then we run the tests in update mode which updates the master\nscreenshots.\n\nHere is the high level outline:\n\n> - Write Espresso test for all activities in the demo\n> - Take screenshots and create a master set\n> - At every CI run take screenshots again and compare with master set\nWe started out with Shot [https://github.com/Karumi/Shot], an open source\nlibrary which allows us to take screenshots and compare them using gradle\ncommands and generate reports.\n\nHere’s what a test for our Alert component looks like 👇\n\nAchilles Heel — The Android Emulator\nWhile the Android emulator has improved a lot in recent times, we found running\nemulators in CI is still unreliable.\n\nHere are a few issues we faced:\n\n> - We had to wait to for the emulator to start up, which was only possible\nthrough a hack(y) script by continuously pinging adb commands\n> Emulator would put more memory pressure on CI runners\n> Emulators also need hardware acceleration which required us to enable kvm on our\nLinux-based machines.\nRunning Instrumentation test cases with these issues would mean our tests would\nbe flaky — and we couldn’t have that.\n\nFirebase Test Lab saves the day!\nWe decide to move away from emulators to real devices.\n\nOne idea was to have devices connected to a machine and use the machine as a\nrunner for running test cases in CI — a device test lab.\n\nBut devices come with their own baggage — maintaining them. They may be\ninterrupted by software updates, system dialogs… or get overcharged and explode!\n🔥\n\nWe found the next best thing: Firebase Test Lab\n[https://firebase.google.com/docs/test-lab] — a set of devices in cloud, managed\nautomatically and available via CLI.\n\nThis solved our device problem, but we ran into another one — Firebase Test Lab\ndoesn’t allow you to run custom gradle commands. Instead, it expects you to\nupload a debug and a test apk, and it will run the tests for you. This meant we\ncould no longer use Shot for taking screenshots and comparing them 😦\n\nWhile scratching our heads over how to overcome this problem, we found that\nFirebase Test Lab allows you\n[https://firebase.google.com/docs/test-lab/android/test-screenshots] to take\nscreenshots through a library and then retrieve them from Google Cloud Bucket.\n\nThere is also a gradle plugin [https://github.com/runningcode/fladle/] which\nautomates this process including downloading artifacts from GCP — open source to\nthe rescue again!\n\nHere’s how our test case looks like with Firebase screenshot library:\n\nFor image comparison we used ImageMagick [https://imagemagick.org/], a very\npopular and feature-packed CLI tool for image manipulation. It also allows us to\noutput a different image in case two images don’t match, which is super useful\nfor generating test failure reports.\n\nThe final piece — integrating screenshot tests into our developer workflow\nAs part of CI, we do the following things when a merge request is raised:\n\n> - Build the project\n> - Run Espresso Tests on Firebase Test Lab\n> - Retrieve screenshots and compare them with master set\n> - If any screenshot doesn’t match, we fail the build and add a comment to PR\nusing Danger [https://danger.systems/]\nDanger reporting mismatch in screenshot along with diff image.We have been using\nthis setup for some time now, and it’s worked out great for us! We have been\nable to execute multiple UI refactors with high confidence.\n\nWhat’s next?\nWe will continue to invest in this setup in the future. Things like testing\nlocalisation, having a test matrix with multiple screen sizes, API levels,\ndevice densities… these are some things we have planned for the future.\n\nA big thank you to the open source libraries that helped us achieve this!\n\n\n--------------------------------------------------------------------------------\n\nLiked what you read? Sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] and we’ll send you weekly\nupdates about our stories! 🖖","html":"<p>By Jitin Sharma</p><p>In this post, we’ll take a look at how we test our Design System components on Android using screenshot tests to make them pixel perfect. 👌</p><p>Let’s start with an example.</p><p>Take a look at these two images:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1052/1*GON1POsYNn-n13Yvx9KWlQ.png\" class=\"kg-image\"><figcaption>Are these images identical?</figcaption></figure><p>They may look the same, but they aren’t! Here’s what’s different:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1052/1*0Cunmda2Ctain_g4xPU3iQ.png\" class=\"kg-image\"></figure><p>There are two subtle changes — the colour of the button is a different shade of green and the elevation is also different.</p><p>In <a href=\"https://blog.gojekengineering.com/ux-engineering-at-gojek-9de2abe24928\" rel=\"noopener\">Asphalt</a>, our design language system, we want to make sure our UI components are robust and detect breakages early. Here’s how we leveraged screenshot tests to achieve this.</p><h1 id=\"components-everywhere\">Components Everywhere</h1><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1584/1*UH05mhuGHielEDM4RtbOcQ.png\" class=\"kg-image\"><figcaption>Asphalt Components in Gojek app</figcaption></figure><p>With Asphalt, we create components that can be reused across the Gojek app. Every button, text, input, or card which you see in most of the screens of the app is an Asphalt Component. On top of this, we have a demo app which showcases the usage of these components.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1220/1*ixxp__0PC20bAMigugixhg.png\" class=\"kg-image\"><figcaption>Asphalt Components in Demo app</figcaption></figure><p>Our components are the backbone of the Gojek app UI. For example, our button class has 300+ occurrences across Gojek’s consumer app codebase. This heavy reuse helps us enforce design guidelines across the app. The importance of these components requires that we test them thoroughly, as even a small regression in one component could mean a degraded experience for our users.</p><h1 id=\"-u-n-i-t-testing\">[U]n[I]t Testing</h1><p>Unit tests are supposed to test logic and fail when expectations aren’t met. How do we expect that a certain UI is being rendered properly?</p><p>The idea of screenshot testing is to have a master copy of screenshots that we know are correct and on every test run compare the current screenshots to the master copy. If the current set does not match the master set, the test fails. This will allow us to check unintentional UI changes. If the changes are intentional, then we run the tests in <code>update</code> mode which updates the master screenshots.</p><p><strong><strong>Here is the high level outline:</strong></strong></p><blockquote><em><em>- Write Espresso test for all activities in the demo</em></em></blockquote><blockquote><em><em>- Take screenshots and create a master set</em></em></blockquote><blockquote><em><em>- At every CI run take screenshots again and compare with master set</em></em></blockquote><p>We started out with <a href=\"https://github.com/Karumi/Shot\" rel=\"noopener\">Shot</a>, an open source library which allows us to take screenshots and compare them using gradle commands and generate reports.</p><p>Here’s what a test for our Alert component looks like 👇</p><!--kg-card-begin: html--><script src=\"https://gist.github.com/jitinsharma/c57e8afbb0b4849ff75a29eeba4dc4d1.js\"></script><!--kg-card-end: html--><h1 id=\"achilles-heel-the-android-emulator\">Achilles Heel — The Android Emulator</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1400/0*WWyaL1uLibHeXC15.png\" class=\"kg-image\"></figure><p>While the Android emulator has improved a lot in recent times, we found running emulators in CI is still unreliable.</p><p>Here are a few issues we faced:</p><blockquote><em><em>- We had to wait to for the emulator to start up, which was only possible through a hack(y) script by continuously pinging <code>adb</code> commands</em></em></blockquote><blockquote><em><em>Emulator would put more memory pressure on CI runners</em></em></blockquote><blockquote><em><em>Emulators also need hardware acceleration which required us to enable <code>kvm</code> on our Linux-based machines.</em></em></blockquote><p>Running Instrumentation test cases with these issues would mean our tests would be flaky — and we couldn’t have that.</p><h1 id=\"firebase-test-lab-saves-the-day-\">Firebase Test Lab saves the day!</h1><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1280/0*IIH6x5bWvHn1Gcv_.jpg\" class=\"kg-image\"></figure><p>We decide to move away from emulators to real devices.</p><p>One idea was to have devices connected to a machine and use the machine as a runner for running test cases in CI — a device test lab.</p><p>But devices come with their own baggage — maintaining them. They may be interrupted by software updates, system dialogs… or get overcharged and explode! 🔥</p><p>We found the next best thing: <a href=\"https://firebase.google.com/docs/test-lab\" rel=\"noopener\">Firebase Test Lab</a> — a set of devices in cloud, managed automatically and available via CLI.</p><p>This solved our device problem, but we ran into another one — Firebase Test Lab doesn’t allow you to run custom gradle commands. Instead, it expects you to upload a debug and a test apk, and it will run the tests for you. This meant we could no longer use Shot for taking screenshots and comparing them 😦</p><p>While scratching our heads over how to overcome this problem, we found that Firebase Test Lab <a href=\"https://firebase.google.com/docs/test-lab/android/test-screenshots\" rel=\"noopener\">allows you</a> to take screenshots through a library and then retrieve them from Google Cloud Bucket.</p><p>There is also a <a href=\"https://github.com/runningcode/fladle/\" rel=\"noopener\">gradle plugin</a> which automates this process including downloading artifacts from GCP — open source to the rescue again!</p><p>Here’s how our test case looks like with Firebase screenshot library:</p><!--kg-card-begin: html--><script src=\"https://gist.github.com/jitinsharma/971c95389af0ae11b38f392076dc6df8.js\"></script><!--kg-card-end: html--><p>For image comparison we used <a href=\"https://imagemagick.org/\" rel=\"noopener\">ImageMagick</a>, a very popular and feature-packed CLI tool for image manipulation. It also allows us to output a different image in case two images don’t match, which is super useful for generating test failure reports.</p><h1 id=\"the-final-piece-integrating-screenshot-tests-into-our-developer-workflow\">The final piece — integrating screenshot tests into our developer workflow</h1><p>As part of CI, we do the following things when a merge request is raised:</p><blockquote><em><em>- Build the project</em></em></blockquote><blockquote><em><em>- Run Espresso Tests on Firebase Test Lab</em></em></blockquote><blockquote><em><em>- Retrieve screenshots and compare them with master set</em></em></blockquote><blockquote><em><em>- If any screenshot doesn’t match, we fail the build and add a comment to PR using <a href=\"https://danger.systems/\" rel=\"noopener\">Danger</a></em></em></blockquote><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1970/1*D6gb_yARAM4n83umso03Xw.png\" class=\"kg-image\"><figcaption>Danger reporting mismatch in screenshot along with diff image.</figcaption></figure><p>We have been using this setup for some time now, and it’s worked out great for us! We have been able to execute multiple UI refactors with high confidence.</p><h1 id=\"what-s-next\">What’s next?</h1><p>We will continue to invest in this setup in the future. Things like testing localisation, having a test matrix with multiple screen sizes, API levels, device densities… these are some things we have planned for the future.</p><p>A big thank you to the open source libraries that helped us achieve this!</p><hr><p>Liked what you read? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter</a> and we’ll send you weekly updates about our stories! 🖖</p>","url":"https://gojek-ghost.zysk.in/screenshot-testing-our-design-system-on-android/","canonical_url":null,"uuid":"4a57a774-789f-4e2c-ac66-c0896c460a22","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec2ca3d7aa22c4066f83b6c","reading_time":5}},{"node":{"id":"Ghost__Post__5eb12eb3f7c7da001effce0b","title":"How We Supercharged Chat","slug":"how-we-supercharged-chat","featured":false,"feature_image":"https://res-3.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_tuDgHHPUouXxzsK4OEzPaw.jpg","excerpt":"The nuts and bolts of the framework that allows other Gojek products to leverage our chat platform via extensions.","custom_excerpt":"The nuts and bolts of the framework that allows other Gojek products to leverage our chat platform via extensions.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"10 January, 2020","updated_at_pretty":"18 May, 2020","created_at":"2020-05-05T14:45:31.000+05:30","published_at":"2020-01-10T09:30:00.000+05:30","updated_at":"2020-05-18T20:45:50.000+05:30","meta_title":null,"meta_description":"The nuts and bolts of the framework that allows other Gojek products to leverage our chat platform via extensions.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Tech","slug":"tech","description":"Learnings from technical challenges solved at Gojek, how-tos, and programming tips.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Benzi Ahamed\n\nThe Gojek consumer app comes with a chat feature. This allows users to have\nconversations with:\n\n * The currently assigned driver partner in relation to a booking.\n * Other Gojek users, provided they are known contacts in your address book.\n   These can be either personal or group chats.\n\nIn order to use the chat platform as springboard to other services within\nGojek’s vast ecosystem, we wanted to expose some features that integrate with\nour other offerings — within the convenience of a chat window.\n\nOne of the first service options we wanted to focus on was payments — paying and\nrequesting for money between individuals and groups. Chat had the platform to\ncreate connections between people, GoPay had payments — it was time to marry the\ntwo.\n\nArchitecture\nTo start with, as a chat platform team, we did not really know anything about\nthe payments domain. In fact, most of the integrations we planned for required\ncollaborating with other product teams within Gojek.\n\nWe decided early on that we needed a plugin-based framework that other product\nteams (and even chat team’s core services) could use. We also decided that the\nAPI surface area for this new framework should have as much as possible in\ncommon between the Android and iOS implementations.\n\nThe first use case we focused on was integrating payment options within chat —\nwhich would help us kickstart our design and feature rollout.\n\nApproach\nIn the vein of keeping things as simple as possible, we came up with the\nfollowing set of guidelines:\n\n * The chat subsystem can expose add-on features to the user\n * These features will not be part of the core chat offering, but can be\n   plugged-in externally\n * These plugin-based entities — chat extensions — can have mainly two\n   capabilities\n * Display a button (widget) in a chat window to trigger the chat extension’s\n   functionality\n * Display chat extension messages that can support rich text, images,\n   call-to-actions\n\nChat extension messages are merely text messages with additional metadata. While\nplain text-based messages are rendered by the core chat rendering system, chat\nextension messages need to be rendered by the chat extension that created the\nmessage.\n\nChat Extension Framework — Key ActorsThe illustration above depicts the final\nframework components we came up with.\n\n * Chat Extension Providers are responsible for vending Chat Extensions based on\n   the active Chat Session (there might be cases where we want to enable a\n   certain feature only for certain types of chats e.g. those between our\n   drivers and customers).\n * Chat Extensions are the components responsible for vending trigger points (\n   Widget Views) and custom message views (Extension Message Views).\n\nWhile the core subsystem takes care of managing life cycles of the chat\nextensions, widgets, and message views, it is the responsibility of extension\nauthors to purely focus on the implementation details of their feature.\n\nWith the above design in place, we were ready to start collaborating and start\nimplementing features.\n\nLet’s take a look at some integrations we were able to build collaboratively.\n\nSample Integrations\nPayments\nThe first integration we did was Request and Pay flows. Utilising GoPay,\ncustomers can make payments and request for money from friends.\n\nHere’s the Request Flow in action, within a personal chat:\n\nRequest Money from an IndividualIn a group chat, Request Flow translates to a\nSplit Bill flow:\n\nRequest Money in a GroupHere’s the Pay flow in action:\n\nPay via GoPay, continue conversation in ChatIn the Pay Flow, we start with\nmaking a payment from the home-screen of the Gojek App. Once a payment is done,\nyou have an option to continue to chat with the person you made the payment to.\nThis flow is of course in addition to similar flows for Request where you can\ntrigger a payment within chat itself.\n\nThe payments team were able to create a UX flow that could be triggered either\nfrom the home screen or the chat window.\n\nRestaurant Sharing\nNext up, our GoFood team wanted to explore sharing restaurant information via\nchat. Since we already had support for extensions at this point in time, we\ncreated a generic Share Via Chat flow that supports sharing simple text messages\nor custom extension message content.\n\nIn the Pay Flow, we start with making a payment from the home-screen of the\nGojek App. Once a payment is done, you have an option to continue to chat with\nthe person you made the payment to. This flow is of course in addition to\nsimilar flows for Request where you can trigger a payment within chat itself.\n\nThe payments team were able to create a UX flow that could be triggered either\nfrom the home screen or the chat window.\n\nRestaurant Sharing\nNext up, our GoFood team wanted to explore sharing restaurant information via\nchat. Since we already had support for extensions at this point in time, we\ncreated a generic Share Via Chat flow that supports sharing simple text messages\nor custom extension message content.\n\n\nShare Restaurant Details via ChatWhat’s interesting is that once a Restaurant\nCard has been shared via chat, a recipient clicking on that card can proceed to\nmake a food order, directly from the chat window itself. This is made possible\nby the fact that Extension Message Views can be fully interactive (e.g. detect\nuser taps), and the chat window provides contextual navigation controls to them.\n\nImage Sharing\nLastly, let us take a look at the most recent feature we rolled out to\nproduction — image sharing in our customer-driver chats.\n\nImage Sharing via ChatDuring the implementation of this feature, we recognised\nthat image sharing would be better triggered from the chat window if there was a\ndirect shortcut button (e.g. a camera icon) within the bottom text input area of\nthe chat window.\n\nThis leads us to enhance our extension framework to allow Chat Extensions to\nprovide Chat Extension Shortcuts as well. Our updated framework looks like\nbelow:\n\nLessons Learned\nIt has been a great journey so far exploring various kinds of integrations in a\nsimple chat window. We have a lot more planned, but in the meanwhile, here are a\nfew key things we learned along the way\n\n * When you are developing a platform, evangelising what your platform provides\n   is key. This is equally relevant if you are a platform-product company, or a\n   platform team within a company. We conducted an internal chat extension\n   hackathon which helped broaden our outreach, and saw some pretty cool ideas\n   implemented including Live Location Sharing, Booking Sharing, Games, Sticker\n   Packs etc.\n * Document your public API! Teams are more willing to collaborate if you have\n   proper, up-to-date documentation in place. We created detailed technical\n   documents, integration guides, and even provided a sample chat extension (a\n   starter-pack, if you will) — these greatly helped teams adopting these new\n   features. Also, the feedback we got during the internal hackathon fed\n   directly back into improving our documentation.\n * Having a common design language helped our Android and iOS engineers to\n   collaborate more closely. It was easier for the team to work on implementing\n   the feature by focussing on the common characteristics during tech\n   discussion, design ratification sessions etc. and leaving the nuances of each\n   platform to respective teams during development. Having a common language\n   that engineers can speak (irrespective of their specialisations) improves\n   cross-communications and collaboration.\n * It is important to design solutions exercising self-imposed constraints.\n   These constraints should directly limit the engineering scope of the\n   solution. As engineers, we are all too comfortable going down the technical\n   analysis rabbit-hole in our pursuit of coming up with a well rounded, albeit\n   (possibly) over-engineered solution. This usually ends up in complicated\n   designs, which translate into complicated code. It is better to design\n   simpler systems and iteratively add smaller features, where each iteration\n   cycle should also incorporate refactoring every step of the way. Even though\n   we knew having something like Extension Shortcuts was nice to have from the\n   get go, we had to exercise restraint and only implemented the feature when it\n   was actually required.\n * We cannot stress this enough, but continuous refactoring (whenever required)\n   is one surefire way to reduce the build-up of tech debt in any codebase.\n   Improve a function here, rename a variable there, refactor a class into two —\n   every little bit helps. It is the responsibility of the entire team to be\n   engaged in this exercise.\n\nSo there you have it, a quick look at the way the core chat team developed a\nbase extension framework that is currently being used to build richer\nintegrations into chat.\n\n\n--------------------------------------------------------------------------------\n\nWant more where that come from? Have our updates delivered straight to your\ninbox by signing up for our newsletter!\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]","html":"<p>By Benzi Ahamed</p><p>The Gojek consumer app comes with a chat feature. This allows users to have conversations with:</p><ul><li>The currently assigned driver partner in relation to a booking.</li><li>Other Gojek users, provided they are known contacts in your address book. These can be either personal or group chats.</li></ul><p>In order to use the chat platform as springboard to other services within Gojek’s vast ecosystem, we wanted to expose some features that integrate with our other offerings — within the convenience of a chat window.</p><p>One of the first service options we wanted to focus on was payments — paying and requesting for money between individuals and groups. Chat had the platform to create connections between people, GoPay had payments — it was time to marry the two.</p><h1 id=\"architecture\">Architecture</h1><p>To start with, as a chat platform team, we did not really know anything about the payments domain. In fact, most of the integrations we planned for required collaborating with other product teams within Gojek.</p><p>We decided early on that we needed a plugin-based framework that other product teams (and even chat team’s core services) could use. We also decided that the API surface area for this new framework should have as much as possible in common between the Android and iOS implementations.</p><p>The first use case we focused on was integrating payment options within chat — which would help us kickstart our design and feature rollout.</p><h2 id=\"approach\">Approach</h2><p>In the vein of keeping things as simple as possible, we came up with the following set of guidelines:</p><ul><li>The chat subsystem can expose add-on features to the user</li><li>These features will not be part of the core chat offering, but can be plugged-in externally</li><li>These plugin-based entities — chat extensions — can have mainly two capabilities</li><li>Display a button (widget) in a chat window to trigger the chat extension’s functionality</li><li>Display chat extension messages that can support rich text, images, call-to-actions</li></ul><p>Chat extension messages are merely text messages with additional metadata. While plain text-based messages are rendered by the core chat rendering system, chat extension messages need to be rendered by the chat extension that created the message.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1980/1*yZbylgYQ7Q7jaF8cooEpeQ.png\" class=\"kg-image\"><figcaption>Chat Extension Framework — Key Actors</figcaption></figure><p>The illustration above depicts the final framework components we came up with.</p><ul><li><strong><strong>Chat Extension Providers</strong></strong> are responsible for vending <strong><strong>Chat Extension</strong></strong>s based on the active <strong><strong>Chat Session</strong></strong> (there might be cases where we want to enable a certain feature only for certain types of chats e.g. those between our drivers and customers).</li><li><strong><strong>Chat Extensions</strong></strong> are the components responsible for vending trigger points (<strong><strong>Widget Views</strong></strong>) and custom message views (<strong><strong>Extension Message Views</strong></strong>).</li></ul><p>While the core subsystem takes care of managing life cycles of the chat extensions, widgets, and message views, it is the responsibility of extension authors to purely focus on the implementation details of their feature.</p><p>With the above design in place, we were ready to start collaborating and start implementing features.</p><p>Let’s take a look at some integrations we were able to build collaboratively.</p><h1 id=\"sample-integrations\">Sample Integrations</h1><h2 id=\"payments\">Payments</h2><p>The first integration we did was Request and Pay flows. Utilising GoPay, customers can make payments and request for money from friends.</p><p>Here’s the Request Flow in action, within a personal chat:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/404/1*2mJZ8btzdO7bVq5rXtwvoQ.gif\" class=\"kg-image\"><figcaption>Request Money from an Individual</figcaption></figure><p>In a group chat, Request Flow translates to a Split Bill flow:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/402/1*OHgw8oUSuN6n1d8sjWCw7A.gif\" class=\"kg-image\"><figcaption>Request Money in a Group</figcaption></figure><p>Here’s the Pay flow in action:</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/404/1*6z12Pjg1Vgy8Y-0P1jFPSw.gif\" class=\"kg-image\"><figcaption>Pay via GoPay, continue conversation in Chat</figcaption></figure><p>In the Pay Flow, we start with making a payment from the home-screen of the Gojek App. Once a payment is done, you have an option to continue to chat with the person you made the payment to. This flow is of course in addition to similar flows for Request where you can trigger a payment within chat itself.</p><p>The payments team were able to create a UX flow that could be triggered either from the home screen or the chat window.</p><h2 id=\"restaurant-sharing\">Restaurant Sharing</h2><p>Next up, our GoFood team wanted to explore sharing restaurant information via chat. Since we already had support for extensions at this point in time, we created a generic Share Via Chat flow that supports sharing simple text messages or custom extension message content.</p><p>In the Pay Flow, we start with making a payment from the home-screen of the Gojek App. Once a payment is done, you have an option to continue to chat with the person you made the payment to. This flow is of course in addition to similar flows for Request where you can trigger a payment within chat itself.</p><p>The payments team were able to create a UX flow that could be triggered either from the home screen or the chat window.</p><h2 id=\"restaurant-sharing-1\">Restaurant Sharing</h2><p>Next up, our GoFood team wanted to explore sharing restaurant information via chat. Since we already had support for extensions at this point in time, we created a generic Share Via Chat flow that supports sharing simple text messages or custom extension message content.<br></p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/404/1*iMz_DNDwFwiCM4aiMRilAg.gif\" class=\"kg-image\"><figcaption>Share Restaurant Details via Chat</figcaption></figure><p>What’s interesting is that once a Restaurant Card has been shared via chat, a recipient clicking on that card can proceed to make a food order, directly from the chat window itself. This is made possible by the fact that Extension Message Views can be fully interactive (e.g. detect user taps), and the chat window provides contextual navigation controls to them.</p><h2 id=\"image-sharing\">Image Sharing</h2><p>Lastly, let us take a look at the most recent feature we rolled out to production — image sharing in our customer-driver chats.</p><figure class=\"kg-card kg-image-card kg-card-hascaption\"><img src=\"https://miro.medium.com/max/600/1*uFGU-NAQrIM2L4USdNLuWA.gif\" class=\"kg-image\"><figcaption>Image Sharing via Chat</figcaption></figure><p>During the implementation of this feature, we recognised that image sharing would be better triggered from the chat window if there was a direct shortcut button (e.g. a camera icon) within the bottom text input area of the chat window.</p><p>This leads us to enhance our extension framework to allow Chat Extensions to provide Chat Extension Shortcuts as well. Our updated framework looks like below:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/2140/1*BDMz2IPpUJcX3M80qI_7bw.png\" class=\"kg-image\"></figure><h1 id=\"lessons-learned\">Lessons Learned</h1><p>It has been a great journey so far exploring various kinds of integrations in a simple chat window. We have a lot more planned, but in the meanwhile, here are a few key things we learned along the way</p><ul><li>When you are developing a platform, evangelising what your platform provides is key. This is equally relevant if you are a platform-product company, or a platform team within a company. We conducted an internal chat extension hackathon which helped broaden our outreach, and saw some pretty cool ideas implemented including Live Location Sharing, Booking Sharing, Games, Sticker Packs etc.</li><li>Document your public API! Teams are more willing to collaborate if you have proper, up-to-date documentation in place. We created detailed technical documents, integration guides, and even provided a sample chat extension (a starter-pack, if you will) — these greatly helped teams adopting these new features. Also, the feedback we got during the internal hackathon fed directly back into improving our documentation.</li><li>Having a common design language helped our Android and iOS engineers to collaborate more closely. It was easier for the team to work on implementing the feature by focussing on the common characteristics during tech discussion, design ratification sessions etc. and leaving the nuances of each platform to respective teams during development. Having a common language that engineers can speak (irrespective of their specialisations) improves cross-communications and collaboration.</li><li>It is important to design solutions exercising self-imposed constraints. These constraints should directly limit the engineering scope of the solution. As engineers, we are all too comfortable going down the technical analysis rabbit-hole in our pursuit of coming up with a well rounded, albeit (possibly) over-engineered solution. This usually ends up in complicated designs, which translate into complicated code. It is better to design simpler systems and iteratively add smaller features, where each iteration cycle should also incorporate refactoring every step of the way. Even though we knew having something like Extension Shortcuts was nice to have from the get go, we had to exercise restraint and only implemented the feature when it was actually required.</li><li>We cannot stress this enough, but <em><em>continuous refactoring</em></em> (whenever required) is one surefire way to reduce the build-up of tech debt in any codebase. Improve a function here, rename a variable there, refactor a class into two — every little bit helps. It is the responsibility of the entire team to be engaged in this exercise.</li></ul><p>So there you have it, a quick look at the way the core chat team developed a base extension framework that is currently being used to build richer integrations into chat.</p><hr><p>Want more where that come from? Have our updates delivered straight to your inbox by <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\">signing up for our newsletter!</a></p>","url":"https://gojek-ghost.zysk.in/how-we-supercharged-chat/","canonical_url":null,"uuid":"a5657369-e813-44f1-af8d-aa2e306bfafd","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb12eb3f7c7da001effce0b","reading_time":6}},{"node":{"id":"Ghost__Post__5eb12ec4f7c7da001effce0f","title":"The Secret Sauce Behind Search Personalisation","slug":"the-secret-sauce-behind-search-personalisation","featured":false,"feature_image":"https://res-5.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_x4G3c6-g3z3mz01o2EJdbw.jpg","excerpt":"How Gojek uses machine learning to personalise search results in GoFood.","custom_excerpt":"How Gojek uses machine learning to personalise search results in GoFood.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"02 December, 2019","updated_at_pretty":"18 May, 2020","created_at":"2020-05-05T14:45:48.000+05:30","published_at":"2019-12-02T09:30:00.000+05:30","updated_at":"2020-05-18T20:43:26.000+05:30","meta_title":null,"meta_description":"How Gojek uses machine learning to personalise search results in GoFood.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Jewel James\n\nAre you looking for food? Thinking about burgers and crispy chicken fritters\nwith creamy sauces sitting on a warm, soft bun? At least, that’s what I am\nthinking about. May be you’re different. Vegan perhaps? Or craving noodles? Each\nof us turn into a different person when we are hungry, and this is the story\nabout how GoFood — Gojek’s food delivery service — helps you find the bite you\ncrave.\n\n> At the core of the food ordering experience, sits search.\nSearches are part of so many of our interactions on web and mobile, that we\ndon’t even notice it anymore. This is mostly because modern search engines have\nmatured to a point where they can deliver high quality results even if the\nentered query is a weak signal of the user’s intent. Even when weak, every query\nstill contains a piece of the user’s intent.\n\nIn the case of GoFood, that piece is a fragment of our user’s hunger-driven\nbrain.\n\nIn this post, we’ll discuss how we personalise the search results we surface on\nGoFood, based on the information we have about our users’ food preferences.\n\nHow Each of Us Differ\nLet’s look at two of our GoFood users who have started feeling the pangs of\nhunger, and come online to check restaurants near them.\n\nThey both open our app and click on the NEAR ME tile that lets users find the\nrestaurants near them. We show them the nearest restaurants first, and this is\nwhat they both see.\n\n\nThis list goes on and on and will let them see each restaurant which is farther\nand farther away. They can now peruse the menus of each restaurant and pick one\nthat serves what they feel like ordering. The problem is that they may spend\nsome time scrolling and then leave the app without being able to make up their\nminds around which restaurant to place an order from. We have thrown too many\nchoices at them and the cognitive effort of picking a restaurant and then a dish\nfrom the menu is too much work to make them suffer through.\n\nBut wait. Both Mila and Husain have transacted with us in the past, and we know\na fair bit about their preferences. 🤔\n\nTo make this experience better, we decided to build a system that would let both\nof them see restaurants that suit their own tastes and preferences\n\nApplying Machine Learning to the Problem\nRanking documents for relevance works by assigning a prediction score to each\ndocument retrieved, which is directly proportional to its relevance. In the case\nof NEAR ME restaurant ranking this can be something like:\n\n> Relevance score = 2 * (1/distance) + 1.2 * rating of restaurant\nHere in the relevance score calculation, we are taking weighted sum of different\nfactors like (1/distance) and rating of restaurant. The coefficients/weights of\nthese factors can be arrived at by experimenting with them and choosing weights\nthat seem to maximise the ordering conversions. But, in the case of restaurant\nranking in GoFood, we want to take into consideration many factors when deciding\nrelevance. Unfortunately, experimenting with combinations of all those factors\nis impossible.\n\nEnter Learning to rank. Here, the problem of deciding the rank of the\nrestaurants shown to the user is formulated as a supervised machine learning\nproblem.\n\nIf we look at past search, click, and ordering data, we will be able to assign\nrelevance judgements to each restaurant listing according to whether our users\nclicked or ordered from one of those restaurants. Restaurants that attracted\nhigher degrees of interest will be given higher degrees of relevance.\n\nIn the below example, a relevance judgement level of 0,1 and 2 is assigned to a\nrestaurant according to whether the user viewed, clicked, or ordered from the\nrestaurant in the search result. The relevance judgements are relative and only\nintent to be monotonically increasing with increasing relevance . They say that\nthe restaurant which the user created an order from is more relevant than a\nrestaurant the user merely checked out by clicking on it. They don’t mean that\nthe restaurant which received the order is twice as relevant .\n\nThe values of each of the factors that could have played a role in the user’s\ndecision of clicking or ordering is also shown against the restaurants.\n\nThree of the factors/features in the above example are marked as\n‘personalisation features’ because they would change according to the user’s\nprevious order history and location. These will be the features that will be\ndifferent between Mila and Husain because of the differences in the restaurants\nand cuisines they have ordered from before in the past.\n\n> These personalisation features are at the crux of creating personalised\nexperiences for each user\nOther customer agnostic features/factors like the rating, price range, and\npopularity of the restaurant are also listed here. GoFood has millions of such\nexamples where users with different tastes made different decisions when shown a\nset of search results. These examples can now be used to create a dataset from\nwhich the learning to rank ML algorithm can create a model to decide how\nrelevant a GoFood user would find a restaurant given that user’s location, order\nhistory and other restaurant statistics.\n\nHow We Ranked\nOne way to approach this was as a point-wise ranking problem, wherein we try to\npredict the relevance judgement of each restaurant. Based on this, later we will\npredict the relevance judgement level and sort restaurants in decreasing order\nof predicted relevance score. This approach reduces learning to rank problem to\na regression problem.\n\nAnother approach was to solve it is a pairwise ranking problem, wherein the ML\nmodel is trying to learn how to get the order of a pair of restaurants correct\ni.e if Restaurant A is more preferable to Restaurant B , the order (Restaurant\nA, Restaurant B) is correct and the order (Restaurant B, Restaurant A) is wrong.\n\nFor an ML model to be learned, we need an objective function that captures this\npairwise ordering formulation . This is called a loss function or error function\nin ML and is the measure through which an ML model can assess how right or wrong\nits decision was. In pairwise ranking , this should be a function that becomes\nhigher whenever the model misjudges a preference order and becomes lower when it\nis right about the preference order.\n\nThe loss/error function C is explained below:\n\nWhen this function is minimised, the model is trying to predict a score for each\nrestaurant such that the ranking of the order of the restaurants are close the\nrelevance judgements the users made.\n\nThe pairwise formulation is a better approach here in comparison to the\npoint-wise approach as it is looking to get the order of restaurants right and\nis not trying to estimate the relevance score themselves whose values were\nassigned only as markers to show how some restaurants were more preferred\nrelative to others.\n\nWe used an implementation of the LambdaMART algorithm that learns to predict\nrelevance scores so as to minimise this pairwise loss. You can think of this as\na pursuit to find the decision tree that takes in all the parameters of the\nrestaurant and gives out a score to the restaurant . This score should be\nassigned in such a way as to make the pair orders right.\n\nOnce this model is trained, it can be used during search, as explained in this\npost\n[https://blog.gojekengineering.com/how-the-gojek-butler-serves-a-gourmet-meal-to-our-users-4a161d83052a?source=friends_link&sk=42397976fe914a418ac40f19545f90b7]\n.\n\nNow let’s go back to our beloved customers — Mila and Husain. The next time Mila\nor Husain looks for restaurants near them, the search results they see will be\naccording to their preferences. This is because the model would look at the\nnumber of times they have ordered from each of the restaurants near them before.\nIt would take their preferred cuisines and factors like restaurant ratings into\naccount, and show them the restaurants that they would prefer to order from\nfirst.\n\nThe different search results Mila and Husain get after learning to rank is used\nto re-rank the results are shown below.\n\nWe ran an AB test using this formulation of learning to rank and observed a\nrelative lift of 20% in search to ordering conversions and 23% improvement in\nNDCG. More information on how this metric is calculated here\n[https://blog.gojekengineering.com/is-this-what-you-were-looking-for-439bf012cca6?source=friends_link&sk=bdc1310acc3b6a8270f10284cb30fa53]\n.\n\nWhat We Learned\nOne interesting thing we observed as we started experimenting with this learning\nto rank model was personalising search results led to the average position at\nwhich the search to order conversions happen to be much higher on the list. This\nis because users were increasingly seeing the restaurants that they have some\naffinity towards and were able to make an ordering decision without scrolling\nmuch and without spending too much time being confused where to order from.\n\nSo that’s how we rank restaurant pairs with respect to relevance based on\navailable user data. We’ll continue to write more about how we make our products\nmore intuitive. Stay tuned to this blog, or sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] for email updates. 👌\n\n\n--------------------------------------------------------------------------------\n\n(Special thanks to Sugam Anand [https://twitter.com/SugamAnand] for additional\ndesign support ✌️)\n\n\n--------------------------------------------------------------------------------\n\nWant weekly updates with more of our stories? Sign up for our newsletter!\n[https://mailchi.mp/go-jek/gojek-tech-newsletter] ✌️","html":"<p>By Jewel James</p><p>Are you looking for food? Thinking about burgers and crispy chicken fritters with creamy sauces sitting on a warm, soft bun? At least, that’s what I am thinking about. May be you’re different. Vegan perhaps? Or craving noodles? Each of us turn into a different person when we are hungry, and this is the story about how GoFood — Gojek’s food delivery service — helps you find the bite you crave.</p><blockquote><em><em>At the core of the food ordering experience, sits search.</em></em></blockquote><p>Searches are part of so many of our interactions on web and mobile, that we don’t even notice it anymore. This is mostly because modern search engines have matured to a point where they can deliver high quality results even if the entered query is a weak signal of the user’s intent. Even when weak, every query still contains a piece of the user’s intent.</p><p><em><em>In the case of GoFood, that piece is a fragment of our user’s hunger-driven brain.</em></em></p><p>In this post, we’ll discuss how we personalise the search results we surface on GoFood, based on the information we have about our users’ food preferences.</p><h1 id=\"how-each-of-us-differ\">How Each of Us Differ</h1><p>Let’s look at two of our GoFood users who have started feeling the pangs of hunger, and come online to check restaurants near them.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/3192/1*AP6fdakISbNOdEZyCUxa5g.jpeg\" class=\"kg-image\"></figure><p>They both open our app and click on the <code>NEAR ME</code> tile that lets users find the restaurants near them. We show them the nearest restaurants first, and this is what they both see.<br></p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/2322/1*tBxtTKY9cfA7rcl5LXq3Ag.jpeg\" class=\"kg-image\"></figure><p>This list goes on and on and will let them see each restaurant which is farther and farther away. They can now peruse the menus of each restaurant and pick one that serves what they feel like ordering. The problem is that they may spend some time scrolling and then leave the app without being able to make up their minds around which restaurant to place an order from. We have thrown too many choices at them and the cognitive effort of picking a restaurant and then a dish from the menu is too much work to make them suffer through.</p><p><strong><strong><em><em>But wait. Both Mila and Husain have transacted with us in the past, and we know a fair bit about their preferences.</em></em> 🤔</strong></strong></p><p>To make this experience better, we decided to build a system that would let both of them see restaurants that suit their own tastes and preferences</p><h1 id=\"applying-machine-learning-to-the-problem\">Applying Machine Learning to the Problem</h1><p>Ranking documents for relevance works by assigning a prediction score to each document retrieved, which is directly proportional to its relevance. In the case of <code>NEAR ME</code> restaurant ranking this can be something like:</p><blockquote><em><em><em>Relevance score = 2 * (1/distance) + 1.2 * rating of restaurant</em></em></em></blockquote><p>Here in the relevance score calculation, we are taking weighted sum of different factors like <em><em>(1/distance) </em></em>and <em><em>rating of restaurant</em></em>. The coefficients/weights of these factors can be arrived at by experimenting with them and choosing weights that seem to maximise the ordering conversions. But, in the case of restaurant ranking in GoFood, we want to take into consideration many factors when deciding relevance. Unfortunately, experimenting with combinations of all those factors is impossible.</p><p>Enter L<em><em>earning to rank</em></em>. Here, the problem of deciding the rank of the restaurants shown to the user is formulated as a supervised machine learning problem.</p><p>If we look at past search, click, and ordering data, we will be able to assign relevance judgements to each restaurant listing according to whether our users clicked or ordered from one of those restaurants. Restaurants that attracted higher degrees of interest will be given higher degrees of relevance.</p><p>In the below example, a relevance judgement level of 0,1 and 2 is assigned to a restaurant according to whether the user viewed, clicked, or ordered from the restaurant in the search result. The relevance judgements are relative and only intent to be monotonically increasing with increasing relevance . They say that the restaurant which the user created an order from is more relevant than a restaurant the user merely checked out by clicking on it. <strong><strong>They don’t mean that the restaurant which received the order is twice as relevant .</strong></strong></p><p>The values of each of the factors that could have played a role in the user’s decision of clicking or ordering is also shown against the restaurants.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/2376/1*X0Oe0KA7ZTU2wYa2SXS_CA.png\" class=\"kg-image\"></figure><p>Three of the factors/features in the above example are marked as ‘personalisation features’ because they would change according to the user’s previous order history and location. These will be the features that will be different between Mila and Husain because of the differences in the restaurants and cuisines they have ordered from before in the past.</p><blockquote>These personalisation features are at the crux of creating personalised experiences for each user</blockquote><p>Other customer agnostic features/factors like the rating, price range, and popularity of the restaurant are also listed here. GoFood has millions of such examples where users with different tastes made different decisions when shown a set of search results. These examples can now be used to create a dataset from which the learning to rank ML algorithm can create a model to decide how relevant a GoFood user would find a restaurant given that user’s location, order history and other restaurant statistics.</p><h1 id=\"how-we-ranked\">How We Ranked</h1><p>One way to approach this was as a point-wise ranking problem, wherein we try to predict the relevance judgement of each restaurant. Based on this, later we will predict the relevance judgement level and sort restaurants in decreasing order of predicted relevance score. This approach reduces learning to rank problem to a regression problem.</p><p>Another approach was to solve it is a pairwise ranking problem, wherein the ML model is trying to learn how to get the order of a pair of restaurants correct i.e if Restaurant A is more preferable to Restaurant B , the order (Restaurant A, Restaurant B) is correct and the order (Restaurant B, Restaurant A) is wrong.</p><p>For an ML model to be learned, we need an objective function that captures this pairwise ordering formulation . This is called a loss function or error function in ML and is the measure through which an ML model can assess how right or wrong its decision was. In pairwise ranking , this should be a function that becomes higher whenever the model misjudges a preference order and becomes lower when it is right about the preference order.</p><p>The loss/error function <strong><strong><em><em>C</em></em></strong></strong> is explained below:</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/3316/1*2sWi_7l1iI_-dRppVoaGRA.png\" class=\"kg-image\"></figure><p>When this function is minimised, the model is trying to predict a score for each restaurant such that the ranking of the order of the restaurants are close the relevance judgements the users made.</p><p>The pairwise formulation is a better approach here in comparison to the point-wise approach as it is looking to get the order of restaurants right and is not trying to estimate the relevance score themselves whose values were assigned only as markers to show how some restaurants were more preferred relative to others.</p><p>We used an implementation of the LambdaMART algorithm that learns to predict relevance scores so as to minimise this pairwise loss. You can think of this as a pursuit to find the decision tree that takes in all the parameters of the restaurant and gives out a score to the restaurant . This score should be assigned in such a way as to make the pair orders right.</p><p>Once this model is trained, it can be used during search, as explained in <a href=\"https://blog.gojekengineering.com/how-the-gojek-butler-serves-a-gourmet-meal-to-our-users-4a161d83052a?source=friends_link&amp;sk=42397976fe914a418ac40f19545f90b7\">this post</a>.</p><p>Now let’s go back to our beloved customers — Mila and Husain. The next time Mila or Husain looks for restaurants near them, the search results they see will be according to their preferences. This is because the model would look at the number of times they have ordered from each of the restaurants near them before. It would take their preferred cuisines and factors like restaurant ratings into account, and show them the restaurants that they would prefer to order from first.</p><p>The different search results Mila and Husain get after learning to rank is used to re-rank the results are shown below.</p><figure class=\"kg-card kg-image-card kg-width-wide\"><img src=\"https://miro.medium.com/max/7545/1*ALMsK5OzG3rUACrx_U3E0g.jpeg\" class=\"kg-image\"></figure><p>We ran an AB test using this formulation of learning to rank and observed a relative lift of 20% in search to ordering conversions and 23% improvement in NDCG. More information on how this metric is calculated <a href=\"https://blog.gojekengineering.com/is-this-what-you-were-looking-for-439bf012cca6?source=friends_link&amp;sk=bdc1310acc3b6a8270f10284cb30fa53\" rel=\"noopener\">here</a>.</p><h1 id=\"what-we-learned\">What We Learned</h1><p>One interesting thing we observed as we started experimenting with this learning to rank model was personalising search results led to the average position at which the search to order conversions happen to be much higher on the list. This is because users were increasingly seeing the restaurants that they have some affinity towards and were able to make an ordering decision without scrolling much and without spending too much time being confused where to order from.</p><p>So that’s how we rank restaurant pairs with respect to relevance based on available user data. We’ll continue to write more about how we make our products more intuitive. Stay tuned to this blog, or <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">sign up for our newsletter</a> for email updates. 👌</p><hr><p>(Special thanks to <a href=\"https://twitter.com/SugamAnand\" rel=\"noopener\">Sugam Anand</a> for additional design support ✌️)</p><hr><p>Want weekly updates with more of our stories? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter!</a> ✌️</p>","url":"https://gojek-ghost.zysk.in/the-secret-sauce-behind-search-personalisation/","canonical_url":null,"uuid":"f53d2946-dab7-43e3-af3b-5453077e95ee","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb12ec4f7c7da001effce0f","reading_time":7}},{"node":{"id":"Ghost__Post__5ec2ca287aa22c4066f83b68","title":"Batch Processing Pipelines for Better Data Analysis","slug":"batch-processing-pipelines-for-better-data-analysis","featured":false,"feature_image":"https://gojek-ghost.zysk.in/content/images/2020/05/1_EbT2AH9uAMjxHrVxh5xJrw.jpeg","excerpt":"How we generate intelligible insights from our data warehouse using batch pipelines.","custom_excerpt":"How we generate intelligible insights from our data warehouse using batch pipelines.","visibility":"public","created_at_pretty":"18 May, 2020","published_at_pretty":"11 November, 2019","updated_at_pretty":"18 May, 2020","created_at":"2020-05-18T23:17:20.000+05:30","published_at":"2019-11-11T09:30:00.000+05:30","updated_at":"2020-05-18T23:34:54.000+05:30","meta_title":null,"meta_description":"How we generate intelligible insights from our data warehouse using batch pipelines.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Maulik Soneji\n\nGojek’s Data Warehouse [https://en.wikipedia.org/wiki/Data_warehouse], built by\nintegrating data from multiple applications and sources, serves as a central\npoint of analysis that also helps generate actionable insights. Our batch\npipelines process billions of data points periodically, in order to help our\nbusiness teams gather an effective view of data.\n\nThis post explains our approach to building batch pipelines that leverage\ncomplex data in an efficient way.\n\nI will start by providing some context on our data warehouse and the data we\nstore in it, and explain the use cases of batch processing that we tackle at\nGojek. Then we’ll talk about how we tackle running batch processing jobs and\nhandling scheduling dependencies.\n\nData Warehouse setup\nAt Gojek, we use Google Bigquery (BQ) as a Data Warehouse. All data points\nranging from booking and searches to location are published in real time using \nBeast [https://github.com/gojek/beast], our open-sourced tool.\n\nWe also push data from Kafka to our data lake, which is Google Cloud\nStorage(GCS). These data points vary in terms of the data format (which might\nnot be relevant to the analysts). They need to gather insights from the data\nwithout needing to know how it is stored.\n\n> To solve this, we wanted to create an abstraction such that the users of data\nonly need to know about the constitution of data, and not about where the data\nis coming from or what format the data is stored.\nBatch processing use cases\nTypical use cases of batch processing at Gojek revolve around enriching\nreal-time data with additional data points mined from huge amounts of historical\ndata.\n\nA few examples of use cases include:\n\nCreating a customer profile:\n\nIn order to provide our customers with the most relevant discount and deal\nvouchers, we enrich customer profiles with the last few months of the customer’s\norder and search history. This enables our team of data analysts and data\nscientists to experiment with customer segmentation and targeting. This use case\nhas been covered in much detail by my colleague Mayank in this blog\n[https://blog.gojekengineering.com/how-we-solved-user-selection-to-help-merchants-win-business-519fe5085a0e]\n.\n\nPersonalising search results:\n\nIn order to personalise the search results served up by our food delivery app\nGoFood, we leverage batch processing to gather insights about trending, popular,\nand highly-rated restaurants near the user that match their taste profile. More\ndetails around how we went about this use case are covered in this blog\n[https://blog.gojekengineering.com/how-the-gojek-butler-serves-a-gourmet-meal-to-our-users-4a161d83052a]\n.\n\nRunning Batch pipelines\nAs I previously mentioned, the users of data usually don’t need to know the\nformat in which the data is stored. They would benefit from having a unified\ninterface to interact with data.\n\nWe leveraged Dataframes in Apache Spark [https://spark.apache.org/] to provide\nthe unified interface.\n\nDataFrames or Datasets\nSpark provides an abstraction on top of the data underneath — called DataFrames\nor Datasets.\n\nDataFrames are distributed collections of data in which data is organised in the\nform of columns.\n\nConceptually, a data frame becomes similar to a database.\n\nFew examples of reading from Bigquery and GCS are as follows:\n\nClient to read data from bigquery into spark dataframe.\n\nClient to read data from GCS into spark dataframe\n\nUsing these clients make it very easy for our analysts to read GCS and Bigquery\ndata into Spark and interact with it.\n\nRunning Spark Jobs\nWe use Google Dataproc [https://cloud.google.com/dataproc/] hosting a Spark\ncluster to run our batch pipelines. On each trigger of a batch job, we create an\nephemeral cluster to run the job, which means that the cluster is destroyed\nafter the batch job completes.\n\nThe batch job is written in Pyspark\n[https://spark.apache.org/docs/2.2.0/api/python/pyspark.html], which all our\nanalysts are familiar with. This provides a good interface to interact with\nSpark Dataframes.\n\nScheduling Dependencies between Jobs\nAs the Spark jobs become more complex and handle many responsibilities, it\nbecomes important to break them down into simpler jobs that can be better\nmanaged.\n\n> But this breakdown brings more challenges.\nWe now have to make sure the related jobs are scheduled taking in mind the\nscheduling dependencies between different jobs.\n\nFor example:\nIf there are two jobs, the first one calculates the last 6 months of order\nhistory and the second job uses the order history to calculate the preferred\nlocations from which the customer has ordered, it becomes important to run the\nfirst job and then schedule the second job.\n\nOur solution to handle such scheduling dependencies is to use Apache Airflow\n[https://airflow.apache.org/]. This is a tool to programmatically schedule and\nmanage scheduling dependencies between different jobs.\n\nThe scheduling dependencies are written as a Directed Acyclic Graph (DAG) and we\nset a schedule for the DAG to run. Simple. 🙂\n\nWith Airflow, we are also able to assign retries for each job. In the instance\nof a job failing, Airflow will rerun the job by itself.\n\nAs a final precaution, we have also added Slack integration and StatsD metrics\nwith Airflow, in order to get alerts for when the jobs have failed and need to\nbe fixed.\n\nSo that’s all for this post. Hope you liked it! If you’d like to work on cool\nproblems and help us scale a #SuperApp for Southeast Asia, make sure to check\nout gojek.jobs [http://bit.ly/2CvjmXv]. Until next time. 🖖\n\n\n--------------------------------------------------------------------------------\n\nWant our updates delivered straight to your inbox? Sign up for our newsletter!\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]","html":"<p>By Maulik Soneji</p><p>Gojek’s <a href=\"https://en.wikipedia.org/wiki/Data_warehouse\" rel=\"noopener\">Data Warehouse</a>, built by integrating data from multiple applications and sources, serves as a central point of analysis that also helps generate actionable insights. Our batch pipelines process billions of data points periodically, in order to help our business teams gather an effective view of data.</p><p>This post explains our approach to building batch pipelines that leverage complex data in an efficient way.</p><p>I will start by providing some context on our data warehouse and the data we store in it, and explain the use cases of batch processing that we tackle at Gojek. Then we’ll talk about how we tackle running batch processing jobs and handling scheduling dependencies.</p><h1 id=\"data-warehouse-setup\">Data Warehouse setup</h1><p>At Gojek, we use Google Bigquery (BQ) as a Data Warehouse. All data points ranging from booking and searches to location are published in real time using <a href=\"https://github.com/gojek/beast\" rel=\"noopener\"><strong><strong>Beast</strong></strong></a><strong><strong>, </strong></strong>our open-sourced tool.</p><p>We also push data from Kafka to our data lake, which is Google Cloud Storage(GCS). These data points vary in terms of the data format (which might not be relevant to the analysts). They need to gather insights from the data without needing to know how it is stored.</p><blockquote><em><em>To solve this, we wanted to create an abstraction such that the users of data only need to know about the constitution of data, and not about where the data is coming from or what format the data is stored.</em></em></blockquote><h1 id=\"batch-processing-use-cases\"><strong>Batch processing use cases</strong></h1><p>Typical use cases of batch processing at Gojek revolve around enriching real-time data with additional data points mined from huge amounts of historical data.</p><p>A few examples of use cases include:</p><p><strong><strong>Creating a customer profile:</strong></strong></p><p>In order to provide our customers with the most relevant discount and deal vouchers, we enrich customer profiles with the last few months of the customer’s order and search history. This enables our team of data analysts and data scientists to experiment with customer segmentation and targeting. This use case has been covered in much detail by my colleague Mayank in this <a href=\"https://blog.gojekengineering.com/how-we-solved-user-selection-to-help-merchants-win-business-519fe5085a0e\" rel=\"noopener\">blog</a>.</p><p><strong><strong>Personalising search results:</strong></strong></p><p>In order to personalise the search results served up by our food delivery app GoFood, we leverage batch processing to gather insights about trending, popular, and highly-rated restaurants near the user that match their taste profile. More details around how we went about this use case are covered in this <a href=\"https://blog.gojekengineering.com/how-the-gojek-butler-serves-a-gourmet-meal-to-our-users-4a161d83052a\" rel=\"noopener\">blog</a>.</p><h1 id=\"running-batch-pipelines\">Running Batch pipelines</h1><p>As I previously mentioned, the users of data usually don’t need to know the format in which the data is stored. They would benefit from having a unified interface to interact with data.</p><p><em><em>We leveraged Dataframes in </em></em><a href=\"https://spark.apache.org/\" rel=\"noopener\"><em><em>Apache Spark</em></em></a><em><em> to provide the unified interface.</em></em></p><h2 id=\"dataframes-or-datasets\"><strong>DataFrames or Datasets</strong></h2><p>Spark provides an abstraction on top of the data underneath — called DataFrames or Datasets.</p><p>DataFrames are distributed collections of data in which data is organised in the form of columns.</p><p><strong><strong>Conceptually, a data frame becomes similar to a database.</strong></strong></p><p>Few examples of reading from Bigquery and GCS are as follows:</p><!--kg-card-begin: html--><script src=\"https://gist.github.com/mauliksoneji/48d7d84976ee5957de90e03ba2314540.js\"></script><!--kg-card-end: html--><p><em>Client to read data from bigquery into spark dataframe.</em></p><!--kg-card-begin: html--><script src=\"https://gist.github.com/mauliksoneji/0a8c12d3c7ecbe2c4794dbd039e03815.js\"></script><!--kg-card-end: html--><p><em>Client to read data from GCS into spark dataframe</em></p><p>Using these clients make it very easy for our analysts to read GCS and Bigquery data into Spark and interact with it.</p><p><strong><strong>Running Spark Jobs</strong></strong><br>We use <a href=\"https://cloud.google.com/dataproc/\" rel=\"noopener\">Google Dataproc</a> hosting a Spark cluster to run our batch pipelines. On each trigger of a batch job, we create an ephemeral cluster to run the job, which means that the cluster is destroyed after the batch job completes.</p><p>The batch job is written in <a href=\"https://spark.apache.org/docs/2.2.0/api/python/pyspark.html\" rel=\"noopener\">Pyspark</a>, which all our analysts are familiar with. This provides a good interface to interact with Spark Dataframes.</p><h1 id=\"scheduling-dependencies-between-jobs\"><strong>Scheduling Dependencies between Jobs</strong></h1><p>As the Spark jobs become more complex and handle many responsibilities, it becomes important to break them down into simpler jobs that can be better managed.</p><blockquote>But this breakdown brings more challenges.</blockquote><p>We now have to make sure the related jobs are scheduled taking in mind the scheduling dependencies between different jobs.</p><p><strong><strong>For example:</strong></strong><br>If there are two jobs, the first one calculates the last 6 months of order history and the second job uses the order history to calculate the preferred locations from which the customer has ordered, it becomes important to run the first job and then schedule the second job.</p><p>Our solution to handle such scheduling dependencies is to use <a href=\"https://airflow.apache.org/\" rel=\"noopener\">Apache Airflow</a>. This is a tool to programmatically schedule and manage scheduling dependencies between different jobs.</p><p>The scheduling dependencies are written as a Directed Acyclic Graph (DAG) and we set a schedule for the DAG to run. Simple. 🙂</p><p>With Airflow, we are also able to assign retries for each job. In the instance of a job failing, Airflow will rerun the job by itself.</p><p>As a final precaution, we have also added Slack integration and StatsD metrics with Airflow, in order to get alerts for when the jobs have failed and need to be fixed.</p><p>So that’s all for this post. Hope you liked it! If you’d like to work on cool problems and help us scale a #SuperApp for Southeast Asia, make sure to check out <a href=\"http://bit.ly/2CvjmXv\" rel=\"noopener\">gojek.jobs</a>. Until next time. 🖖</p><hr><p>Want our updates delivered straight to your inbox? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\">Sign up for our newsletter!</a></p>","url":"https://gojek-ghost.zysk.in/batch-processing-pipelines-for-better-data-analysis/","canonical_url":null,"uuid":"0d510c4e-75d7-409e-97c0-5414539cb91f","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec2ca287aa22c4066f83b68","reading_time":3}},{"node":{"id":"Ghost__Post__5ec2d7d17aa22c4066f83c9a","title":"The Road to a Merchant SuperApp","slug":"the-road-to-a-merchant-superapp","featured":false,"feature_image":"https://gojek-ghost.zysk.in/content/images/2020/05/1.gif","excerpt":"How we tried, failed, and tried again — to build a full-fledged platform for our merchant partners.","custom_excerpt":"How we tried, failed, and tried again — to build a full-fledged platform for our merchant partners.","visibility":"public","created_at_pretty":"18 May, 2020","published_at_pretty":"01 November, 2019","updated_at_pretty":"18 May, 2020","created_at":"2020-05-19T00:15:37.000+05:30","published_at":"2019-11-01T09:30:00.000+05:30","updated_at":"2020-05-19T00:23:10.000+05:30","meta_title":null,"meta_description":"How we tried, failed, and tried again — to build a full-fledged platform for our merchant partners.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":null,"profile_image":null,"twitter":"@gojektech","facebook":null,"website":"http://www.gojek.io"},"primary_tag":{"name":"Stories","slug":"stories","description":"Deep dives into high-impact initiatives and products that helped Gojek create significant impact.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Stories","slug":"stories","description":"Deep dives into high-impact initiatives and products that helped Gojek create significant impact.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"By Sooraj Rajmohan\n\nEarlier this year, during a visit to Gojek’s HQ in Jakarta, a few of us from the\nGojek Marketing team had a craving to try Indonesia’s famed fried delicacy — \npisang goreng.\n\nToday, fulfilling such food cravings is a simple process. GoFood — Gojek’s food\ndelivery product — lists 400,000+ merchants. You search for the outlet you want\nto order from, select the item and quantity, check out, and pay either via cash\nor Gojek’s digital wallet GoPay. Then, you sit back and watch the little Gojek\ndriver partner on the screen zoom their way to the restaurant, and bring you\nsome fried banana goodness. 😍\n\nSimple. Fast. Reliable.\n\n> Rewind a few years, and things didn’t look so good.\nFirst, some context\nWhen GoFood launched in 2015, expansion and adoption happened rapidly. The\norders started piling in, and we were struggling to keep up with demand.\nInitially, we’d simply list food merchants on our marketplace, send demand their\nway, and fulfil it through our fleet of driver partners.\n\nWe were building for our consumers and driver partners, but merchants were\nalways a key component of our ecosystem. If Gojek is an iceberg, the\nconsumer-facing Super App is the part above water. In this story, we’ll dive\nbeneath the surface to explore another key component — GoBiz, our merchant\nSuperApp.\n\n> But before GoBiz, there was GoResto.\nThe Merchant Problem\nIf we had ordered ourselves that pisang goreng in the early days of GoFood,\nthings would have worked very differently.\n\nYou see, merchants were onboarded by the GoFood team by uploading their menus to\nour systems. We’d look through these menus to find our fried banana of choice,\nand make an order, which would be relayed directly to a driver partner. This\npartner would then go to the restaurant and place the order (which is when the\nmerchant partner gets involved in the process).\n\nSo, while our bananas are fried, the driver partner would wait around, and when\nthe order is ready, pay in cash. The problem with this approach was that there\nwas no record of the transaction besides a booking on GoFood and a receipt\nhanded to the driver partner.\n\nThis was an inefficient system, for driver partners, and our customers.\n\n> Oh, and those merchants? Things weren’t rosy for them either.\nLet’s assume our pisang goreng place is a GoFood partner (meaning Gojek collects\ncommissions for the increased demand we send their way), and also part of a\nlarger chain. When we place the order, GoFood will assign it to one outlet of\nthe chain. However, our driver partner may decide to visit another outlet and\npick up the order from there.\n\nAt the end of the month, our restaurant partners would be invoiced for\ncommission that was due to us, based on sales as reported by the GoFood app.\nThis meant we were charging some merchants commission for sales their outlet may\nhave never made.\n\nWe spent a lot of time and resources addressing merchant complaints. 🤦‍♂️\n\n> Then there was the matter of control.\nIf a merchant partner was not open for business on a particular day, wanted to\nupdate their menu, or indicate items as out of stock, they had to call Gojek\nCustomer Care. During this time, orders might still be coming in.\n\nLet’s just say we weren’t doing ourselves any favours. 🤷🏻‍♂️\n\nThere was a lot that needed fixing here, and it could only be done by\nintegrating merchants more deeply into our ecosystem. So that’s what we did.\n\nThe birth of GoResto\nTowards the end of 2016, a concept was developed for an app that would cater to\nGoFood merchant partners, and by early 2017 GoResto — which is what we called it\nat the time — was ready. You can read more about the product research process\nthat went into making GoResto here\n[https://blog.gojekengineering.com/whats-cooking-diving-into-kitchens-for-go-biz-e01051bfdc98]\n).\n\nWith GoResto, we addressed some of the problems outlined earlier.\n\n1. Electronic payments\nAll of Gojek’s driver partners had GoPay e-wallets associated with their\naccounts. With GoResto, we did the same for GoFood merchants. Transactions\nbetween driver and merchant partners would now be wallet-to-wallet, not cash.\nGojek would deduct any applicable commission immediately from the merchant\nwallet. This made the reconciliation process with merchants simpler.\n\n2. PIN exchange for restaurant verification\nTo eliminate fraud, driver partners would also need to share a PIN with the\nmerchant while picking up the order. This electronic handshake helped us verify\nthey were indeed picking up the right order from the right outlet.\n\nIt was a decent solution. If all went according to plan, we could breathe easy.\n\n> As you might have guessed, all did not go according to plan. 🙇‍♂️\nIn the first iteration, the wallet creation process required collaboration with\nthe GoPay team, which was itself facing bandwidth constraints due to rapid\ngrowth (which we’ll talk about a little later).\n\nAlso, the merchant onboarding to GoResto at this point was still a manual\nprocess. In our first month, we onboarded only 26 merchants. 😣\n\nWe needed a more scalable solution.\n\nHere’s a quick note on Gojek company culture. When the chips are down, it’s\nimportant for organisations to have core values to guide decision-making. One of\nour values happens to be:\n\nThis line is an affirmation to all stakeholders to take the best decision for a\nparticular situation based on available information. Such decisions are then\nrespected by everyone else.\n\nWe made two drastic decisions:\n\n 1. Merchant onboarding was completely frozen until we could build a platform to\n    automate the process.\n 2. Engineers from the Merchants team were embedded within GoPay, building\n    required capacities on GoPay systems while core GoPay engineers continued\n    work on scaling the platform.\n\n> In three months, as summer rolled around, GoResto was back.\nWe weren’t out of the woods yet though. All this was happening before Gojek had\ndeprecated its legacy codebase, Stan Marsh\n[https://blog.gojekengineering.com/thank-you-stan-marsh-29db553544bf], in favour\nof microservices, so system stability was not exactly excellent. As a result, we\nstill faced sync issues between GoFood and GoResto order management systems.\nThis, in turn, began to reflect on us publicly.\n\nOur app store rating at this point slid down to 3.2.\n\nMake It Work, Then Make It Better\nWe clearly had a long way to go to make GoResto the app our merchants deserved.\nThings were bad, but as they say — sometimes the only way out is through.\n\nChallenge accepted. 💪\n\nFirst things first, we went about fixing the sync issues by building a second\nsystem to replace our unreliable version. Not only was this accomplished, but\nall onboarded merchants were migrated to the new system, with zero downtime. \nRead more about how this was done in this post\n[https://blog.gojekengineering.com/zero-downtime-traffic-migration-at-go-food-17ba413eb8c2]\n.\n\n> One small win.\nNow for the real problems, giving merchants the control they needed over how\nthey were represented on GoFood. The first self-serve feature we introduced to\nGoResto was allowing merchants to update their restaurant status in real time.\n\n> Another small win.\nWe had unlocked a critical component in product design — empathy for the people\nyou’re building for. The question now was — what can we do that will make life\neasier for our merchants?\n\nItem availability? Understood.\nMenu updation? Got it.\nPricing adjustments? Why not.\nAdd categories? Move items between categories? Update images?\n\n> Done, done… and done. ✅\nOur systems were stable, early teething troubles were addressed, we were finally\nsolving the problems that needed solving.\n\nBuild It Right, And They Will Come\nAs GoResto grew in functionality, we began\n\n slowly earning back the goodwill of our merchant community. Soon, our app store\nrating began to reflect that.\n\nApp store ratings reflecting how customer goodwill can be earned back ✌️We\ndidn’t need to push GoResto to merchants anymore, it was adopted due to the ease\nof doing business it offered.\n\n> It was long overdue, but we had accomplished what we had set out to do. There\nwas finally a moment to sit back and enjoy the sunrise.\nOr so we thought.\n\nThe rest was short-lived. Southeast Asia was abuzz with activity. According to\nthis report\n[https://www.blog.google/documents/47/SEA_Internet_Economy_Report_2019.pdf], the\nvalue of the Internet economy in the region tripled in the years since 2015. The\nGross Merchandise Value (GMV) projection for 2025 is estimated to be $300\nbillion.\n\n> To put that in perspective — in 2016, that projection was $100 billion.\nEven as GoResto was being built, there was another behemoth stirring under the\nrich waters of Indonesia’s digital payments landscape. GoPay, which had been\nrapidly growing in this favourable environment since its arrival in 2016, was\nnow being used by roughly three-quarters of digital payments users in Indonesia.\n\nBut we wanted more.\n\nIn 2018, GoPay introduced offline acceptance, bringing a whole new category of\nmerchant partners into our ecosystem.\n\n> Our existing solution wasn’t good enough anymore. It was time to evolve.\nKeep watching this space for the continued story charting GoResto’s evolution\ninto our full-fledged merchants platform — GoBiz.\n\n\n--------------------------------------------------------------------------------\n\nWant our updates beamed straight to your inbox? Sign up for our newsletter!\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]","html":"<p>By Sooraj Rajmohan</p><p>Earlier this year, during a visit to Gojek’s HQ in Jakarta, a few of us from the Gojek Marketing team had a craving to try Indonesia’s famed fried delicacy — <em><em>pisang goreng.</em></em></p><p>Today, fulfilling such food cravings is a simple process. GoFood — Gojek’s food delivery product — lists 400,000+ merchants. You search for the outlet you want to order from, select the item and quantity, check out, and pay either via cash or Gojek’s digital wallet GoPay. Then, you sit back and watch the little Gojek driver partner on the screen zoom their way to the restaurant, and bring you some fried banana goodness. 😍</p><p><strong><strong>Simple. Fast. Reliable.</strong></strong></p><blockquote>Rewind a few years, and things didn’t look so good.</blockquote><h1 id=\"first-some-context\">First, some context</h1><p>When GoFood launched in 2015, expansion and adoption happened rapidly. The orders started piling in, and we were struggling to keep up with demand. Initially, we’d simply list food merchants on our marketplace, send demand their way, and fulfil it through our fleet of driver partners.</p><p>We were building for our consumers and driver partners, but merchants were always a key component of our ecosystem. If Gojek is an iceberg, the consumer-facing Super App is the part above water. In this story, we’ll dive beneath the surface to explore another key component — GoBiz, our merchant SuperApp.</p><blockquote>But before GoBiz, there was GoResto.</blockquote><h1 id=\"the-merchant-problem\">The Merchant Problem</h1><p>If we had ordered ourselves that <em><em>pisang goreng</em></em> in the early days of GoFood, things would have worked very differently.</p><p>You see, merchants were onboarded by the GoFood team by uploading their menus to our systems. We’d look through these menus to find our fried banana of choice, and make an order, which would be relayed directly to a driver partner. This partner would then go to the restaurant and place the order (which is when the merchant partner gets involved in the process).</p><p>So, while our bananas are fried, the driver partner would wait around, and when the order is ready, pay in cash. The problem with this approach was that there was no record of the transaction besides a booking on GoFood and a receipt handed to the driver partner.</p><p>This was an inefficient system, for driver partners, and our customers.</p><blockquote><em><em>Oh, and those merchants? Things weren’t rosy for them either.</em></em></blockquote><p>Let’s assume our <em><em>pisang goreng</em></em> place is a GoFood partner (meaning Gojek collects commissions for the increased demand we send their way), and also part of a larger chain. When we place the order, GoFood will assign it to one outlet of the chain. However, our driver partner may decide to visit another outlet and pick up the order from there.</p><p>At the end of the month, our restaurant partners would be invoiced for commission that was due to us, based on sales as reported by the GoFood app. This meant we were charging some merchants commission for sales their outlet may have never made.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/428/1*-ZP7pyLDGJo31gjM1kbr2Q.jpeg\" class=\"kg-image\"></figure><p><strong><strong>We spent a lot of time and resources addressing merchant complaints. </strong></strong>🤦‍♂️</p><blockquote>Then there was the matter of control.</blockquote><p>If a merchant partner was not open for business on a particular day, wanted to update their menu, or indicate items as out of stock, they had to call Gojek Customer Care. During this time, orders might still be coming in.</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/723/1*7mru-w9gwgvBTO-wReUymw.jpeg\" class=\"kg-image\"></figure><p><strong><strong>Let’s just say we weren’t doing ourselves any favours. 🤷🏻‍♂️</strong></strong></p><p>There was a lot that needed fixing here, and it could only be done by integrating merchants more deeply into our ecosystem. So that’s what we did.</p><h1 id=\"the-birth-of-goresto\">The birth of GoResto</h1><p>Towards the end of 2016, a concept was developed for an app that would cater to GoFood merchant partners, and by early 2017 GoResto — which is what we called it at the time — was ready. You can read more about the product research process that went into making GoResto <a href=\"https://blog.gojekengineering.com/whats-cooking-diving-into-kitchens-for-go-biz-e01051bfdc98\" rel=\"noopener\">here</a>).</p><p><strong><strong><em><em>With GoResto, we addressed some of the problems outlined earlier.</em></em></strong></strong></p><h2 id=\"1-electronic-payments\">1. Electronic payments</h2><p>All of Gojek’s driver partners had GoPay e-wallets associated with their accounts. With GoResto, we did the same for GoFood merchants. Transactions between driver and merchant partners would now be wallet-to-wallet, not cash. Gojek would deduct any applicable commission immediately from the merchant wallet. This made the reconciliation process with merchants simpler.</p><h2 id=\"2-pin-exchange-for-restaurant-verification\">2. PIN exchange for restaurant verification</h2><p>To eliminate fraud, driver partners would also need to share a PIN with the merchant while picking up the order. This electronic handshake helped us verify they were indeed picking up the right order from the right outlet.</p><p>It was a decent solution. If all went according to plan, we could breathe easy.</p><blockquote>As you might have guessed, all did not go according to plan. 🙇‍♂️</blockquote><p>In the first iteration, the wallet creation process required collaboration with the GoPay team, which was itself facing bandwidth constraints due to rapid growth (which we’ll talk about a little later).</p><p>Also, the merchant onboarding to GoResto at this point was still a manual process. In our first month, we onboarded only 26 merchants. 😣</p><p>We needed a more scalable solution.</p><p>Here’s a quick note on Gojek company culture. When the chips are down, it’s important for organisations to have core values to guide decision-making. One of our values happens to be:</p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/1326/1*AcfpMzeJqM2bj5x8TedY7A.jpeg\" class=\"kg-image\"></figure><p>This line is an affirmation to all stakeholders to take the best decision for a particular situation based on available information. Such decisions are then respected by everyone else.</p><p>We made two drastic decisions:</p><ol><li>Merchant onboarding was completely frozen until we could build a platform to automate the process.</li><li>Engineers from the Merchants team were embedded within GoPay, building required capacities on GoPay systems while core GoPay engineers continued work on scaling the platform.</li></ol><blockquote>In three months, as summer rolled around, GoResto was back.</blockquote><p>We weren’t out of the woods yet though. All this was happening before Gojek had deprecated its legacy codebase, <a href=\"https://blog.gojekengineering.com/thank-you-stan-marsh-29db553544bf\" rel=\"noopener\">Stan Marsh</a>, in favour of microservices, so system stability was not exactly excellent. As a result, we still faced sync issues between GoFood and GoResto order management systems. This, in turn, began to reflect on us publicly.</p><p><strong><strong>Our app store rating at this point slid down to 3.2.</strong></strong></p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/794/1*tK41Ht4hzRXSuKNR5w2qxA.jpeg\" class=\"kg-image\"></figure><h1 id=\"make-it-work-then-make-it-better\">Make It Work, Then Make It Better</h1><p>We clearly had a long way to go to make GoResto the app our merchants deserved. Things were bad, but as they say — sometimes the only way out is through.</p><p><strong><strong>Challenge accepted. 💪</strong></strong></p><p>First things first, we went about fixing the sync issues by building a second system to replace our unreliable version. Not only was this accomplished, but all onboarded merchants were migrated to the new system, with <em><em>zero downtime. </em></em>Read more about how this was done <a href=\"https://blog.gojekengineering.com/zero-downtime-traffic-migration-at-go-food-17ba413eb8c2\" rel=\"noopener\">in this post</a>.</p><blockquote><em><em>One small win.</em></em></blockquote><p>Now for the real problems, giving merchants the control they needed over how they were represented on GoFood. The first self-serve feature we introduced to GoResto was allowing merchants to update their restaurant status in real time.</p><blockquote><em><em>Another small win.</em></em></blockquote><p>We had unlocked a critical component in product design — empathy for the people you’re building for. The question now was — what can we do that will make life easier for our merchants?</p><p><em><em>Item availability?</em></em> Understood.<br><em><em>Menu updation?</em></em> Got it.<br><em><em>Pricing adjustments?</em></em> Why not.<br><em><em>Add categories? Move items between categories? Update images?</em></em></p><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/522/1*bRzkmDwhHIrGOEJDz45a1A.jpeg\" class=\"kg-image\"></figure><blockquote>Done, done… and done. ✅</blockquote><p>Our systems were stable, early teething troubles were addressed, we were finally solving the problems that needed solving.</p><h1 id=\"build-it-right-and-they-will-come\">Build It Right, And They Will Come</h1><p>As GoResto grew in functionality, we began</p><p> slowly earning back the goodwill of our merchant community. Soon, our app store rating began to reflect that.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1864/1*j3tGYn7EvCzlh46jk5cyPw.png\" class=\"kg-image\"><figcaption>App store ratings reflecting how customer goodwill can be earned back ✌️</figcaption></figure><p>We didn’t need to push GoResto to merchants anymore, it was adopted due to the ease of doing business it offered.</p><blockquote><em><em>It was long overdue, but we had accomplished what we had set out to do. There was finally a moment to sit back and enjoy the sunrise.</em></em></blockquote><p>Or so we thought.</p><p>The rest was short-lived. Southeast Asia was abuzz with activity. <a href=\"https://www.blog.google/documents/47/SEA_Internet_Economy_Report_2019.pdf\" rel=\"noopener\">According to this report</a>, the value of the Internet economy in the region tripled in the years since 2015. The Gross Merchandise Value (GMV) projection for 2025 is estimated to be $300 billion.</p><blockquote>To put that in perspective — in 2016, that projection was $100 billion.</blockquote><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/884/1*cntOWzHiq2mS76fgLCSD7Q.jpeg\" class=\"kg-image\"></figure><p>Even as GoResto was being built, there was another behemoth stirring under the rich waters of Indonesia’s digital payments landscape. GoPay, which had been rapidly growing in this favourable environment since its arrival in 2016, was now being used by roughly three-quarters of digital payments users in Indonesia.</p><p><strong><strong>But we wanted more.</strong></strong></p><p>In 2018, GoPay introduced offline acceptance, bringing a whole new category of merchant partners into our ecosystem.</p><blockquote>Our existing solution wasn’t good enough anymore. It was time to evolve.</blockquote><p>Keep watching this space for the continued story charting GoResto’s evolution into our full-fledged merchants platform — GoBiz.</p><hr><p>Want our updates beamed straight to your inbox? <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">Sign up for our newsletter!</a></p>","url":"https://gojek-ghost.zysk.in/the-road-to-a-merchant-superapp/","canonical_url":null,"uuid":"122c2057-8d07-47b0-b573-1f6b888deedb","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5ec2d7d17aa22c4066f83c9a","reading_time":7}}]}},"pageContext":{"slug":"gojek","limit":12,"skip":0,"numberOfPages":3,"humanPageNumber":1,"prevPageNumber":null,"nextPageNumber":2,"previousPagePath":null,"nextPagePath":"/author/gojek/page/2/"}}}