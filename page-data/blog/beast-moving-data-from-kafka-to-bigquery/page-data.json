{"componentChunkName":"component---src-templates-post-js","path":"/blog/beast-moving-data-from-kafka-to-bigquery/","result":{"data":{"ghostPost":{"id":"Ghost__Post__5eb0fef85524cd001e739246","title":"Efficient Experimentation at Gojek","slug":"beast-moving-data-from-kafka-to-bigquery","featured":false,"feature_image":"https://res-5.cloudinary.com/hcq4cvthp/image/upload/q_auto/v1/ghost-blog-images/1_VVhMvfqoGY_h6W0-VW4iMQ.jpg","excerpt":"A breakdown of the tool we use to estimate the right audience sample size for our experiments.","custom_excerpt":"A breakdown of the tool we use to estimate the right audience sample size for our experiments.","visibility":"public","created_at_pretty":"05 May, 2020","published_at_pretty":"02 September, 2019","updated_at_pretty":"12 May, 2020","created_at":"2020-05-05T11:21:52.000+05:30","published_at":"2019-09-02T09:30:00.000+05:30","updated_at":"2020-05-12T11:53:43.000+05:30","meta_title":"Efficient Experimentation at Gojek","meta_description":"A breakdown of the tool we use to estimate the right audience sample size for our experiments.","og_description":null,"og_image":null,"og_title":null,"twitter_description":null,"twitter_image":null,"twitter_title":null,"authors":[{"name":"Gojek","slug":"gojek","bio":"Gojek is a Super App. It’s one app for ordering food, commuting, digital payments, shopping, hyper-local delivery, and two dozen services.","profile_image":"https://gojek-ghost.zysk.in/content/images/2020/05/logo-01-1.png","twitter":"@gojektech","facebook":"gojektech","website":"https://www.gojek.io"}],"primary_author":{"name":"Gojek","slug":"gojek","bio":"Gojek is a Super App. It’s one app for ordering food, commuting, digital payments, shopping, hyper-local delivery, and two dozen services.","profile_image":"https://gojek-ghost.zysk.in/content/images/2020/05/logo-01-1.png","twitter":"@gojektech","facebook":"gojektech","website":"https://www.gojek.io"},"primary_tag":{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"},"tags":[{"name":"Data","slug":"data","description":"Updates on Gojek's work in Data Science and Data Engineering—from infrastructure development to our experiments with AI and ML.","feature_image":null,"meta_description":null,"meta_title":null,"visibility":"public"}],"plaintext":"Experiments are wonderful things. They help us validate our hypotheses without\nhaving to involve our entire user base. However, any good experiment first\nrequires the answer to the question — how do we know the right number of people\nto include in it?\n\nLet’s break down why this is important. If we target too few, our experiments\nwill not detect smaller effects, leading us to miss legitimate opportunities. If\nwe target too many, we would be wasting resources and potentially hurting our\nbusiness metrics (if the treatments turn out to be detrimental).\n\nPreviously, we used simple heuristics (and a mysterious formula) to estimate the\nrequired sample size. These practices were not very scientific and produced\ninconsistent experimental results. To compensate, we had to repeat the same\nexperiment multiple times just to validate the results. Sometimes different\niterations would conflict with each other, leaving everyone scratching their\nheads.\n\nLast year, we ditched those unscientific practices and built a new tool called\nSample Size Calculator (yes, imaginative name, we know). This post explains how\nthe calculator helps us find the right number of people to include in\nexperiments.\n\nOur calculator is based on Frequentist school of statistics. Under the hood, we\nused both the pwr\n[https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html] \npackage and the base sample size calculation functions in R programming\nlanguage. This is what the tool looks like:\n\nFigure 1. Screenshot of the Sample Size Calculator used at GojekThe most\nimportant parameters are the type of dependent variable measured, the historical\ndata, and the required sensitivity from the experiment. As you can see in the\ngraph, if we increase sensitivity to allow detection of smaller effects, the\nrequired sample size soars, which makes sense.\n\nAlthough this is a major step in the right direction, there is a problem if we\nare interested in a continuous dependent variable for our experiment. This is\nbecause the underlying methodology used in the calculator assumes a normal\ndistribution, while most continuous metrics that we care about at Gojek — such\nas bookings per user — are usually skewed. By ‘skewed’, we mean that most users\nare light users and only a small percentage are heavy users. This could cause\nthe computed sample size requirement to be wrong because a key assumption was\nnot met.\n\nWe have four options to deal with this problem:\n\n 1. Use a methodology that doesn’t assume normality. Unfortunately, the\n    available non-parametric methods are complex to implement [1\n    [http://www.biostat.jhsph.edu/~ejohnson/regression/Sample%20Size%20Power%20Considerations.pdf]\n    ] [2 [https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4423589/]]\n 2. Transform data to have a normal distribution. This doesn’t always work —\n    some data just can’t be coerced to normal\n 3. Use a larger sample size. Since the worry is lower power than expected,\n    simple multiplication should boost the power, but the multiplier needs to be\n    reasonable. Figuring the right multiplier would be another beast on its own\n 4. Ignore it. This is the path we took\n\n> But but but… that’s not scientific!\nDon’t worry. We tested the robustness of this solution before going ahead with\nit.\n\nAs you can see in the graph below, we created two right-skewed distributions\nwith known 5% difference in means to serve as our populations. The plan is to\ncontinuously sample from this population (equivalent to replicating the same\nexperiment many times) and see how often we can detect this 5% difference (aka\nwhat is our “power [https://en.wikipedia.org/wiki/Power_(statistics)]”).\n\nFigure 2. Two right-skewed distributions (typical shape for continuous metric at\nGojek) with known mean difference (lift) of 5%The first step is to calculate the\nrequired sample size with a power of 80% and minimum detectable effect of 5%.\nLet’s refer to this sample size requirement as the “exact” size. Then we divide\nand multiply it by three and call them “less” and “more”, respectively. For each\nsample size, we sample from the populations, compute the mean difference\n(typically called “lift”), and repeat this procedure many times.\n\nThe resulting distributions of lifts are shown below. The coloured vertical\nlines show the average lift of each experimental size, which is also equal to\nthe actual population lift. This is central limit theorem\n[https://en.wikipedia.org/wiki/Central_limit_theorem] at work. What is\ninteresting are the relative shapes of the sampling distributions. The “more”\ngroup is the safest and most consistent but the “exact” group seems to have good\naccuracy with only a third of the sample size. In the “less” group, we even see\na non-negligible number of lifts that are negative, even though we know the\npopulation lift is actually +5%. This is in line with our intuition that larger\nsample size is generally more trustworthy than a smaller one, all else being\nequal.\n\nFigure 3. Sampling distribution of the mean difference from each size groupSince\nwe currently report the statistical significance of our experimental results at\nGojek, we will also run t-test for each of our sample here.\n\nAs it turns out, 80.4% of the experiments in the “exact” group have\nstatistically significant results (p < 0.05), which is almost equal to the 80%\npower we set in the sample size calculator. In layman’s terms, the tool roughly\npromised that if you run the experiment with this sample size, you have 80%\nchance of detecting a 5% lift (the minimum detectable effect) if it’s there.\n\nSince it kept its promise even on non-normally distributed data, we can conclude\nthat the methodology is robust to some degree of violation of the normality\nassumption. Therefore we can ignore it until otherwise proven.\n\nFigure 4. Percentage of samples/experiments with statistically significant\nresults (p < 0.05) from each size groupMeanwhile, the “less” group had only ~34%\nstatistically significant results, suggesting that we shouldn’t run an\nexperiment if we cannot fulfil the sample size requirement — since we risk not\nbeing able to detect an existing effect. With the “more” group having close to\n100% statistically significant results, we again reaffirm that larger sample\nsize is generally a good thing if we can afford it.\n\nSince it was deployed in mid-2018, many teams across Gojek have adopted the\nSample Size Calculator. So far, nearly 1,000 experiments have incorporated this\ntool in their designs, and it is also a part of Litmus, our experimentation\nplatform\n[https://blog.gojekengineering.com/introducing-litmus-gojeks-own-experimentation-platform-3803467b6a53]\n. The more critical takeaway for us is that the experiments run using the\nrecommended sample sizes have similar results when full-scaled. This fact has\nenabled us to iterate faster and cut waste while maintaining a high degree of\nconfidence in the experimental results. ✌️\n\nDid we mention Gojek’s Growth team is hiring analysts? We are a super\ndata-driven team and have helped shape some of the company’s best practices\nthrough projects like this. If you are analytical, interested in sharpening your\ntechnical chops, and want to have a meaningful impact to Gojek’s hypergrowth,\ncome join us!\n\n\n--------------------------------------------------------------------------------\n\nFor more updates like this, don’t forget to sign up for our newsletter\n[https://mailchi.mp/go-jek/gojek-tech-newsletter]!","html":"<p>Experiments are wonderful things. They help us validate our hypotheses without having to involve our entire user base. However, any good experiment first requires the answer to the question — how do we know the right number of people to include in it?</p><p>Let’s break down why this is important. If we target too few, our experiments will not detect smaller effects, leading us to miss legitimate opportunities. If we target too many, we would be wasting resources and potentially hurting our business metrics (if the treatments turn out to be detrimental).</p><p>Previously, we used simple heuristics (and a mysterious formula) to estimate the required sample size. These practices were not very scientific and produced inconsistent experimental results. To compensate, we had to repeat the same experiment multiple times just to validate the results. Sometimes different iterations would conflict with each other, leaving everyone scratching their heads.</p><p>Last year, we ditched those unscientific practices and built a new tool called Sample Size Calculator (yes, imaginative name, we know). This post explains how the calculator helps us find the right number of people to include in experiments.</p><p>Our calculator is based on Frequentist school of statistics. Under the hood, we used both the <a href=\"https://cran.r-project.org/web/packages/pwr/vignettes/pwr-vignette.html\" rel=\"noopener\"><em><em>pwr</em></em></a> package and the base sample size calculation functions in R programming language. This is what the tool looks like:</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1600/0*4kcE2olMNjGN4WFC\" class=\"kg-image\"><figcaption><strong>Figure 1.</strong> Screenshot of the Sample Size Calculator used at Gojek</figcaption></figure><p>The most important parameters are the type of dependent variable measured, the historical data, and the required sensitivity from the experiment. As you can see in the graph, if we increase sensitivity to allow detection of smaller effects, the required sample size soars, which makes sense.</p><p>Although this is a major step in the right direction, there is a problem if we are interested in a continuous dependent variable for our experiment. This is because the underlying methodology used in the calculator assumes a normal distribution, while most continuous metrics that we care about at Gojek — such as <code>bookings per user</code> — are usually skewed. By ‘skewed’, we mean that most users are light users and only a small percentage are heavy users. This could cause the computed sample size requirement to be wrong because a key assumption was not met.</p><p>We have four options to deal with this problem:</p><ol><li>Use a methodology that doesn’t assume normality. Unfortunately, the available non-parametric methods are complex to implement [<a href=\"http://www.biostat.jhsph.edu/~ejohnson/regression/Sample%20Size%20Power%20Considerations.pdf\" rel=\"noopener\">1</a>] [<a href=\"https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4423589/\" rel=\"noopener\">2</a>]</li><li>Transform data to have a normal distribution. This doesn’t always work — some data just can’t be coerced to normal</li><li>Use a larger sample size. Since the worry is lower power than expected, simple multiplication should boost the power, but the multiplier needs to be reasonable. Figuring the right multiplier would be another beast on its own</li><li>Ignore it. <strong><strong>This is the path we took</strong></strong></li></ol><figure class=\"kg-card kg-image-card\"><img src=\"https://miro.medium.com/max/350/1*lDXre2rWb6KOp8zOdx7V-Q.gif\" class=\"kg-image\"></figure><blockquote><strong>But but but… that’s not scientific!</strong></blockquote><p><strong><strong>Don’t worry. We tested the robustness of this solution before going ahead with it.</strong></strong></p><p>As you can see in the graph below, we created two right-skewed distributions with known 5% difference in means to serve as our populations. The plan is to continuously sample from this population (equivalent to replicating the same experiment many times) and see how often we can detect this 5% difference (aka what is our “<a href=\"https://en.wikipedia.org/wiki/Power_(statistics)\" rel=\"noopener\">power</a>”).</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1120/0*vJpyQEMT_z3AgDSs\" class=\"kg-image\"><figcaption><strong>Figure 2.</strong> Two right-skewed distributions (typical shape for continuous metric at Gojek) with known mean difference (lift) of 5%</figcaption></figure><p>The first step is to calculate the required sample size with a power of 80% and minimum detectable effect of 5%. Let’s refer to this sample size requirement as the “exact” size. Then we divide and multiply it by three and call them “less” and “more”, respectively. For each sample size, we sample from the populations, compute the mean difference (typically called “lift”), and repeat this procedure many times.</p><p>The resulting distributions of lifts are shown below. The coloured vertical lines show the average lift of each experimental size, which is also equal to the actual population lift. This is <a href=\"https://en.wikipedia.org/wiki/Central_limit_theorem\" rel=\"noopener\">central limit theorem</a> at work. What is interesting are the relative shapes of the sampling distributions. The “more” group is the safest and most consistent but the “exact” group seems to have good accuracy with only a third of the sample size. In the “less” group, we even see a non-negligible number of lifts that are negative, even though we know the population lift is actually +5%. This is in line with our intuition that larger sample size is generally more trustworthy than a smaller one, all else being equal.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1120/0*Jtrd9syTiZADm04j\" class=\"kg-image\"><figcaption><strong>Figure 3.</strong> Sampling distribution of the mean difference from each size group</figcaption></figure><p>Since we currently report the statistical significance of our experimental results at Gojek, we will also run t-test for each of our sample here.</p><p>As it turns out, 80.4% of the experiments in the “exact” group have statistically significant results (p &lt; 0.05), which is almost equal to the 80% power we set in the sample size calculator. In layman’s terms, the tool roughly promised that <em><em>if you run the experiment with this sample size, you have 80% chance of detecting a 5% lift (the minimum detectable effect) if it’s there.</em></em></p><p>Since it kept its promise even on non-normally distributed data, we can conclude that the methodology is robust to some degree of violation of the normality assumption. Therefore we can ignore it until otherwise proven.</p><figure class=\"kg-card kg-image-card kg-width-wide kg-card-hascaption\"><img src=\"https://miro.medium.com/max/1120/0*zF3ocylJM9iMEDue\" class=\"kg-image\"><figcaption><strong>Figure 4.</strong> Percentage of samples/experiments with statistically significant results (p &lt; 0.05) from each size group</figcaption></figure><p>Meanwhile, the “less” group had only ~34% statistically significant results, suggesting that we shouldn’t run an experiment if we cannot fulfil the sample size requirement — since we risk not being able to detect an existing effect. With the “more” group having close to 100% statistically significant results, we again reaffirm that larger sample size is generally a good thing if we can afford it.</p><p>Since it was deployed in mid-2018, many teams across Gojek have adopted the Sample Size Calculator. So far, nearly 1,000 experiments have incorporated this tool in their designs, and it is also a part of <a href=\"https://blog.gojekengineering.com/introducing-litmus-gojeks-own-experimentation-platform-3803467b6a53\" rel=\"noopener\">Litmus, our experimentation platform</a>. The more critical takeaway for us is that the experiments run using the recommended sample sizes have similar results when full-scaled. This fact has enabled us to iterate faster and cut waste while maintaining a high degree of confidence in the experimental results. ✌️</p><p>Did we mention Gojek’s Growth team is hiring analysts? We are a super data-driven team and have helped shape some of the company’s best practices through projects like this. If you are analytical, interested in sharpening your technical chops, and want to have a meaningful impact to Gojek’s hypergrowth, come join us!</p><hr><p>For more updates like this, don’t forget to <a href=\"https://mailchi.mp/go-jek/gojek-tech-newsletter\" rel=\"noopener\">sign up for our newsletter</a>!</p>","url":"https://gojek-ghost.zysk.in/beast-moving-data-from-kafka-to-bigquery/","canonical_url":null,"uuid":"66b6dc18-3809-4494-a81e-a73d320935a3","page":null,"codeinjection_foot":null,"codeinjection_head":null,"codeinjection_styles":null,"comment_id":"5eb0fef85524cd001e739246","reading_time":5},"tags":{"edges":[{"node":{"name":"Culture","slug":"culture"}},{"node":{"name":"Data","slug":"data"}},{"node":{"name":"Design","slug":"design"}},{"node":{"name":"News","slug":"news"}},{"node":{"name":"Stories","slug":"stories"}},{"node":{"name":"Tech","slug":"tech"}},{"node":{"name":"Maps","slug":"maps"}},{"node":{"name":"Ride Hailing","slug":"ride-hailing"}},{"node":{"name":"Software Engineering","slug":"software-engineering"}},{"node":{"name":"Startup","slug":"startup"}}]}},"pageContext":{"slug":"beast-moving-data-from-kafka-to-bigquery"}}}